{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evitement des collisions - Démonstration (Resnet18)\n",
    "\n",
    "Dans ce notebook, nous allons utiliser le modèle entrainé en situation réelle avec le moteur TensorRT !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création du contexte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorrt as trt\n",
    "\n",
    "# Construction de la class du logger\n",
    "class MyLogger(trt.ILogger):\n",
    "    def __init__(self):\n",
    "        trt.ILogger.__init__(self)\n",
    "\n",
    "    def log(self, severity, msg):\n",
    "        print(\"%s : %s\" %(severity,msg))\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Severity.INFO : [MemUsageChange] Init CUDA: CPU +198, GPU +0, now: CPU 283, GPU 2090 (MiB)\n",
      "Severity.INFO : Loaded engine size: 37 MB\n",
      "Severity.INFO : [MemUsageSnapshot] deserializeCudaEngine begin: CPU 321 MiB, GPU 2165 MiB\n",
      "Severity.VERBOSE : Using cublas a tactic source\n",
      "Severity.INFO : [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +158, GPU +246, now: CPU 479, GPU 2411 (MiB)\n",
      "Severity.VERBOSE : Using cuDNN as a tactic source\n",
      "Severity.INFO : [MemUsageChange] Init cuDNN: CPU +241, GPU +351, now: CPU 720, GPU 2762 (MiB)\n",
      "Severity.INFO : [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +0, now: CPU 719, GPU 2762 (MiB)\n",
      "Severity.VERBOSE : Deserialization required 6168505 microseconds.\n",
      "Severity.INFO : [MemUsageSnapshot] deserializeCudaEngine end: CPU 719 MiB, GPU 2762 MiB\n"
     ]
    }
   ],
   "source": [
    "import tensorrt as trt\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "\n",
    "PRECISION = trt.float32\n",
    "\n",
    "logger = MyLogger()\n",
    "runtime = trt.Runtime(logger)\n",
    "\n",
    "with open(\"meilleur_model_colab/meilleur_modele_colab_FP16.engine\", \"rb\") as f:\n",
    "    engine = runtime.deserialize_cuda_engine(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul de la taille mémoire requise pour stocker les données d'entrée / sortie dans le GPU\n",
    "size_input = trt.volume(engine.get_binding_shape(0))* engine.max_batch_size\n",
    "size_output = trt.volume(engine.get_binding_shape(1))* engine.max_batch_size\n",
    "\n",
    "# Allocation de mémoire de type \"page-locked\" sur l'hôte\n",
    "input_host_mem = cuda.pagelocked_empty(size_input, trt.nptype(PRECISION))\n",
    "output_host_mem = cuda.pagelocked_empty(size_output, trt.nptype(PRECISION))\n",
    "\n",
    "# Allocation de mémoire dans la mémoire GPU\n",
    "input_device_mem = cuda.mem_alloc(input_host_mem.nbytes)\n",
    "output_device_mem = cuda.mem_alloc(output_host_mem.nbytes)\n",
    "\n",
    "# Récupère les adresses en GPU des buffers entrées / sorties\n",
    "bindings = [int(input_device_mem), int(output_device_mem)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création de l'interface d'acquisition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "J'ai créé une classe Image personnelle afin d'optimiser le pipeline avec OpenCV :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traitlets\n",
    "import threading\n",
    "import atexit\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Camera(traitlets.HasTraits):\n",
    "    type_camera = traitlets.Unicode(\"CSI\")\n",
    "    capture_device = traitlets.Integer(default_value=0)\n",
    "    capture_width = traitlets.Integer(default_value=1280)\n",
    "    capture_height = traitlets.Integer(default_value=720)\n",
    "    display_width = traitlets.Integer(default_value=640)\n",
    "    display_height = traitlets.Integer(default_value=480)\n",
    "    fps = traitlets.Integer(default_value=30)\n",
    "    flip = traitlets.Integer(default_value=0)\n",
    "    image = traitlets.Any()\n",
    "    video_on = traitlets.Bool(default_value=False)\n",
    "    \n",
    "    def __init__(self,*args,**kwargs):\n",
    "        super(Camera, self).__init__(*args, **kwargs)\n",
    "        self._running = False\n",
    "        self.image = np.zeros((self.display_height, self.display_width, 3), dtype=np.uint8)\n",
    "        \n",
    "        if self.type_camera.find(\"CSI\")>=0:\n",
    "            self.cap = cv2.VideoCapture(self._gstreamer_pipeline_CSI(),cv2.CAP_GSTREAMER)\n",
    "        else:\n",
    "            self.cap = cv2.VideoCapture(self._gstreamer_pipeline_USB(),cv2.CAP_GSTREAMER)\n",
    "\n",
    "        if self.cap.isOpened():\n",
    "            print(\"Caméra initialisée\")\n",
    "        else:\n",
    "            print(\"Erreur d'ouverture du flux vidéo\")\n",
    "        atexit.register(self.cap.release)\n",
    "    \n",
    "    # Lecture d'une frame\n",
    "    def capture_image(self):\n",
    "        re, image = self.cap.read()\n",
    "        if re:\n",
    "            image_resized = cv2.resize(image,(int(self.display_width),int(self.display_height)))\n",
    "            return image_resized\n",
    "        else:\n",
    "            return self.image\n",
    "    \n",
    "    # ON/OFF de la capture vidéo\n",
    "    def capture_video(self,run=False):\n",
    "        if run is True:\n",
    "            self.video_on = True\n",
    "        else:\n",
    "            self.video_on = False\n",
    "    \n",
    "    # Lecture d'un flux vidéo\n",
    "    def _capture_video(self):\n",
    "        while True:\n",
    "            if not self._running:\n",
    "                break\n",
    "            self.image = self.capture_image()\n",
    "\n",
    "            \n",
    "    # Détachement de la caméra\n",
    "    def release(self):\n",
    "        self.cap.release()\n",
    "\n",
    "    # Définition du pipeline pour la caméra CSI\n",
    "    def _gstreamer_pipeline_CSI(self):\n",
    "        return(\"nvarguscamerasrc sensor-id=%d ! \"\n",
    "                \"video/x-raw(memory:NVMM),\"\n",
    "                \"width=(int)%d,height=(int)%d,\"\n",
    "                \"format=(string)NV12, framerate=(fraction)%d/1 ! \"\n",
    "                \"nvvidconv flip-method=%d ! \"\n",
    "                \"video/x-raw,\"\n",
    "                \"width=(int)%d,height=(int)%d,\"\n",
    "                \"format=(string)BGRx ! videoconvert ! \"\n",
    "                \"video/x-raw, format=(string)BGR ! \"\n",
    "                \"appsink drop=true\"\n",
    "        %(self.capture_device,self.capture_width,self.capture_height,self.fps,self.flip, self.display_width,self.display_height))\n",
    "\n",
    "    # Définition du pipeline pour la USB\n",
    "    def _gstreamer_pipeline_USB(self):\n",
    "        return(\"v4l2src device=/dev/video%d ! \"\n",
    "               \"video/x-raw, width=(int)%d, height=(int)%d, framerate=(fraction)%d/1 ! \"\n",
    "               \"videoflip method=%d ! \"\n",
    "               \"videoconvert ! \"\n",
    "               \"video/x-raw, format=(string)BGR ! appsink drop=true\"\n",
    "        %(self.capture_device,self.capture_width,self.capture_height,self.fps,self.flip))\n",
    "    \n",
    "    # Surveillance de la variable \"video_on\"\n",
    "    @traitlets.observe('video_on')\n",
    "    def _on_running(self, change):\n",
    "        if change['new'] and not change['old']:\n",
    "            # not running -> running\n",
    "            self._running = True\n",
    "            self.thread = threading.Thread(target=self._capture_video)\n",
    "            self.thread.start()\n",
    "        elif change['old'] and not change['new']:\n",
    "            # running -> not running\n",
    "            self._running = False\n",
    "            self.thread.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonction pour initialiser la caméra :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def InitCamera():\n",
    "    camera = Camera(type_camera=\"CSI\",capture_device=0,\n",
    "                capture_width=224,capture_height=224,\n",
    "                display_width=224,display_height=224,\n",
    "                fps=30,flip=0)\n",
    "    return camera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Création de l'interface :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caméra initialisée\n"
     ]
    }
   ],
   "source": [
    "import ipywidgets\n",
    "import traitlets\n",
    "from IPython.display import display\n",
    "\n",
    "try :\n",
    "    camera.capture_video(run=False)\n",
    "    camera.release()\n",
    "    del camera\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "# Initialise la caméra\n",
    "camera = InitCamera()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "639c0eca1c3e4e9b90c10a03d952918f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import traitlets\n",
    "from IPython.display import display\n",
    "import ipywidgets.widgets as widgets\n",
    "\n",
    "from jetbot import bgr8_to_jpeg\n",
    "\n",
    "# Lance la caméra\n",
    "camera.capture_video(run=True)\n",
    "\n",
    "# Création de l'interface\n",
    "image = widgets.Image(format='jpeg', width=224, height=224)\n",
    "slider_bloquer = widgets.FloatSlider(description='bloquer', min=0.0, max=1.0, orientation='vertical')\n",
    "slider_vitesse = widgets.FloatSlider(description='vitesse', min=0.0, max=0.5, value=0.0, step=0.01, orientation='horizontal')\n",
    "\n",
    "lien_camera = traitlets.dlink((camera, 'image'), (image, 'value'), transform=bgr8_to_jpeg)\n",
    "\n",
    "display(widgets.VBox([widgets.HBox([image, slider_bloquer]), slider_vitesse]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il faut ensuite créer une instance du robot pour pouvoir le commander :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetbot import Robot\n",
    "\n",
    "robot = Robot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensuite, on créé une fonction qui va être appellée à chaque fois qu'une nouvelle image est disponible. Cette fonction doit réaliser les opérations suivantes :\n",
    "\n",
    "1. Pré-traitement de l'image issue de la caméra\n",
    "2. Appliquer le modèle sur l'image récupérée\n",
    "3. Si le modèle indique que nous sommes bloqué, alors le robot tourne à gauche. Sinon le robot avance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "n_images = 0\n",
    "somme_proba = 0.0\n",
    "\n",
    "def mise_a_jour(change):\n",
    "    global slider_bloquer, robot\n",
    "    global n_images\n",
    "    global somme_proba\n",
    "    \n",
    "    x = change['new']                               # (224,224,3)\n",
    "    #x = traitement_image(x)                        # Aucun traitement ici\n",
    "    x = x.astype(np.float32)\n",
    "    x = np.expand_dims(x,axis=0)                          # (1,224,224,3)\n",
    "    \n",
    "    np.copyto(input_host_mem,x.ravel())\n",
    "    \n",
    "    cfx.push()\n",
    "    cuda.memcpy_htod(input_device_mem, input_host_mem)\n",
    "    context.execute(batch_size=1,bindings=bindings)\n",
    "    cuda.memcpy_dtoh(output_host_mem, output_device_mem)\n",
    "    cfx.pop()\n",
    "    \n",
    "    proba_bloquer = float(np.asarray(output_host_mem[0]))\n",
    "    \n",
    "    n_images = n_images + 1\n",
    "    somme_proba = somme_proba + proba_bloquer\n",
    "\n",
    "    if n_images == 1:\n",
    "        proba_moyenne = somme_proba/1\n",
    "        slider_bloquer.value = proba_moyenne\n",
    "        if proba_moyenne < 0.5:\n",
    "            robot.forward(slider_vitesse.value)\n",
    "        else:\n",
    "            robot.left(slider_vitesse.value)\n",
    "        n_images = 0\n",
    "        somme_proba = 0.0\n",
    "    \n",
    "    time.sleep(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Création du context...\n",
      "Severity.INFO : [MemUsageSnapshot] ExecutionContext creation begin: CPU 1773 MiB, GPU 3839 MiB\n",
      "Severity.VERBOSE : Using cublas a tactic source\n",
      "Severity.INFO : [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +158, GPU +6, now: CPU 1931, GPU 3846 (MiB)\n",
      "Severity.VERBOSE : Using cuDNN as a tactic source\n",
      "Severity.INFO : [MemUsageChange] Init cuDNN: CPU +240, GPU -40, now: CPU 2171, GPU 3806 (MiB)\n",
      "Severity.VERBOSE : Total per-runner device memory is 29800960\n",
      "Severity.VERBOSE : Total per-runner host memory is 30016\n",
      "Severity.VERBOSE : Allocated activation device memory of size 3671040\n",
      "Severity.INFO : [MemUsageSnapshot] ExecutionContext creation end: CPU 2170 MiB, GPU 3797 MiB\n",
      "Severity.INFO : [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +0, now: CPU 2170, GPU 3802 (MiB)\n"
     ]
    }
   ],
   "source": [
    "print(\"Création du context...\")\n",
    "cfx = cuda.Device(0).make_context()\n",
    "context = engine.create_execution_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mise_a_jour({'new': camera.image})  # Appel la fonction une première fois pour initialiser le réseau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons donc maintenant notre réseeau de neurones en place, mais il reste à créer le lien entre la caméra et la fonction de mise à jour pour récupérer les images filmées. Cela se fait avec la fonction ``observe``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.observe(mise_a_jour, names='image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous devriez maintenant voir le slider indiquer la probabilité d'être bloqué ou non ! Il suffit d'augmenter la vitesse pour tester le bon fonctionnement du robot en déplacement.\n",
    "\n",
    "Pour arrêter les expériences, il suffit de rompre le lien avec la fonction de mise à jour :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "camera.unobserve(mise_a_jour, names='image')\n",
    "\n",
    "time.sleep(0.1)  # Petit temps d'attente pour que l'image soit bien traitée par le modèle\n",
    "\n",
    "robot.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_device_mem.free()\n",
    "output_device_mem.free()\n",
    "del input_host_mem\n",
    "del output_host_mem\n",
    "del context\n",
    "del engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avant de quitter, il faut fermer la caméra :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try :\n",
    "    camera.capture_video(run=False)\n",
    "    camera.release()\n",
    "    del camera\n",
    "except NameError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
