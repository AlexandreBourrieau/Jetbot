{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a8713c0-3bb9-452d-930d-ce2921ba25b2",
   "metadata": {},
   "source": [
    "# Test de rapidité du modèle utilisé avec TensorRT (Resnet18)\n",
    "\n",
    "Dans ce notebook, nous allons tester la rapidité du modèle TensorRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96baae5d-a860-4732-88c3-c1f5bc225f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537ddb1e-fd15-4811-8362-7a9320e3310e",
   "metadata": {},
   "source": [
    "# Création du contexte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6a281b-1502-42bb-8c8b-038d4b5297be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorrt as trt\n",
    "\n",
    "# Construction de la class du logger\n",
    "class MyLogger(trt.ILogger):\n",
    "    def __init__(self):\n",
    "        trt.ILogger.__init__(self)\n",
    "\n",
    "    def log(self, severity, msg):\n",
    "        print(\"%s : %s\" %(severity,msg))\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d544063-0e9a-4365-8dab-a918e3eaf6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorrt as trt\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "\n",
    "PRECISION = trt.float32\n",
    "\n",
    "logger = MyLogger()\n",
    "runtime = trt.Runtime(logger)\n",
    "\n",
    "with open(\"meilleur_model_colab/meilleur_modele_colab_FP16.engine\", \"rb\") as f:\n",
    "    engine = runtime.deserialize_cuda_engine(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df47e0aa-e77c-4099-8f28-25676273fb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = engine.create_execution_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf2b711-56b0-4964-a42d-b323d7d0163d",
   "metadata": {},
   "source": [
    "# Utilisation du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e41da8-9c21-4ab9-af0d-68f6bc48e50c",
   "metadata": {},
   "source": [
    "Commençons par allouer les espaces mémoire nécessaires :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b5c57c-4d94-402d-83d5-ecefe18fc73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul de la taille mémoire requise pour stocker les données d'entrée / sortie dans le GPU\n",
    "size_input = trt.volume(engine.get_binding_shape(0))* engine.max_batch_size\n",
    "size_output = trt.volume(engine.get_binding_shape(1))* engine.max_batch_size\n",
    "\n",
    "# Allocation de mémoire de type \"page-locked\" sur l'hôte\n",
    "input_host_mem = cuda.pagelocked_empty(size_input, trt.nptype(PRECISION))\n",
    "output_host_mem = cuda.pagelocked_empty(size_output, trt.nptype(PRECISION))\n",
    "\n",
    "# Allocation de mémoire dans la mémoire GPU\n",
    "input_device_mem = cuda.mem_alloc(input_host_mem.nbytes)\n",
    "output_device_mem = cuda.mem_alloc(output_host_mem.nbytes)\n",
    "\n",
    "# Récupère les adresses en GPU des buffers entrées / sorties\n",
    "bindings = [int(input_device_mem), int(output_device_mem)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ab8a26-0481-4b56-afa2-5bb189cba225",
   "metadata": {},
   "source": [
    "Nous allons utiliser notre modèle pour mesurer son temps de calcul et son débit pour traiter les images. Du fait de l'initialisation du GPU, nous allons mesurer ces caractéristiques après avoir utilisé le modèle un petit nombre de fois :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4091a86c-e6ae-4cba-bfd8-9957bae38687",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "nbr_run = 100\n",
    "delais = []\n",
    "predictions = []\n",
    "\n",
    "image = np.zeros((1,224, 224, 3), dtype=np.float32)\n",
    "\n",
    "# Initialisation des calculs\n",
    "print(\"Initialisation des calculs...\")\n",
    "for i in range(5):\n",
    "    np.copyto(input_host_mem,image.ravel())\n",
    "    cuda.memcpy_htod(input_device_mem, input_host_mem)\n",
    "    context.execute(batch_size=1,bindings=bindings)\n",
    "    cuda.memcpy_dtoh(output_host_mem, output_device_mem)\n",
    "    predictions.append(float(np.asarray(output_host_mem[0])))\n",
    "\n",
    "# Lance les inférences\n",
    "for i in range(nbr_run):\n",
    "    time0 = time.time()\n",
    "    np.copyto(input_host_mem,image.ravel())\n",
    "    cuda.memcpy_htod(input_device_mem, input_host_mem)\n",
    "    context.execute(batch_size=1,bindings=bindings)\n",
    "    cuda.memcpy_dtoh(output_host_mem, output_device_mem)\n",
    "    time_end = time.time()\n",
    "        \n",
    "    delais = np.append(delais,time_end - time0)\n",
    "    predictions.append(float(np.asarray(output_host_mem[0])))\n",
    "        \n",
    "    if i%10 == 0:\n",
    "        print(\"Etape %d-%d moyenne : %4.1f ms\" %(i,i+5,(delais[-10:].mean())*1000))\n",
    "                       \n",
    "print(\"Débit : %.0f images/s\" %(nbr_run / delais.sum()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
