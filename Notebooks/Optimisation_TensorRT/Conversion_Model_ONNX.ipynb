{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from tensorflow import keras\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chargement du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On commence par charger notre modèle en mémoire :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import classification_models\n",
    "from classification_models.tfkeras import Classifiers\n",
    "\n",
    "# Chargement du modèle ResNEt18\n",
    "ResNet18, preprocess_input = Classifiers.get('resnet18')\n",
    "\n",
    "# Instanciation du modèle pré-entrainé ResNet18\n",
    "base_model = ResNet18(input_shape=(224,224,3), weights='imagenet', include_top=False,pooling=False)\n",
    "\n",
    "# Désactivation des couches pour l'entrainement\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "# Ajout de l'applatissement des sorties et de la couche dense avec 2 neurones\"\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "output = tf.keras.layers.Dense(units=2, activation='softmax')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=[base_model.input], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"meilleur_modele_colab.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exportation du modèle au format Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.saved_model.save(model,\"meilleur_model_colab\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour obtenir des informations sur le modèlé on peut utiliser la commande **saved_model_cli** :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!saved_model_cli show --all --dir meilleur_model_colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversion du modèle sauvegardé au format ONNX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous aurons besoin par la suite du modèle au format ONNX pour réaliser les optimisations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remarque importante** : Si vous voyez le message ***IMPORTANT*** Installed protbuf is not cpp accelerated... Il faut mettre à jour votre version en utilisant le script disponible ici : https://github.com/AlexandreBourrieau/JetsonNano/blob/main/install_protobuf-3.19.4.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m tf2onnx.convert --saved-model \"meilleur_model_colab\" --output \"meilleur_model_colab/meilleur_model_colab.onnx\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On modifie maintenant le batch_size :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "\n",
    "batch_size = 1\n",
    "onnx_model = onnx.load(\"meilleur_model_colab/meilleur_model_colab.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regardons à quoi ressemble l'entrée du modèle :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = onnx_model.graph.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "\n",
    "inputs = onnx_model.graph.input\n",
    "for input in inputs:\n",
    "    dim1 = input.type.tensor_type.shape.dim[0]\n",
    "    dim1.dim_value = batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puis on sauvegarde les modifications :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx.save_model(onnx_model,\"meilleur_model_colab/meilleur_model_colab.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
