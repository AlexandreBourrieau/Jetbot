{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evitement de collisions - Entrainement du modèle (ResNet18)\n",
    "\n",
    "Dans ce notebook, nous allons entrainer notre modèle afin qu'il puisse classifier les images capturées avec la caméra dans les classes ``libre`` ou ``bloquer``. Le modèle que nous allons utiliser est le modèle Restnet18.\n",
    "Nous allons utiliser la librairie Keras / Tensorflow pour créer notre modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from tensorflow import keras\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Téléchargement et extraction des données collectées \n",
    "\n",
    "Tout d'abord il faut récupérer les données collectées contenues dans le fichier ``dataset.zip`` que nous avons créé précedemment. Pour cela, il suffit d'exécuter la commande ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!unzip -q dataset.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un dossier nommé ``dataset`` devrait apparaître dans l'explorateur de fichiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création des datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement des images dans le dataset d'entrainement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir des images sauvegardées dans le répertoire de travail, on peut maintenant créer notre dataset. On commence par créer une liste contenant les deux classes utilisées :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORIES = ['bloquer', 'libre']\n",
    "datasets = {}\n",
    "for name in CATEGORIES:\n",
    "    datasets[name] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On charge ensuite les données à l'aide de la fonction ``image_dataset_from_directory`` de Keras, en précisant la résolution des images et le type de label associé (ici on utilise le type ``categorical`` - voir ci-dessous). On demande également d'utiliser un ``batch size`` de 1 et d'utiliser 90% des images pour l'entrainement et les 10% restant pour les validations :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupère le répertoire courant\n",
    "repertoire_courant = os.getcwd()\n",
    "\n",
    "# Création du dataset d'entrainement\n",
    "dataset_entrainement = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    repertoire_courant+\"/dataset/\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    image_size=(224, 224),\n",
    "    batch_size=1,\n",
    "    shuffle=True,\n",
    "    seed=123,\n",
    "    label_mode='categorical')\n",
    "\n",
    "# Création du dataset de validation\n",
    "dataset_validation = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    repertoire_courant+\"/dataset/\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    image_size=(224, 224),\n",
    "    batch_size=1,\n",
    "    shuffle=True,\n",
    "    seed=123,\n",
    "    label_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observons le nom des classes utilisées :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = dataset_entrainement.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regardons le format du tenseur contenu dans le dataset :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image,label in dataset_entrainement.take(2):\n",
    "    print(image.shape)\n",
    "    print(label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regardons comment est codée une image :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image,label in dataset_entrainement.take(1):\n",
    "    print(image[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichons quelques labels codé de manière \"categorical\" et leur valeur équivalente \"binaire\" :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image,label in dataset_entrainement.take(5):\n",
    "    print(\"Label categorical : %s\" %label[0])\n",
    "    print(\"Label binaire correspondant : %s\" %np.argmax(label[0], axis=None, out=None))\n",
    "    print(\"Classe correspondante : %s\" %class_names[np.argmax(label[0], axis=None, out=None)])\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichons maintenant quelques images :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = iter(dataset_entrainement)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(8):\n",
    "    ax = plt.subplot(4, 4, i + 1)\n",
    "    image, label = iterator.get_next()\n",
    "    plt.imshow(image[0].numpy().astype(\"uint8\"))\n",
    "    plt.title(class_names[np.argmax(label[0], axis=None, out=None)])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traitement des images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour le Resnet18 avec Keras / Tensorflow, il n'y a aucune action de prétraitement à effectuer !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour utiliser le modèle RestNet18, nous allons utiliser le package Image-classifiers disponnible sur le github : https://github.com/AlexandreBourrieau/classification_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import classification_models\n",
    "from classification_models.tfkeras import Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement du modèle ResNEt18\n",
    "ResNet18, preprocess_input = Classifiers.get('resnet18')\n",
    "\n",
    "# Instanciation du modèle pré-entrainé ResNet18\n",
    "base_model = ResNet18(input_shape=(224,224,3), weights='imagenet', include_top=False,pooling=False)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=base_model.input, outputs=base_model.output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Désactivation des couches pour l'entrainement\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On ajoute ensuite la couche d'applatissemnt des sorties et la couche dense avec 2 neurones (1 neurone par classe) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajout de l'applatissement des sorties et de la couche dense avec 2 neurones\"\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "output = tf.keras.layers.Dense(units=2, activation='softmax')(x)\n",
    "\n",
    "# Création du modèle global\n",
    "model = tf.keras.Model(inputs=[base_model.input], outputs=[output])\n",
    "\n",
    "# Affichage des informations sur le modèle\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste des couches du modèle\n",
    "for i, layer in enumerate(model.layers):\n",
    "   print(i, layer.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On sélectionne éventuellement les couches à entrainer :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#68 stage4_unit1_conv1\n",
    "#72 stage4_unit1_conv2\n",
    "#78 stage4_unit2_conv1\n",
    "#82 stage4_unit2_conv2\n",
    "#87 dense_1\n",
    "\n",
    "for layer in model.layers[87:]:\n",
    "   layer.trainable = True\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrainement du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant, on lance l'entrainement du modèle. On fait également en sorte de sauvegarder le meilleur modèle en considérant les résultats obtenus sur les données de validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Nombre de périodes d'entrainement\n",
    "periodes = 30\n",
    "\n",
    "# Définition de la fonction d'enregistrement automatique du meilleur modèle\n",
    "model_save = ModelCheckpoint('meilleur_modele.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "\n",
    "# Définition de l'ooptimiseur\n",
    "adam = keras.optimizers.Adam(learning_rate=1e-4)\n",
    "\n",
    "# Entrainement du modèle : from_logits=True car on utilise un Softmax en sortie de notre modèle\n",
    "model.compile(optimizer=adam, loss='categorical_crossentropy')\n",
    "historique = model.fit(dataset_entrainement,validation_data=dataset_validation,verbose=1,epochs=periodes, callbacks=[model_save])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observons pour finir l'évolution de la qualité de l'apprentissage du modèle :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = historique.history['loss']\n",
    "val_loss = historique.history['val_loss']\n",
    "\n",
    "intervalle_periodes = range(periodes)\n",
    "\n",
    "plt.plot(intervalle_periodes, loss, label=\"Erreur d'entrainement\")\n",
    "plt.plot(intervalle_periodes, val_loss, label=\"Erreur de validation\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.title(\"Erreur d'entrainement et de validation\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
