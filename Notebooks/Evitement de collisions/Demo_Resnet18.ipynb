{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evitement des collisions - Démonstration (Resnet18)\n",
    "\n",
    "Dans ce notebook, nous allons utiliser le modèle entrainé en situation réelle !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import classification_models\n",
    "from classification_models.tfkeras import Classifiers\n",
    "\n",
    "# Chargement du modèle ResNEt18\n",
    "ResNet18, preprocess_input = Classifiers.get('resnet18')\n",
    "\n",
    "# Instanciation du modèle pré-entrainé ResNet18\n",
    "base_model = ResNet18(input_shape=(224,224,3), weights='imagenet', include_top=False,pooling=False)\n",
    "\n",
    "# Désactivation des couches pour l'entrainement\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "# Ajout de l'applatissement des sorties et de la couche dense avec 2 neurones\"\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "output = tf.keras.layers.Dense(units=2, activation='softmax')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=[base_model.input], outputs=[output])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On charge ensuite les poids sauvegardés lors de l'entrainement :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"meilleur_modele_colab.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création de l'interface d'acquisition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "J'ai créé une classe Image personnelle afin d'optimiser le pipeline avec OpenCV :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traitlets\n",
    "import threading\n",
    "import atexit\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Camera(traitlets.HasTraits):\n",
    "    type_camera = traitlets.Unicode(\"CSI\")\n",
    "    capture_device = traitlets.Integer(default_value=0)\n",
    "    capture_width = traitlets.Integer(default_value=1280)\n",
    "    capture_height = traitlets.Integer(default_value=720)\n",
    "    display_width = traitlets.Integer(default_value=640)\n",
    "    display_height = traitlets.Integer(default_value=480)\n",
    "    fps = traitlets.Integer(default_value=30)\n",
    "    flip = traitlets.Integer(default_value=0)\n",
    "    image = traitlets.Any()\n",
    "    video_on = traitlets.Bool(default_value=False)\n",
    "    \n",
    "    def __init__(self,*args,**kwargs):\n",
    "        super(Camera, self).__init__(*args, **kwargs)\n",
    "        self._running = False\n",
    "        self.image = np.zeros((self.display_height, self.display_width, 3), dtype=np.uint8)\n",
    "        \n",
    "        if self.type_camera.find(\"CSI\")>=0:\n",
    "            self.cap = cv2.VideoCapture(self._gstreamer_pipeline_CSI(),cv2.CAP_GSTREAMER)\n",
    "        else:\n",
    "            self.cap = cv2.VideoCapture(self._gstreamer_pipeline_USB(),cv2.CAP_GSTREAMER)\n",
    "\n",
    "        if self.cap.isOpened():\n",
    "            print(\"Caméra initialisée\")\n",
    "        else:\n",
    "            print(\"Erreur d'ouverture du flux vidéo\")\n",
    "        atexit.register(self.cap.release)\n",
    "    \n",
    "    # Lecture d'une frame\n",
    "    def capture_image(self):\n",
    "        re, image = self.cap.read()\n",
    "        if re:\n",
    "            image_resized = cv2.resize(image,(int(self.display_width),int(self.display_height)))\n",
    "            return image_resized\n",
    "        else:\n",
    "            return self.image\n",
    "    \n",
    "    # ON/OFF de la capture vidéo\n",
    "    def capture_video(self,run=False):\n",
    "        if run is True:\n",
    "            self.video_on = True\n",
    "        else:\n",
    "            self.video_on = False\n",
    "    \n",
    "    # Lecture d'un flux vidéo\n",
    "    def _capture_video(self):\n",
    "        while True:\n",
    "            if not self._running:\n",
    "                break\n",
    "            self.image = self.capture_image()\n",
    "\n",
    "            \n",
    "    # Détachement de la caméra\n",
    "    def release(self):\n",
    "        self.cap.release()\n",
    "\n",
    "    # Définition du pipeline pour la caméra CSI\n",
    "    def _gstreamer_pipeline_CSI(self):\n",
    "        return(\"nvarguscamerasrc sensor-id=%d ! \"\n",
    "                \"video/x-raw(memory:NVMM),\"\n",
    "                \"width=(int)%d,height=(int)%d,\"\n",
    "                \"format=(string)NV12, framerate=(fraction)%d/1 ! \"\n",
    "                \"nvvidconv flip-method=%d ! \"\n",
    "                \"video/x-raw,\"\n",
    "                \"width=(int)%d,height=(int)%d,\"\n",
    "                \"format=(string)BGRx ! videoconvert ! \"\n",
    "                \"video/x-raw, format=(string)BGR ! \"\n",
    "                \"appsink drop=true\"\n",
    "        %(self.capture_device,self.capture_width,self.capture_height,self.fps,self.flip, self.display_width,self.display_height))\n",
    "\n",
    "    # Définition du pipeline pour la USB\n",
    "    def _gstreamer_pipeline_USB(self):\n",
    "        return(\"v4l2src device=/dev/video%d ! \"\n",
    "               \"video/x-raw, width=(int)%d, height=(int)%d, framerate=(fraction)%d/1 ! \"\n",
    "               \"videoflip method=%d ! \"\n",
    "               \"videoconvert ! \"\n",
    "               \"video/x-raw, format=(string)BGR ! appsink drop=true\"\n",
    "        %(self.capture_device,self.capture_width,self.capture_height,self.fps,self.flip))\n",
    "    \n",
    "    # Surveillance de la variable \"video_on\"\n",
    "    @traitlets.observe('video_on')\n",
    "    def _on_running(self, change):\n",
    "        if change['new'] and not change['old']:\n",
    "            # not running -> running\n",
    "            self._running = True\n",
    "            self.thread = threading.Thread(target=self._capture_video)\n",
    "            self.thread.start()\n",
    "        elif change['old'] and not change['new']:\n",
    "            # running -> not running\n",
    "            self._running = False\n",
    "            self.thread.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonction pour initialiser la caméra :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def InitCamera():\n",
    "    camera = Camera(type_camera=\"CSI\",capture_device=0,\n",
    "                capture_width=224,capture_height=224,\n",
    "                display_width=224,display_height=224,\n",
    "                fps=25,flip=0)\n",
    "    return camera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Création de l'interface :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets\n",
    "import traitlets\n",
    "from IPython.display import display\n",
    "\n",
    "try :\n",
    "    camera.capture_video(run=False)\n",
    "    camera.release()\n",
    "    del camera\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "# Initialise la caméra\n",
    "camera = InitCamera()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traitlets\n",
    "from IPython.display import display\n",
    "import ipywidgets.widgets as widgets\n",
    "\n",
    "from jetbot import bgr8_to_jpeg\n",
    "\n",
    "# Lance la caméra\n",
    "camera.capture_video(run=True)\n",
    "\n",
    "# Création de l'interface\n",
    "image = widgets.Image(format='jpeg', width=224, height=224)\n",
    "slider_bloquer = widgets.FloatSlider(description='bloquer', min=0.0, max=1.0, orientation='vertical')\n",
    "slider_vitesse = widgets.FloatSlider(description='vitesse', min=0.0, max=0.5, value=0.0, step=0.01, orientation='horizontal')\n",
    "\n",
    "lien_camera = traitlets.dlink((camera, 'image'), (image, 'value'), transform=bgr8_to_jpeg)\n",
    "\n",
    "display(widgets.VBox([widgets.HBox([image, slider_bloquer]), slider_vitesse]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il faut ensuite créer une instance du robot pour pouvoir le commander :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetbot import Robot\n",
    "\n",
    "robot = Robot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensuite, on créé une fonction qui va être appellée à chaque fois qu'une nouvelle image est disponible. Cette fonction doit réaliser les opérations suivantes :\n",
    "\n",
    "1. Pré-traitement de l'image issue de la caméra\n",
    "2. Appliquer le modèle sur l'image récupérée\n",
    "3. Si le modèle indique que nous sommes bloqué, alors le robot tourne à gauche. Sinon le robot avance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def mise_a_jour(change):\n",
    "    global slider_bloquer, robot\n",
    "    x = change['new']                               # (224,224,3)\n",
    "    #x = traitement_image(x)                        # Aucun traitement ici\n",
    "    y = model(tf.expand_dims(x,0))                  # (224,224,3) => (1,224,224,3)\n",
    "      \n",
    "    proba_bloquer = float(np.asarray(y[0])[0])\n",
    "    \n",
    "    slider_bloquer.value = proba_bloquer\n",
    "    \n",
    "    if proba_bloquer < 0.5:\n",
    "        robot.forward(slider_vitesse.value)\n",
    "    else:\n",
    "        robot.left(slider_vitesse.value)\n",
    "    \n",
    "    time.sleep(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mise_a_jour({'new': camera.image})  # Appel la fonction une première fois pour initialiser le réseau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons donc maintenant notre réseeau de neurones en place, mais il reste à créer le lien entre la caméra et la fonction de mise à jour pour récupérer les images filmées. Cela se fait avec la fonction ``observe``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.observe(mise_a_jour, names='image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous devriez maintenant voir le slider indiquer la probabilité d'être bloqué ou non ! Il suffit d'augmenter la vitesse pour tester le bon fonctionnement du robot en déplacement.\n",
    "\n",
    "Pour arrêter les expériences, il suffit de rompre le lien avec la fonction de mise à jour :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "camera.unobserve(mise_a_jour, names='image')\n",
    "\n",
    "time.sleep(0.1)  # Petit temps d'attente pour que l'image soit bien traitée par le modèle\n",
    "\n",
    "robot.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avant de quitter, il faut fermer la caméra :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try :\n",
    "    camera.capture_video(run=False)\n",
    "    camera.release()\n",
    "    del camera\n",
    "except NameError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "That's it for this live demo!  Hopefully you had some fun and your robot avoided collisions intelligently! \n",
    "\n",
    "If your robot wasn't avoiding collisions very well, try to spot where it fails.  The beauty is that we can collect more data for these failure scenarios\n",
    "and the robot should get even better :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
