{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb4a0ce6-202c-46cf-ba24-651a3535da6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from tensorflow import keras\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b30cd6c-4969-4195-99f9-df4167dc9585",
   "metadata": {},
   "source": [
    "# Conversion du modèle vers un modèle TensorRT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7f7879-f1fc-405f-93fc-8845b065627c",
   "metadata": {},
   "source": [
    "TensorRT réalise plusieurs modifications et optimisations sur le réseau. Tout d'abord, les couches n'utilisant pas de sorties sont supprimées afin d'alléger les calculs. Ensuite, lorsque cela est possible, les couches de convolution, les offsets (bias) et les activations sont fusionnées pour ne former qu'une couche unique.  \n",
    "Vous pouvez trouver des informations relatives à TensorRT sur le site de Nvidia : https://developer.nvidia.com/tensorrt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd04c2a-d1a6-4188-892c-258313ef6f36",
   "metadata": {},
   "source": [
    "Pour réaliser la converison du modèle, nous utilisons l'outil trtexec, en précisant le répertoire dans lequel le modèle est sauvegardé et les paramètres de conversion :  \n",
    "- **precision_mode** : Format de codage des nombres : FP32, FP16 ou INT8. Les formats inférieurs au FP32 (FP16 et INT8) peuvent améliorer les performances des calculs. Le mode FP16 utilise des coeurs matériels avec des instructions sur des flottants 16bits lorsque cela est possible. Le mode INT8 utilise des coeurs matériels avec des instructions sur des entiers.     \n",
    "- **max_batch_size** : Le batch-size maximum à utiliser pendant l'optimisation. Pendant l'excéution en temps réel, on peut choisir une valeur plus petite mais pas plus grande.  \n",
    "- **minimum_segment_size** : Ce paramètre permet de préciser la valeur minimale de noeuds qu'il faut pour que la conversion du réseau soit exécutée. En conséquence, en général on choisit des valeurs inférieures à 5. Ce paramètre permet également de choisir le nombre minimum de noeuds pendant l'optimisation finale INT8 et donc d'optimiser la précision des résultats finaux.  \n",
    "- **max_workspace_size_byte** : Les opérations d'optimisation de TensorRT ont besoin d'utiliser de l'espace de stockage temporaire. Ce paramètre permet de limiter l'espace maximal utilisé dans le GPU qu'une couche peut utiliser. Si une valeur insuffisante est donnée, TensorRT peut ne pas réussir à optimiser le modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83489ce-9a2f-42fe-b28c-d61452116238",
   "metadata": {},
   "source": [
    "Les arguments disponibles peuvent être obtenus à l'aide de la commande trtexec :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df4f99e-3db0-4f27-aa69-9f43a55829a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!/usr/src/tensorrt/bin/trtexec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8205c1-d6a3-4ea6-99d2-ffb271bc5a18",
   "metadata": {},
   "source": [
    "### Conversion au format FP16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20cb0dc-1e43-42cb-a928-44462cc83fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "&&&& RUNNING TensorRT.trtexec [TensorRT v8001] # /usr/src/tensorrt/bin/trtexec --verbose --fp16 --workspace=256 --maxBatch=1 --onnx=meilleur_model_colab/meilleur_model_colab.onnx --saveEngine=meilleur_model_colab/meilleur_modele_colab_FP16.engine\n",
      "[04/10/2022-15:17:19] [I] === Model Options ===\n",
      "[04/10/2022-15:17:19] [I] Format: ONNX\n",
      "[04/10/2022-15:17:19] [I] Model: meilleur_model_colab/meilleur_model_colab.onnx\n",
      "[04/10/2022-15:17:19] [I] Output:\n",
      "[04/10/2022-15:17:19] [I] === Build Options ===\n",
      "[04/10/2022-15:17:19] [I] Max batch: explicit\n",
      "[04/10/2022-15:17:19] [I] Workspace: 256 MiB\n",
      "[04/10/2022-15:17:19] [I] minTiming: 1\n",
      "[04/10/2022-15:17:19] [I] avgTiming: 8\n",
      "[04/10/2022-15:17:19] [I] Precision: FP32+FP16\n",
      "[04/10/2022-15:17:19] [I] Calibration: \n",
      "[04/10/2022-15:17:19] [I] Refit: Disabled\n",
      "[04/10/2022-15:17:19] [I] Sparsity: Disabled\n",
      "[04/10/2022-15:17:19] [I] Safe mode: Disabled\n",
      "[04/10/2022-15:17:19] [I] Restricted mode: Disabled\n",
      "[04/10/2022-15:17:19] [I] Save engine: meilleur_model_colab/meilleur_modele_colab_FP16.engine\n",
      "[04/10/2022-15:17:19] [I] Load engine: \n",
      "[04/10/2022-15:17:19] [I] NVTX verbosity: 0\n",
      "[04/10/2022-15:17:19] [I] Tactic sources: Using default tactic sources\n",
      "[04/10/2022-15:17:19] [I] timingCacheMode: local\n",
      "[04/10/2022-15:17:19] [I] timingCacheFile: \n",
      "[04/10/2022-15:17:19] [I] Input(s)s format: fp32:CHW\n",
      "[04/10/2022-15:17:19] [I] Output(s)s format: fp32:CHW\n",
      "[04/10/2022-15:17:19] [I] Input build shapes: model\n",
      "[04/10/2022-15:17:19] [I] Input calibration shapes: model\n",
      "[04/10/2022-15:17:19] [I] === System Options ===\n",
      "[04/10/2022-15:17:19] [I] Device: 0\n",
      "[04/10/2022-15:17:19] [I] DLACore: \n",
      "[04/10/2022-15:17:19] [I] Plugins:\n",
      "[04/10/2022-15:17:19] [I] === Inference Options ===\n",
      "[04/10/2022-15:17:19] [I] Batch: Explicit\n",
      "[04/10/2022-15:17:19] [I] Input inference shapes: model\n",
      "[04/10/2022-15:17:19] [I] Iterations: 10\n",
      "[04/10/2022-15:17:19] [I] Duration: 3s (+ 200ms warm up)\n",
      "[04/10/2022-15:17:19] [I] Sleep time: 0ms\n",
      "[04/10/2022-15:17:19] [I] Streams: 1\n",
      "[04/10/2022-15:17:19] [I] ExposeDMA: Disabled\n",
      "[04/10/2022-15:17:19] [I] Data transfers: Enabled\n",
      "[04/10/2022-15:17:19] [I] Spin-wait: Disabled\n",
      "[04/10/2022-15:17:19] [I] Multithreading: Disabled\n",
      "[04/10/2022-15:17:19] [I] CUDA Graph: Disabled\n",
      "[04/10/2022-15:17:19] [I] Separate profiling: Disabled\n",
      "[04/10/2022-15:17:19] [I] Time Deserialize: Disabled\n",
      "[04/10/2022-15:17:19] [I] Time Refit: Disabled\n",
      "[04/10/2022-15:17:19] [I] Skip inference: Disabled\n",
      "[04/10/2022-15:17:19] [I] Inputs:\n",
      "[04/10/2022-15:17:19] [I] === Reporting Options ===\n",
      "[04/10/2022-15:17:19] [I] Verbose: Enabled\n",
      "[04/10/2022-15:17:19] [I] Averages: 10 inferences\n",
      "[04/10/2022-15:17:19] [I] Percentile: 99\n",
      "[04/10/2022-15:17:19] [I] Dump refittable layers:Disabled\n",
      "[04/10/2022-15:17:19] [I] Dump output: Disabled\n",
      "[04/10/2022-15:17:19] [I] Profile: Disabled\n",
      "[04/10/2022-15:17:19] [I] Export timing to JSON file: \n",
      "[04/10/2022-15:17:19] [I] Export output to JSON file: \n",
      "[04/10/2022-15:17:19] [I] Export profile to JSON file: \n",
      "[04/10/2022-15:17:19] [I] \n",
      "[04/10/2022-15:17:19] [I] === Device Information ===\n",
      "[04/10/2022-15:17:19] [I] Selected Device: NVIDIA Tegra X1\n",
      "[04/10/2022-15:17:19] [I] Compute Capability: 5.3\n",
      "[04/10/2022-15:17:19] [I] SMs: 1\n",
      "[04/10/2022-15:17:19] [I] Compute Clock Rate: 0.9216 GHz\n",
      "[04/10/2022-15:17:19] [I] Device Global Memory: 3964 MiB\n",
      "[04/10/2022-15:17:19] [I] Shared Memory per SM: 64 KiB\n",
      "[04/10/2022-15:17:19] [I] Memory Bus Width: 64 bits (ECC disabled)\n",
      "[04/10/2022-15:17:19] [I] Memory Clock Rate: 0.01275 GHz\n",
      "[04/10/2022-15:17:19] [I] \n",
      "[04/10/2022-15:17:19] [I] TensorRT version: 8001\n",
      "[04/10/2022-15:17:19] [V] [TRT] Registered plugin creator - ::GridAnchor_TRT version 1\n",
      "[04/10/2022-15:17:19] [V] [TRT] Registered plugin creator - ::GridAnchorRect_TRT version 1\n",
      "[04/10/2022-15:17:19] [V] [TRT] Registered plugin creator - ::NMS_TRT version 1\n",
      "[04/10/2022-15:17:19] [V] [TRT] Registered plugin creator - ::Reorg_TRT version 1\n",
      "[04/10/2022-15:17:19] [V] [TRT] Registered plugin creator - ::Region_TRT version 1\n",
      "[04/10/2022-15:17:19] [V] [TRT] Registered plugin creator - ::Clip_TRT version 1\n",
      "[04/10/2022-15:17:19] [V] [TRT] Registered plugin creator - ::LReLU_TRT version 1\n",
      "[04/10/2022-15:17:19] [V] [TRT] Registered plugin creator - ::PriorBox_TRT version 1\n",
      "[04/10/2022-15:17:19] [V] [TRT] Registered plugin creator - ::Normalize_TRT version 1\n",
      "[04/10/2022-15:17:19] [V] [TRT] Registered plugin creator - ::ScatterND version 1\n",
      "[04/10/2022-15:17:19] [V] [TRT] Registered plugin creator - ::RPROI_TRT version 1\n",
      "[04/10/2022-15:17:19] [V] [TRT] Registered plugin creator - ::BatchedNMS_TRT version 1\n",
      "[04/10/2022-15:17:19] [V] [TRT] Registered plugin creator - ::BatchedNMSDynamic_TRT version 1\n",
      "[04/10/2022-15:17:19] [V] [TRT] Registered plugin creator - ::FlattenConcat_TRT version 1\n",
      "[04/10/2022-15:17:19] [V] [TRT] Registered plugin creator - ::CropAndResize version 1\n",
      "[04/10/2022-15:17:19] [V] [TRT] Registered plugin creator - ::DetectionLayer_TRT version 1\n",
      "[04/10/2022-15:17:19] [V] [TRT] Registered plugin creator - ::EfficientNMS_ONNX_TRT version 1\n",
      "[04/10/2022-15:17:19] [V] [TRT] Registered plugin creator - ::EfficientNMS_TRT version 1\n",
      "[04/10/2022-15:17:19] [V] [TRT] Registered plugin creator - ::Proposal version 1\n",
      "[04/10/2022-15:17:19] [V] [TRT] Registered plugin creator - ::ProposalLayer_TRT version 1\n",
      "[04/10/2022-15:17:19] [V] [TRT] Registered plugin creator - ::PyramidROIAlign_TRT version 1\n",
      "[04/10/2022-15:17:19] [V] [TRT] Registered plugin creator - ::ResizeNearest_TRT version 1\n",
      "[04/10/2022-15:17:19] [V] [TRT] Registered plugin creator - ::Split version 1\n",
      "[04/10/2022-15:17:19] [V] [TRT] Registered plugin creator - ::SpecialSlice_TRT version 1\n",
      "[04/10/2022-15:17:19] [V] [TRT] Registered plugin creator - ::InstanceNormalization_TRT version 1\n",
      "[04/10/2022-15:17:22] [I] [TRT] [MemUsageChange] Init CUDA: CPU +203, GPU +0, now: CPU 221, GPU 2157 (MiB)\n",
      "[04/10/2022-15:17:22] [I] Start parsing network model\n",
      "[04/10/2022-15:17:22] [I] [TRT] ----------------------------------------------------------------\n",
      "[04/10/2022-15:17:22] [I] [TRT] Input filename:   meilleur_model_colab/meilleur_model_colab.onnx\n",
      "[04/10/2022-15:17:22] [I] [TRT] ONNX IR version:  0.0.4\n",
      "[04/10/2022-15:17:22] [I] [TRT] Opset version:    9\n",
      "[04/10/2022-15:17:22] [I] [TRT] Producer name:    tf2onnx\n",
      "[04/10/2022-15:17:22] [I] [TRT] Producer version: 1.10.0\n",
      "[04/10/2022-15:17:22] [I] [TRT] Domain:           \n",
      "[04/10/2022-15:17:22] [I] [TRT] Model version:    0\n",
      "[04/10/2022-15:17:22] [I] [TRT] Doc string:       \n",
      "[04/10/2022-15:17:22] [I] [TRT] ----------------------------------------------------------------\n",
      "[04/10/2022-15:17:22] [V] [TRT] Plugin creator already registered - ::GridAnchor_TRT version 1\n",
      "[04/10/2022-15:17:22] [V] [TRT] Plugin creator already registered - ::GridAnchorRect_TRT version 1\n",
      "[04/10/2022-15:17:22] [V] [TRT] Plugin creator already registered - ::NMS_TRT version 1\n",
      "[04/10/2022-15:17:22] [V] [TRT] Plugin creator already registered - ::Reorg_TRT version 1\n",
      "[04/10/2022-15:17:22] [V] [TRT] Plugin creator already registered - ::Region_TRT version 1\n",
      "[04/10/2022-15:17:22] [V] [TRT] Plugin creator already registered - ::Clip_TRT version 1\n",
      "[04/10/2022-15:17:22] [V] [TRT] Plugin creator already registered - ::LReLU_TRT version 1\n",
      "[04/10/2022-15:17:22] [V] [TRT] Plugin creator already registered - ::PriorBox_TRT version 1\n",
      "[04/10/2022-15:17:22] [V] [TRT] Plugin creator already registered - ::Normalize_TRT version 1\n",
      "[04/10/2022-15:17:22] [V] [TRT] Plugin creator already registered - ::ScatterND version 1\n",
      "[04/10/2022-15:17:22] [V] [TRT] Plugin creator already registered - ::RPROI_TRT version 1\n",
      "[04/10/2022-15:17:22] [V] [TRT] Plugin creator already registered - ::BatchedNMS_TRT version 1\n",
      "[04/10/2022-15:17:22] [V] [TRT] Plugin creator already registered - ::BatchedNMSDynamic_TRT version 1\n",
      "[04/10/2022-15:17:22] [V] [TRT] Plugin creator already registered - ::FlattenConcat_TRT version 1\n",
      "[04/10/2022-15:17:22] [V] [TRT] Plugin creator already registered - ::CropAndResize version 1\n",
      "[04/10/2022-15:17:22] [V] [TRT] Plugin creator already registered - ::DetectionLayer_TRT version 1\n",
      "[04/10/2022-15:17:22] [V] [TRT] Plugin creator already registered - ::EfficientNMS_ONNX_TRT version 1\n",
      "[04/10/2022-15:17:22] [V] [TRT] Plugin creator already registered - ::EfficientNMS_TRT version 1\n",
      "[04/10/2022-15:17:22] [V] [TRT] Plugin creator already registered - ::Proposal version 1\n",
      "[04/10/2022-15:17:22] [V] [TRT] Plugin creator already registered - ::ProposalLayer_TRT version 1\n",
      "[04/10/2022-15:17:22] [V] [TRT] Plugin creator already registered - ::PyramidROIAlign_TRT version 1\n",
      "[04/10/2022-15:17:22] [V] [TRT] Plugin creator already registered - ::ResizeNearest_TRT version 1\n",
      "[04/10/2022-15:17:22] [V] [TRT] Plugin creator already registered - ::Split version 1\n",
      "[04/10/2022-15:17:22] [V] [TRT] Plugin creator already registered - ::SpecialSlice_TRT version 1\n",
      "[04/10/2022-15:17:22] [V] [TRT] Plugin creator already registered - ::InstanceNormalization_TRT version 1\n",
      "[04/10/2022-15:17:22] [V] [TRT] Adding network input: data with dtype: float32, dimensions: (1, 224, 224, 3)\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering tensor: data for ONNX tensor: data\n",
      "[04/10/2022-15:17:22] [V] [TRT] Importing initializer: StatefulPartitionedCall/model_1/stage4_unit2_conv2/Conv2D/ReadVariableOp:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Importing initializer: StatefulPartitionedCall/model_1/stage4_unit2_conv1/Conv2D_weights_fused_bn\n",
      "[04/10/2022-15:17:22] [V] [TRT] Importing initializer: StatefulPartitionedCall/model_1/stage4_unit2_conv1/Conv2D_bias_fused_bn\n",
      "[04/10/2022-15:17:22] [V] [TRT] Importing initializer: StatefulPartitionedCall/model_1/stage4_unit2_bn1/ReadVariableOp_1:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Importing initializer: StatefulPartitionedCall/model_1/stage4_unit2_bn1/ReadVariableOp:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Importing initializer: StatefulPartitionedCall/model_1/stage4_unit2_bn1/FusedBatchNormV3/ReadVariableOp_1:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Importing initializer: StatefulPartitionedCall/model_1/stage4_unit2_bn1/FusedBatchNormV3/ReadVariableOp:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Importing initializer: StatefulPartitionedCall/model_1/stage4_unit1_sc/Conv2D/ReadVariableOp:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Importing initializer: StatefulPartitionedCall/model_1/stage4_unit1_conv2/Conv2D/ReadVariableOp:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Importing initializer: StatefulPartitionedCall/model_1/stage4_unit1_conv1/Conv2D_weights_fused_bn\n",
      "[04/10/2022-15:17:22] [V] [TRT] Importing initializer: StatefulPartitionedCall/model_1/stage4_unit1_conv1/Conv2D_bias_fused_bn\n",
      "[04/10/2022-15:17:22] [V] [TRT] Importing initializer: StatefulPartitionedCall/model_1/stage4_unit1_bn1/ReadVariableOp_1:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Importing initializer: StatefulPartitionedCall/model_1/stage4_unit1_bn1/ReadVariableOp:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Importing initializer: StatefulPartitionedCall/model_1/stage4_unit1_bn1/FusedBatchNormV3/ReadVariableOp_1:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Importing initializer: StatefulPartitionedCall/model_1/stage4_unit1_bn1/FusedBatchNormV3/ReadVariableOp:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Importing initializer: StatefulPartitionedCall/model_1/stage3_unit2_conv2/Conv2D/ReadVariableOp:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Importing initializer: StatefulPartitionedCall/model_1/stage3_unit2_conv1/Conv2D_weights_fused_bn\n",
      "[04/10/2022-15:17:22] [V] [TRT] Importing initializer: StatefulPartitionedCall/model_1/stage3_unit2_conv1/Conv2D_bias_fused_bn\n",
      "[04/10/2022-15:17:22] [V] [TRT] Importing initializer: StatefulPartitionedCall/model_1/stage3_unit2_bn1/ReadVariableOp_1:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Importing initializer: StatefulPartitionedCall/model_1/stage3_unit2_bn1/ReadVariableOp:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Importing initializer: StatefulPartitionedCall/model_1/stage3_unit2_bn1/FusedBatchNormV3/ReadVariableOp_1:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Importing initializer: StatefulPartitionedCall/model_1/stage3_unit2_bn1/FusedBatchNormV3/ReadVariableOp:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Importing initializer: StatefulPartitionedCall/model_1/stage3_unit1_sc/Conv2D/ReadVariableOp:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Importing initializer: StatefulPartitionedCall/model_1/stage3_unit1_conv2/Conv2D/ReadVariableOp:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Importing initializer: StatefulPartitionedCall/model_1/stage3_unit1_conv1/Conv2D_weights_fused_bn\n",
      "[04/10/2022-15:17:22] [V] [TRT] Importing initializer: StatefulPartitionedCall/model_1/stage3_unit1_conv1/Conv2D_bias_fused_bn\n",
      "[04/10/2022-15:17:22] [V] [TRT] Importing initializer: StatefulPartitionedCall/model_1/stage3_unit1_bn1/ReadVariableOp_1:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Importing initializer: StatefulPartitionedCall/model_1/stage3_unit1_bn1/ReadVariableOp:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Importing initializer: StatefulPartitionedCall/model_1/stage3_unit1_bn1/FusedBatchNormV3/ReadVariableOp_1:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Importing initializer: StatefulPartitionedCall/model_1/stage3_unit1_bn1/FusedBatchNormV3/ReadVariableOp:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Importing initializer: StatefulPartitionedCall/model_1/stage2_unit2_conv2/Conv2D/ReadVariableOp:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Importing initializer: StatefulPartitionedCall/model_1/stage2_unit2_conv1/Conv2D_weights_fused_bn\n",
      "[04/10/2022-15:17:22] [V] [TRT] Importing initializer: StatefulPartitionedCall/model_1/stage2_unit2_conv1/Conv2D_bias_fused_bn\n",
      "[04/10/2022-15:17:22] [V] [TRT] Importing initializer: StatefulPartitionedCall/model_1/stage2_unit2_bn1/ReadVariableOp_1:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Importing initializer: StatefulPartitionedCall/model_1/stage2_unit2_bn1/ReadVariableOp:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Importing initializer: StatefulPartitionedCall/model_1/stage2_unit2_bn1/FusedBatchNormV3/ReadVariableOp_1:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Importing initializer: StatefulPartitionedCall/model_1/stage2_unit2_bn1/FusedBatchNormV3/ReadVariableOp:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Importing initializer: StatefulPartitionedCall/model_1/stage2_unit1_sc/Conv2D/ReadVariableOp:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Importing initializer: StatefulPartitionedCall/model_1/stage2_unit1_conv2/Conv2D/ReadVariableOp:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Importing initializer: StatefulPartitionedCall/model_1/stage2_unit1_conv1/Conv2D_weights_fused_bn\n",
      "[04/10/2022-15:17:22] [V] [TRT] Importing initializer: StatefulPartitionedCall/model_1/stage2_unit1_conv1/Conv2D_bias_fused_bn\n",
      "[04/10/2022-15:17:22] [V] [TRT] Importing initializer: StatefulPartitionedCall/model_1/stage2_unit1_bn1/ReadVariableOp_1:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Importing initializer: StatefulPartitionedCall/model_1/stage2_unit1_bn1/ReadVariableOp:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Importing initializer: StatefulPartitionedCall/model_1/stage2_unit1_bn1/FusedBatchNormV3/ReadVariableOp_1:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Importing initializer: StatefulPartitionedCall/model_1/stage2_unit1_bn1/FusedBatchNormV3/ReadVariableOp:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Importing initializer: StatefulPartitionedCall/model_1/stage1_unit2_conv2/Conv2D/ReadVariableOp:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Importing initializer: StatefulPartitionedCall/model_1/stage1_unit2_conv1/Conv2D_weights_fused_bn\n",
      "[04/10/2022-15:17:22] [V] [TRT] Importing initializer: StatefulPartitionedCall/model_1/stage1_unit2_conv1/Conv2D_bias_fused_bn\n",
      "[04/10/2022-15:17:22] [V] [TRT] Importing initializer: StatefulPartitionedCall/model_1/stage1_unit2_bn1/ReadVariableOp_1:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Importing initializer: StatefulPartitionedCall/model_1/stage1_unit2_bn1/ReadVariableOp:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Importing initializer: StatefulPartitionedCall/model_1/stage1_unit2_bn1/FusedBatchNormV3/ReadVariableOp_1:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Importing initializer: StatefulPartitionedCall/model_1/stage1_unit2_bn1/FusedBatchNormV3/ReadVariableOp:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Importing initializer: StatefulPartitionedCall/model_1/stage1_unit1_sc/Conv2D/ReadVariableOp:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Importing initializer: StatefulPartitionedCall/model_1/stage1_unit1_conv2/Conv2D/ReadVariableOp:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Importing initializer: StatefulPartitionedCall/model_1/stage1_unit1_conv1/Conv2D_weights_fused_bn\n",
      "[04/10/2022-15:17:22] [V] [TRT] Importing initializer: StatefulPartitionedCall/model_1/stage1_unit1_conv1/Conv2D_bias_fused_bn\n",
      "[04/10/2022-15:17:22] [V] [TRT] Importing initializer: StatefulPartitionedCall/model_1/stage1_unit1_bn1/ReadVariableOp_1:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Importing initializer: StatefulPartitionedCall/model_1/stage1_unit1_bn1/ReadVariableOp:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Importing initializer: StatefulPartitionedCall/model_1/stage1_unit1_bn1/FusedBatchNormV3/ReadVariableOp_1:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Importing initializer: StatefulPartitionedCall/model_1/stage1_unit1_bn1/FusedBatchNormV3/ReadVariableOp:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Importing initializer: StatefulPartitionedCall/model_1/dense/MatMul/ReadVariableOp:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Importing initializer: StatefulPartitionedCall/model_1/dense/BiasAdd/ReadVariableOp:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Importing initializer: StatefulPartitionedCall/model_1/conv0/Conv2D/ReadVariableOp:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Importing initializer: StatefulPartitionedCall/model_1/bn_data/ReadVariableOp:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Importing initializer: StatefulPartitionedCall/model_1/bn_data/FusedBatchNormV3/ReadVariableOp_1:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Importing initializer: StatefulPartitionedCall/model_1/bn_data/FusedBatchNormV3/ReadVariableOp:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Importing initializer: StatefulPartitionedCall/model_1/bn1/ReadVariableOp_1:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Importing initializer: StatefulPartitionedCall/model_1/bn1/ReadVariableOp:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Importing initializer: StatefulPartitionedCall/model_1/bn1/FusedBatchNormV3/ReadVariableOp_1:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Importing initializer: StatefulPartitionedCall/model_1/bn1/FusedBatchNormV3/ReadVariableOp:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Importing initializer: StatefulPartitionedCall/model_1/bn0/ReadVariableOp_1:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Importing initializer: StatefulPartitionedCall/model_1/bn0/ReadVariableOp:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Importing initializer: StatefulPartitionedCall/model_1/bn0/FusedBatchNormV3/ReadVariableOp_1:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Importing initializer: StatefulPartitionedCall/model_1/bn0/FusedBatchNormV3/ReadVariableOp:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Importing initializer: Func/StatefulPartitionedCall/input/_1:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Parsing node: StatefulPartitionedCall/model_1/bn_data/FusedBatchNormV3__74 [Transpose]\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: data\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/bn_data/FusedBatchNormV3__74 [Transpose] inputs: [data -> (1, 224, 224, 3)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering layer: StatefulPartitionedCall/model_1/bn_data/FusedBatchNormV3__74 for ONNX node: StatefulPartitionedCall/model_1/bn_data/FusedBatchNormV3__74\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering tensor: StatefulPartitionedCall/model_1/bn_data/FusedBatchNormV3__74:0 for ONNX tensor: StatefulPartitionedCall/model_1/bn_data/FusedBatchNormV3__74:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/bn_data/FusedBatchNormV3__74 [Transpose] outputs: [StatefulPartitionedCall/model_1/bn_data/FusedBatchNormV3__74:0 -> (1, 3, 224, 224)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Parsing node: StatefulPartitionedCall/model_1/bn_data/FusedBatchNormV3 [BatchNormalization]\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/bn_data/FusedBatchNormV3__74:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: Func/StatefulPartitionedCall/input/_1:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/bn_data/ReadVariableOp:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/bn_data/FusedBatchNormV3/ReadVariableOp:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/bn_data/FusedBatchNormV3/ReadVariableOp_1:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/bn_data/FusedBatchNormV3 [BatchNormalization] inputs: [StatefulPartitionedCall/model_1/bn_data/FusedBatchNormV3__74:0 -> (1, 3, 224, 224)[FLOAT]], [Func/StatefulPartitionedCall/input/_1:0 -> (3)[FLOAT]], [StatefulPartitionedCall/model_1/bn_data/ReadVariableOp:0 -> (3)[FLOAT]], [StatefulPartitionedCall/model_1/bn_data/FusedBatchNormV3/ReadVariableOp:0 -> (3)[FLOAT]], [StatefulPartitionedCall/model_1/bn_data/FusedBatchNormV3/ReadVariableOp_1:0 -> (3)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering layer: StatefulPartitionedCall/model_1/bn_data/FusedBatchNormV3 for ONNX node: StatefulPartitionedCall/model_1/bn_data/FusedBatchNormV3\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering tensor: StatefulPartitionedCall/model_1/bn_data/FusedBatchNormV3:0 for ONNX tensor: StatefulPartitionedCall/model_1/bn_data/FusedBatchNormV3:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/bn_data/FusedBatchNormV3 [BatchNormalization] outputs: [StatefulPartitionedCall/model_1/bn_data/FusedBatchNormV3:0 -> (1, 3, 224, 224)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Parsing node: StatefulPartitionedCall/model_1/conv0/Conv2D [Conv]\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/bn_data/FusedBatchNormV3:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/conv0/Conv2D/ReadVariableOp:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/conv0/Conv2D [Conv] inputs: [StatefulPartitionedCall/model_1/bn_data/FusedBatchNormV3:0 -> (1, 3, 224, 224)[FLOAT]], [StatefulPartitionedCall/model_1/conv0/Conv2D/ReadVariableOp:0 -> (64, 3, 7, 7)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Convolution input dimensions: (1, 3, 224, 224)\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering layer: StatefulPartitionedCall/model_1/conv0/Conv2D for ONNX node: StatefulPartitionedCall/model_1/conv0/Conv2D\n",
      "[04/10/2022-15:17:22] [V] [TRT] Using kernel: (7, 7), strides: (2, 2), prepadding: (3, 3), postpadding: (3, 3), dilations: (1, 1), numOutputs: 64\n",
      "[04/10/2022-15:17:22] [V] [TRT] Convolution output dimensions: (1, 64, 112, 112)\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering tensor: StatefulPartitionedCall/model_1/conv0/Conv2D:0 for ONNX tensor: StatefulPartitionedCall/model_1/conv0/Conv2D:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/conv0/Conv2D [Conv] outputs: [StatefulPartitionedCall/model_1/conv0/Conv2D:0 -> (1, 64, 112, 112)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Parsing node: StatefulPartitionedCall/model_1/bn0/FusedBatchNormV3 [BatchNormalization]\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/conv0/Conv2D:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/bn0/ReadVariableOp:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/bn0/ReadVariableOp_1:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/bn0/FusedBatchNormV3/ReadVariableOp:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/bn0/FusedBatchNormV3/ReadVariableOp_1:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/bn0/FusedBatchNormV3 [BatchNormalization] inputs: [StatefulPartitionedCall/model_1/conv0/Conv2D:0 -> (1, 64, 112, 112)[FLOAT]], [StatefulPartitionedCall/model_1/bn0/ReadVariableOp:0 -> (64)[FLOAT]], [StatefulPartitionedCall/model_1/bn0/ReadVariableOp_1:0 -> (64)[FLOAT]], [StatefulPartitionedCall/model_1/bn0/FusedBatchNormV3/ReadVariableOp:0 -> (64)[FLOAT]], [StatefulPartitionedCall/model_1/bn0/FusedBatchNormV3/ReadVariableOp_1:0 -> (64)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering layer: StatefulPartitionedCall/model_1/bn0/FusedBatchNormV3 for ONNX node: StatefulPartitionedCall/model_1/bn0/FusedBatchNormV3\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering tensor: StatefulPartitionedCall/model_1/bn0/FusedBatchNormV3:0 for ONNX tensor: StatefulPartitionedCall/model_1/bn0/FusedBatchNormV3:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/bn0/FusedBatchNormV3 [BatchNormalization] outputs: [StatefulPartitionedCall/model_1/bn0/FusedBatchNormV3:0 -> (1, 64, 112, 112)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Parsing node: StatefulPartitionedCall/model_1/relu0/Relu [Relu]\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/bn0/FusedBatchNormV3:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/relu0/Relu [Relu] inputs: [StatefulPartitionedCall/model_1/bn0/FusedBatchNormV3:0 -> (1, 64, 112, 112)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering layer: StatefulPartitionedCall/model_1/relu0/Relu for ONNX node: StatefulPartitionedCall/model_1/relu0/Relu\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering tensor: StatefulPartitionedCall/model_1/relu0/Relu:0 for ONNX tensor: StatefulPartitionedCall/model_1/relu0/Relu:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/relu0/Relu [Relu] outputs: [StatefulPartitionedCall/model_1/relu0/Relu:0 -> (1, 64, 112, 112)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Parsing node: StatefulPartitionedCall/model_1/zero_padding2d_1/Pad [Pad]\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/relu0/Relu:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/zero_padding2d_1/Pad [Pad] inputs: [StatefulPartitionedCall/model_1/relu0/Relu:0 -> (1, 64, 112, 112)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering layer: StatefulPartitionedCall/model_1/zero_padding2d_1/Pad for ONNX node: StatefulPartitionedCall/model_1/zero_padding2d_1/Pad\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering tensor: StatefulPartitionedCall/model_1/zero_padding2d_1/Pad:0 for ONNX tensor: StatefulPartitionedCall/model_1/zero_padding2d_1/Pad:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/zero_padding2d_1/Pad [Pad] outputs: [StatefulPartitionedCall/model_1/zero_padding2d_1/Pad:0 -> (1, 64, 114, 114)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Parsing node: StatefulPartitionedCall/model_1/pooling0/MaxPool [MaxPool]\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/zero_padding2d_1/Pad:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/pooling0/MaxPool [MaxPool] inputs: [StatefulPartitionedCall/model_1/zero_padding2d_1/Pad:0 -> (1, 64, 114, 114)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering layer: StatefulPartitionedCall/model_1/pooling0/MaxPool for ONNX node: StatefulPartitionedCall/model_1/pooling0/MaxPool\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering tensor: StatefulPartitionedCall/model_1/pooling0/MaxPool:0 for ONNX tensor: StatefulPartitionedCall/model_1/pooling0/MaxPool:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/pooling0/MaxPool [MaxPool] outputs: [StatefulPartitionedCall/model_1/pooling0/MaxPool:0 -> (1, 64, 56, 56)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Parsing node: StatefulPartitionedCall/model_1/stage1_unit1_bn1/FusedBatchNormV3 [BatchNormalization]\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/pooling0/MaxPool:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage1_unit1_bn1/ReadVariableOp:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage1_unit1_bn1/ReadVariableOp_1:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage1_unit1_bn1/FusedBatchNormV3/ReadVariableOp:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage1_unit1_bn1/FusedBatchNormV3/ReadVariableOp_1:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_bn1/FusedBatchNormV3 [BatchNormalization] inputs: [StatefulPartitionedCall/model_1/pooling0/MaxPool:0 -> (1, 64, 56, 56)[FLOAT]], [StatefulPartitionedCall/model_1/stage1_unit1_bn1/ReadVariableOp:0 -> (64)[FLOAT]], [StatefulPartitionedCall/model_1/stage1_unit1_bn1/ReadVariableOp_1:0 -> (64)[FLOAT]], [StatefulPartitionedCall/model_1/stage1_unit1_bn1/FusedBatchNormV3/ReadVariableOp:0 -> (64)[FLOAT]], [StatefulPartitionedCall/model_1/stage1_unit1_bn1/FusedBatchNormV3/ReadVariableOp_1:0 -> (64)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering layer: StatefulPartitionedCall/model_1/stage1_unit1_bn1/FusedBatchNormV3 for ONNX node: StatefulPartitionedCall/model_1/stage1_unit1_bn1/FusedBatchNormV3\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering tensor: StatefulPartitionedCall/model_1/stage1_unit1_bn1/FusedBatchNormV3:0 for ONNX tensor: StatefulPartitionedCall/model_1/stage1_unit1_bn1/FusedBatchNormV3:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_bn1/FusedBatchNormV3 [BatchNormalization] outputs: [StatefulPartitionedCall/model_1/stage1_unit1_bn1/FusedBatchNormV3:0 -> (1, 64, 56, 56)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Parsing node: StatefulPartitionedCall/model_1/stage1_unit1_relu1/Relu [Relu]\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage1_unit1_bn1/FusedBatchNormV3:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_relu1/Relu [Relu] inputs: [StatefulPartitionedCall/model_1/stage1_unit1_bn1/FusedBatchNormV3:0 -> (1, 64, 56, 56)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering layer: StatefulPartitionedCall/model_1/stage1_unit1_relu1/Relu for ONNX node: StatefulPartitionedCall/model_1/stage1_unit1_relu1/Relu\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering tensor: StatefulPartitionedCall/model_1/stage1_unit1_relu1/Relu:0 for ONNX tensor: StatefulPartitionedCall/model_1/stage1_unit1_relu1/Relu:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_relu1/Relu [Relu] outputs: [StatefulPartitionedCall/model_1/stage1_unit1_relu1/Relu:0 -> (1, 64, 56, 56)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Parsing node: StatefulPartitionedCall/model_1/stage1_unit1_sc/Conv2D [Conv]\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage1_unit1_relu1/Relu:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage1_unit1_sc/Conv2D/ReadVariableOp:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_sc/Conv2D [Conv] inputs: [StatefulPartitionedCall/model_1/stage1_unit1_relu1/Relu:0 -> (1, 64, 56, 56)[FLOAT]], [StatefulPartitionedCall/model_1/stage1_unit1_sc/Conv2D/ReadVariableOp:0 -> (64, 64, 1, 1)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Convolution input dimensions: (1, 64, 56, 56)\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering layer: StatefulPartitionedCall/model_1/stage1_unit1_sc/Conv2D for ONNX node: StatefulPartitionedCall/model_1/stage1_unit1_sc/Conv2D\n",
      "[04/10/2022-15:17:22] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 64\n",
      "[04/10/2022-15:17:22] [V] [TRT] Convolution output dimensions: (1, 64, 56, 56)\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering tensor: StatefulPartitionedCall/model_1/stage1_unit1_sc/Conv2D:0 for ONNX tensor: StatefulPartitionedCall/model_1/stage1_unit1_sc/Conv2D:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_sc/Conv2D [Conv] outputs: [StatefulPartitionedCall/model_1/stage1_unit1_sc/Conv2D:0 -> (1, 64, 56, 56)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Parsing node: StatefulPartitionedCall/model_1/stage1_unit1_conv1/Conv2D [Conv]\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage1_unit1_relu1/Relu:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage1_unit1_conv1/Conv2D_weights_fused_bn\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage1_unit1_conv1/Conv2D_bias_fused_bn\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_conv1/Conv2D [Conv] inputs: [StatefulPartitionedCall/model_1/stage1_unit1_relu1/Relu:0 -> (1, 64, 56, 56)[FLOAT]], [StatefulPartitionedCall/model_1/stage1_unit1_conv1/Conv2D_weights_fused_bn -> (64, 64, 3, 3)[FLOAT]], [StatefulPartitionedCall/model_1/stage1_unit1_conv1/Conv2D_bias_fused_bn -> (64)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Convolution input dimensions: (1, 64, 56, 56)\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering layer: StatefulPartitionedCall/model_1/stage1_unit1_conv1/Conv2D for ONNX node: StatefulPartitionedCall/model_1/stage1_unit1_conv1/Conv2D\n",
      "[04/10/2022-15:17:22] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64\n",
      "[04/10/2022-15:17:22] [V] [TRT] Convolution output dimensions: (1, 64, 56, 56)\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering tensor: StatefulPartitionedCall/model_1/stage1_unit1_bn2/FusedBatchNormV3:0 for ONNX tensor: StatefulPartitionedCall/model_1/stage1_unit1_bn2/FusedBatchNormV3:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_conv1/Conv2D [Conv] outputs: [StatefulPartitionedCall/model_1/stage1_unit1_bn2/FusedBatchNormV3:0 -> (1, 64, 56, 56)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Parsing node: StatefulPartitionedCall/model_1/stage1_unit1_relu2/Relu [Relu]\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage1_unit1_bn2/FusedBatchNormV3:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_relu2/Relu [Relu] inputs: [StatefulPartitionedCall/model_1/stage1_unit1_bn2/FusedBatchNormV3:0 -> (1, 64, 56, 56)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering layer: StatefulPartitionedCall/model_1/stage1_unit1_relu2/Relu for ONNX node: StatefulPartitionedCall/model_1/stage1_unit1_relu2/Relu\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering tensor: StatefulPartitionedCall/model_1/stage1_unit1_relu2/Relu:0 for ONNX tensor: StatefulPartitionedCall/model_1/stage1_unit1_relu2/Relu:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_relu2/Relu [Relu] outputs: [StatefulPartitionedCall/model_1/stage1_unit1_relu2/Relu:0 -> (1, 64, 56, 56)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Parsing node: StatefulPartitionedCall/model_1/stage1_unit1_conv2/Conv2D [Conv]\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage1_unit1_relu2/Relu:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage1_unit1_conv2/Conv2D/ReadVariableOp:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_conv2/Conv2D [Conv] inputs: [StatefulPartitionedCall/model_1/stage1_unit1_relu2/Relu:0 -> (1, 64, 56, 56)[FLOAT]], [StatefulPartitionedCall/model_1/stage1_unit1_conv2/Conv2D/ReadVariableOp:0 -> (64, 64, 3, 3)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Convolution input dimensions: (1, 64, 56, 56)\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering layer: StatefulPartitionedCall/model_1/stage1_unit1_conv2/Conv2D for ONNX node: StatefulPartitionedCall/model_1/stage1_unit1_conv2/Conv2D\n",
      "[04/10/2022-15:17:22] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64\n",
      "[04/10/2022-15:17:22] [V] [TRT] Convolution output dimensions: (1, 64, 56, 56)\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering tensor: StatefulPartitionedCall/model_1/stage1_unit1_conv2/Conv2D:0 for ONNX tensor: StatefulPartitionedCall/model_1/stage1_unit1_conv2/Conv2D:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_conv2/Conv2D [Conv] outputs: [StatefulPartitionedCall/model_1/stage1_unit1_conv2/Conv2D:0 -> (1, 64, 56, 56)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Parsing node: StatefulPartitionedCall/model_1/add/add [Add]\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage1_unit1_conv2/Conv2D:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage1_unit1_sc/Conv2D:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/add/add [Add] inputs: [StatefulPartitionedCall/model_1/stage1_unit1_conv2/Conv2D:0 -> (1, 64, 56, 56)[FLOAT]], [StatefulPartitionedCall/model_1/stage1_unit1_sc/Conv2D:0 -> (1, 64, 56, 56)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering layer: StatefulPartitionedCall/model_1/add/add for ONNX node: StatefulPartitionedCall/model_1/add/add\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering tensor: StatefulPartitionedCall/model_1/add/add:0 for ONNX tensor: StatefulPartitionedCall/model_1/add/add:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/add/add [Add] outputs: [StatefulPartitionedCall/model_1/add/add:0 -> (1, 64, 56, 56)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Parsing node: StatefulPartitionedCall/model_1/stage1_unit2_bn1/FusedBatchNormV3 [BatchNormalization]\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/add/add:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage1_unit2_bn1/ReadVariableOp:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage1_unit2_bn1/ReadVariableOp_1:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage1_unit2_bn1/FusedBatchNormV3/ReadVariableOp:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage1_unit2_bn1/FusedBatchNormV3/ReadVariableOp_1:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit2_bn1/FusedBatchNormV3 [BatchNormalization] inputs: [StatefulPartitionedCall/model_1/add/add:0 -> (1, 64, 56, 56)[FLOAT]], [StatefulPartitionedCall/model_1/stage1_unit2_bn1/ReadVariableOp:0 -> (64)[FLOAT]], [StatefulPartitionedCall/model_1/stage1_unit2_bn1/ReadVariableOp_1:0 -> (64)[FLOAT]], [StatefulPartitionedCall/model_1/stage1_unit2_bn1/FusedBatchNormV3/ReadVariableOp:0 -> (64)[FLOAT]], [StatefulPartitionedCall/model_1/stage1_unit2_bn1/FusedBatchNormV3/ReadVariableOp_1:0 -> (64)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering layer: StatefulPartitionedCall/model_1/stage1_unit2_bn1/FusedBatchNormV3 for ONNX node: StatefulPartitionedCall/model_1/stage1_unit2_bn1/FusedBatchNormV3\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering tensor: StatefulPartitionedCall/model_1/stage1_unit2_bn1/FusedBatchNormV3:0 for ONNX tensor: StatefulPartitionedCall/model_1/stage1_unit2_bn1/FusedBatchNormV3:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit2_bn1/FusedBatchNormV3 [BatchNormalization] outputs: [StatefulPartitionedCall/model_1/stage1_unit2_bn1/FusedBatchNormV3:0 -> (1, 64, 56, 56)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Parsing node: StatefulPartitionedCall/model_1/stage1_unit2_relu1/Relu [Relu]\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage1_unit2_bn1/FusedBatchNormV3:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit2_relu1/Relu [Relu] inputs: [StatefulPartitionedCall/model_1/stage1_unit2_bn1/FusedBatchNormV3:0 -> (1, 64, 56, 56)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering layer: StatefulPartitionedCall/model_1/stage1_unit2_relu1/Relu for ONNX node: StatefulPartitionedCall/model_1/stage1_unit2_relu1/Relu\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering tensor: StatefulPartitionedCall/model_1/stage1_unit2_relu1/Relu:0 for ONNX tensor: StatefulPartitionedCall/model_1/stage1_unit2_relu1/Relu:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit2_relu1/Relu [Relu] outputs: [StatefulPartitionedCall/model_1/stage1_unit2_relu1/Relu:0 -> (1, 64, 56, 56)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Parsing node: StatefulPartitionedCall/model_1/stage1_unit2_conv1/Conv2D [Conv]\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage1_unit2_relu1/Relu:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage1_unit2_conv1/Conv2D_weights_fused_bn\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage1_unit2_conv1/Conv2D_bias_fused_bn\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit2_conv1/Conv2D [Conv] inputs: [StatefulPartitionedCall/model_1/stage1_unit2_relu1/Relu:0 -> (1, 64, 56, 56)[FLOAT]], [StatefulPartitionedCall/model_1/stage1_unit2_conv1/Conv2D_weights_fused_bn -> (64, 64, 3, 3)[FLOAT]], [StatefulPartitionedCall/model_1/stage1_unit2_conv1/Conv2D_bias_fused_bn -> (64)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Convolution input dimensions: (1, 64, 56, 56)\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering layer: StatefulPartitionedCall/model_1/stage1_unit2_conv1/Conv2D for ONNX node: StatefulPartitionedCall/model_1/stage1_unit2_conv1/Conv2D\n",
      "[04/10/2022-15:17:22] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64\n",
      "[04/10/2022-15:17:22] [V] [TRT] Convolution output dimensions: (1, 64, 56, 56)\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering tensor: StatefulPartitionedCall/model_1/stage1_unit2_bn2/FusedBatchNormV3:0 for ONNX tensor: StatefulPartitionedCall/model_1/stage1_unit2_bn2/FusedBatchNormV3:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit2_conv1/Conv2D [Conv] outputs: [StatefulPartitionedCall/model_1/stage1_unit2_bn2/FusedBatchNormV3:0 -> (1, 64, 56, 56)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Parsing node: StatefulPartitionedCall/model_1/stage1_unit2_relu2/Relu [Relu]\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage1_unit2_bn2/FusedBatchNormV3:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit2_relu2/Relu [Relu] inputs: [StatefulPartitionedCall/model_1/stage1_unit2_bn2/FusedBatchNormV3:0 -> (1, 64, 56, 56)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering layer: StatefulPartitionedCall/model_1/stage1_unit2_relu2/Relu for ONNX node: StatefulPartitionedCall/model_1/stage1_unit2_relu2/Relu\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering tensor: StatefulPartitionedCall/model_1/stage1_unit2_relu2/Relu:0 for ONNX tensor: StatefulPartitionedCall/model_1/stage1_unit2_relu2/Relu:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit2_relu2/Relu [Relu] outputs: [StatefulPartitionedCall/model_1/stage1_unit2_relu2/Relu:0 -> (1, 64, 56, 56)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Parsing node: StatefulPartitionedCall/model_1/stage1_unit2_conv2/Conv2D [Conv]\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage1_unit2_relu2/Relu:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage1_unit2_conv2/Conv2D/ReadVariableOp:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit2_conv2/Conv2D [Conv] inputs: [StatefulPartitionedCall/model_1/stage1_unit2_relu2/Relu:0 -> (1, 64, 56, 56)[FLOAT]], [StatefulPartitionedCall/model_1/stage1_unit2_conv2/Conv2D/ReadVariableOp:0 -> (64, 64, 3, 3)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Convolution input dimensions: (1, 64, 56, 56)\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering layer: StatefulPartitionedCall/model_1/stage1_unit2_conv2/Conv2D for ONNX node: StatefulPartitionedCall/model_1/stage1_unit2_conv2/Conv2D\n",
      "[04/10/2022-15:17:22] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64\n",
      "[04/10/2022-15:17:22] [V] [TRT] Convolution output dimensions: (1, 64, 56, 56)\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering tensor: StatefulPartitionedCall/model_1/stage1_unit2_conv2/Conv2D:0 for ONNX tensor: StatefulPartitionedCall/model_1/stage1_unit2_conv2/Conv2D:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit2_conv2/Conv2D [Conv] outputs: [StatefulPartitionedCall/model_1/stage1_unit2_conv2/Conv2D:0 -> (1, 64, 56, 56)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Parsing node: StatefulPartitionedCall/model_1/add_1/add [Add]\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage1_unit2_conv2/Conv2D:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/add/add:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/add_1/add [Add] inputs: [StatefulPartitionedCall/model_1/stage1_unit2_conv2/Conv2D:0 -> (1, 64, 56, 56)[FLOAT]], [StatefulPartitionedCall/model_1/add/add:0 -> (1, 64, 56, 56)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering layer: StatefulPartitionedCall/model_1/add_1/add for ONNX node: StatefulPartitionedCall/model_1/add_1/add\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering tensor: StatefulPartitionedCall/model_1/add_1/add:0 for ONNX tensor: StatefulPartitionedCall/model_1/add_1/add:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/add_1/add [Add] outputs: [StatefulPartitionedCall/model_1/add_1/add:0 -> (1, 64, 56, 56)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Parsing node: StatefulPartitionedCall/model_1/stage2_unit1_bn1/FusedBatchNormV3 [BatchNormalization]\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/add_1/add:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage2_unit1_bn1/ReadVariableOp:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage2_unit1_bn1/ReadVariableOp_1:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage2_unit1_bn1/FusedBatchNormV3/ReadVariableOp:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage2_unit1_bn1/FusedBatchNormV3/ReadVariableOp_1:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_bn1/FusedBatchNormV3 [BatchNormalization] inputs: [StatefulPartitionedCall/model_1/add_1/add:0 -> (1, 64, 56, 56)[FLOAT]], [StatefulPartitionedCall/model_1/stage2_unit1_bn1/ReadVariableOp:0 -> (64)[FLOAT]], [StatefulPartitionedCall/model_1/stage2_unit1_bn1/ReadVariableOp_1:0 -> (64)[FLOAT]], [StatefulPartitionedCall/model_1/stage2_unit1_bn1/FusedBatchNormV3/ReadVariableOp:0 -> (64)[FLOAT]], [StatefulPartitionedCall/model_1/stage2_unit1_bn1/FusedBatchNormV3/ReadVariableOp_1:0 -> (64)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering layer: StatefulPartitionedCall/model_1/stage2_unit1_bn1/FusedBatchNormV3 for ONNX node: StatefulPartitionedCall/model_1/stage2_unit1_bn1/FusedBatchNormV3\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering tensor: StatefulPartitionedCall/model_1/stage2_unit1_bn1/FusedBatchNormV3:0 for ONNX tensor: StatefulPartitionedCall/model_1/stage2_unit1_bn1/FusedBatchNormV3:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_bn1/FusedBatchNormV3 [BatchNormalization] outputs: [StatefulPartitionedCall/model_1/stage2_unit1_bn1/FusedBatchNormV3:0 -> (1, 64, 56, 56)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Parsing node: StatefulPartitionedCall/model_1/stage2_unit1_relu1/Relu [Relu]\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage2_unit1_bn1/FusedBatchNormV3:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_relu1/Relu [Relu] inputs: [StatefulPartitionedCall/model_1/stage2_unit1_bn1/FusedBatchNormV3:0 -> (1, 64, 56, 56)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering layer: StatefulPartitionedCall/model_1/stage2_unit1_relu1/Relu for ONNX node: StatefulPartitionedCall/model_1/stage2_unit1_relu1/Relu\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering tensor: StatefulPartitionedCall/model_1/stage2_unit1_relu1/Relu:0 for ONNX tensor: StatefulPartitionedCall/model_1/stage2_unit1_relu1/Relu:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_relu1/Relu [Relu] outputs: [StatefulPartitionedCall/model_1/stage2_unit1_relu1/Relu:0 -> (1, 64, 56, 56)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Parsing node: StatefulPartitionedCall/model_1/stage2_unit1_sc/Conv2D [Conv]\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage2_unit1_relu1/Relu:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage2_unit1_sc/Conv2D/ReadVariableOp:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_sc/Conv2D [Conv] inputs: [StatefulPartitionedCall/model_1/stage2_unit1_relu1/Relu:0 -> (1, 64, 56, 56)[FLOAT]], [StatefulPartitionedCall/model_1/stage2_unit1_sc/Conv2D/ReadVariableOp:0 -> (128, 64, 1, 1)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Convolution input dimensions: (1, 64, 56, 56)\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering layer: StatefulPartitionedCall/model_1/stage2_unit1_sc/Conv2D for ONNX node: StatefulPartitionedCall/model_1/stage2_unit1_sc/Conv2D\n",
      "[04/10/2022-15:17:22] [V] [TRT] Using kernel: (1, 1), strides: (2, 2), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 128\n",
      "[04/10/2022-15:17:22] [V] [TRT] Convolution output dimensions: (1, 128, 28, 28)\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering tensor: StatefulPartitionedCall/model_1/stage2_unit1_sc/Conv2D:0 for ONNX tensor: StatefulPartitionedCall/model_1/stage2_unit1_sc/Conv2D:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_sc/Conv2D [Conv] outputs: [StatefulPartitionedCall/model_1/stage2_unit1_sc/Conv2D:0 -> (1, 128, 28, 28)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Parsing node: StatefulPartitionedCall/model_1/stage2_unit1_conv1/Conv2D [Conv]\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage2_unit1_relu1/Relu:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage2_unit1_conv1/Conv2D_weights_fused_bn\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage2_unit1_conv1/Conv2D_bias_fused_bn\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_conv1/Conv2D [Conv] inputs: [StatefulPartitionedCall/model_1/stage2_unit1_relu1/Relu:0 -> (1, 64, 56, 56)[FLOAT]], [StatefulPartitionedCall/model_1/stage2_unit1_conv1/Conv2D_weights_fused_bn -> (128, 64, 3, 3)[FLOAT]], [StatefulPartitionedCall/model_1/stage2_unit1_conv1/Conv2D_bias_fused_bn -> (128)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Convolution input dimensions: (1, 64, 56, 56)\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering layer: StatefulPartitionedCall/model_1/stage2_unit1_conv1/Conv2D for ONNX node: StatefulPartitionedCall/model_1/stage2_unit1_conv1/Conv2D\n",
      "[04/10/2022-15:17:22] [V] [TRT] Using kernel: (3, 3), strides: (2, 2), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 128\n",
      "[04/10/2022-15:17:22] [V] [TRT] Convolution output dimensions: (1, 128, 28, 28)\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering tensor: StatefulPartitionedCall/model_1/stage2_unit1_bn2/FusedBatchNormV3:0 for ONNX tensor: StatefulPartitionedCall/model_1/stage2_unit1_bn2/FusedBatchNormV3:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_conv1/Conv2D [Conv] outputs: [StatefulPartitionedCall/model_1/stage2_unit1_bn2/FusedBatchNormV3:0 -> (1, 128, 28, 28)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Parsing node: StatefulPartitionedCall/model_1/stage2_unit1_relu2/Relu [Relu]\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage2_unit1_bn2/FusedBatchNormV3:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_relu2/Relu [Relu] inputs: [StatefulPartitionedCall/model_1/stage2_unit1_bn2/FusedBatchNormV3:0 -> (1, 128, 28, 28)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering layer: StatefulPartitionedCall/model_1/stage2_unit1_relu2/Relu for ONNX node: StatefulPartitionedCall/model_1/stage2_unit1_relu2/Relu\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering tensor: StatefulPartitionedCall/model_1/stage2_unit1_relu2/Relu:0 for ONNX tensor: StatefulPartitionedCall/model_1/stage2_unit1_relu2/Relu:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_relu2/Relu [Relu] outputs: [StatefulPartitionedCall/model_1/stage2_unit1_relu2/Relu:0 -> (1, 128, 28, 28)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Parsing node: StatefulPartitionedCall/model_1/stage2_unit1_conv2/Conv2D [Conv]\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage2_unit1_relu2/Relu:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage2_unit1_conv2/Conv2D/ReadVariableOp:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_conv2/Conv2D [Conv] inputs: [StatefulPartitionedCall/model_1/stage2_unit1_relu2/Relu:0 -> (1, 128, 28, 28)[FLOAT]], [StatefulPartitionedCall/model_1/stage2_unit1_conv2/Conv2D/ReadVariableOp:0 -> (128, 128, 3, 3)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Convolution input dimensions: (1, 128, 28, 28)\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering layer: StatefulPartitionedCall/model_1/stage2_unit1_conv2/Conv2D for ONNX node: StatefulPartitionedCall/model_1/stage2_unit1_conv2/Conv2D\n",
      "[04/10/2022-15:17:22] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 128\n",
      "[04/10/2022-15:17:22] [V] [TRT] Convolution output dimensions: (1, 128, 28, 28)\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering tensor: StatefulPartitionedCall/model_1/stage2_unit1_conv2/Conv2D:0 for ONNX tensor: StatefulPartitionedCall/model_1/stage2_unit1_conv2/Conv2D:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_conv2/Conv2D [Conv] outputs: [StatefulPartitionedCall/model_1/stage2_unit1_conv2/Conv2D:0 -> (1, 128, 28, 28)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Parsing node: StatefulPartitionedCall/model_1/add_2/add [Add]\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage2_unit1_conv2/Conv2D:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage2_unit1_sc/Conv2D:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/add_2/add [Add] inputs: [StatefulPartitionedCall/model_1/stage2_unit1_conv2/Conv2D:0 -> (1, 128, 28, 28)[FLOAT]], [StatefulPartitionedCall/model_1/stage2_unit1_sc/Conv2D:0 -> (1, 128, 28, 28)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering layer: StatefulPartitionedCall/model_1/add_2/add for ONNX node: StatefulPartitionedCall/model_1/add_2/add\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering tensor: StatefulPartitionedCall/model_1/add_2/add:0 for ONNX tensor: StatefulPartitionedCall/model_1/add_2/add:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/add_2/add [Add] outputs: [StatefulPartitionedCall/model_1/add_2/add:0 -> (1, 128, 28, 28)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Parsing node: StatefulPartitionedCall/model_1/stage2_unit2_bn1/FusedBatchNormV3 [BatchNormalization]\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/add_2/add:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage2_unit2_bn1/ReadVariableOp:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage2_unit2_bn1/ReadVariableOp_1:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage2_unit2_bn1/FusedBatchNormV3/ReadVariableOp:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage2_unit2_bn1/FusedBatchNormV3/ReadVariableOp_1:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit2_bn1/FusedBatchNormV3 [BatchNormalization] inputs: [StatefulPartitionedCall/model_1/add_2/add:0 -> (1, 128, 28, 28)[FLOAT]], [StatefulPartitionedCall/model_1/stage2_unit2_bn1/ReadVariableOp:0 -> (128)[FLOAT]], [StatefulPartitionedCall/model_1/stage2_unit2_bn1/ReadVariableOp_1:0 -> (128)[FLOAT]], [StatefulPartitionedCall/model_1/stage2_unit2_bn1/FusedBatchNormV3/ReadVariableOp:0 -> (128)[FLOAT]], [StatefulPartitionedCall/model_1/stage2_unit2_bn1/FusedBatchNormV3/ReadVariableOp_1:0 -> (128)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering layer: StatefulPartitionedCall/model_1/stage2_unit2_bn1/FusedBatchNormV3 for ONNX node: StatefulPartitionedCall/model_1/stage2_unit2_bn1/FusedBatchNormV3\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering tensor: StatefulPartitionedCall/model_1/stage2_unit2_bn1/FusedBatchNormV3:0 for ONNX tensor: StatefulPartitionedCall/model_1/stage2_unit2_bn1/FusedBatchNormV3:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit2_bn1/FusedBatchNormV3 [BatchNormalization] outputs: [StatefulPartitionedCall/model_1/stage2_unit2_bn1/FusedBatchNormV3:0 -> (1, 128, 28, 28)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Parsing node: StatefulPartitionedCall/model_1/stage2_unit2_relu1/Relu [Relu]\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage2_unit2_bn1/FusedBatchNormV3:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit2_relu1/Relu [Relu] inputs: [StatefulPartitionedCall/model_1/stage2_unit2_bn1/FusedBatchNormV3:0 -> (1, 128, 28, 28)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering layer: StatefulPartitionedCall/model_1/stage2_unit2_relu1/Relu for ONNX node: StatefulPartitionedCall/model_1/stage2_unit2_relu1/Relu\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering tensor: StatefulPartitionedCall/model_1/stage2_unit2_relu1/Relu:0 for ONNX tensor: StatefulPartitionedCall/model_1/stage2_unit2_relu1/Relu:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit2_relu1/Relu [Relu] outputs: [StatefulPartitionedCall/model_1/stage2_unit2_relu1/Relu:0 -> (1, 128, 28, 28)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Parsing node: StatefulPartitionedCall/model_1/stage2_unit2_conv1/Conv2D [Conv]\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage2_unit2_relu1/Relu:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage2_unit2_conv1/Conv2D_weights_fused_bn\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage2_unit2_conv1/Conv2D_bias_fused_bn\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit2_conv1/Conv2D [Conv] inputs: [StatefulPartitionedCall/model_1/stage2_unit2_relu1/Relu:0 -> (1, 128, 28, 28)[FLOAT]], [StatefulPartitionedCall/model_1/stage2_unit2_conv1/Conv2D_weights_fused_bn -> (128, 128, 3, 3)[FLOAT]], [StatefulPartitionedCall/model_1/stage2_unit2_conv1/Conv2D_bias_fused_bn -> (128)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Convolution input dimensions: (1, 128, 28, 28)\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering layer: StatefulPartitionedCall/model_1/stage2_unit2_conv1/Conv2D for ONNX node: StatefulPartitionedCall/model_1/stage2_unit2_conv1/Conv2D\n",
      "[04/10/2022-15:17:22] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 128\n",
      "[04/10/2022-15:17:22] [V] [TRT] Convolution output dimensions: (1, 128, 28, 28)\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering tensor: StatefulPartitionedCall/model_1/stage2_unit2_bn2/FusedBatchNormV3:0 for ONNX tensor: StatefulPartitionedCall/model_1/stage2_unit2_bn2/FusedBatchNormV3:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit2_conv1/Conv2D [Conv] outputs: [StatefulPartitionedCall/model_1/stage2_unit2_bn2/FusedBatchNormV3:0 -> (1, 128, 28, 28)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Parsing node: StatefulPartitionedCall/model_1/stage2_unit2_relu2/Relu [Relu]\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage2_unit2_bn2/FusedBatchNormV3:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit2_relu2/Relu [Relu] inputs: [StatefulPartitionedCall/model_1/stage2_unit2_bn2/FusedBatchNormV3:0 -> (1, 128, 28, 28)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering layer: StatefulPartitionedCall/model_1/stage2_unit2_relu2/Relu for ONNX node: StatefulPartitionedCall/model_1/stage2_unit2_relu2/Relu\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering tensor: StatefulPartitionedCall/model_1/stage2_unit2_relu2/Relu:0 for ONNX tensor: StatefulPartitionedCall/model_1/stage2_unit2_relu2/Relu:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit2_relu2/Relu [Relu] outputs: [StatefulPartitionedCall/model_1/stage2_unit2_relu2/Relu:0 -> (1, 128, 28, 28)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Parsing node: StatefulPartitionedCall/model_1/stage2_unit2_conv2/Conv2D [Conv]\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage2_unit2_relu2/Relu:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage2_unit2_conv2/Conv2D/ReadVariableOp:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit2_conv2/Conv2D [Conv] inputs: [StatefulPartitionedCall/model_1/stage2_unit2_relu2/Relu:0 -> (1, 128, 28, 28)[FLOAT]], [StatefulPartitionedCall/model_1/stage2_unit2_conv2/Conv2D/ReadVariableOp:0 -> (128, 128, 3, 3)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Convolution input dimensions: (1, 128, 28, 28)\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering layer: StatefulPartitionedCall/model_1/stage2_unit2_conv2/Conv2D for ONNX node: StatefulPartitionedCall/model_1/stage2_unit2_conv2/Conv2D\n",
      "[04/10/2022-15:17:22] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 128\n",
      "[04/10/2022-15:17:22] [V] [TRT] Convolution output dimensions: (1, 128, 28, 28)\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering tensor: StatefulPartitionedCall/model_1/stage2_unit2_conv2/Conv2D:0 for ONNX tensor: StatefulPartitionedCall/model_1/stage2_unit2_conv2/Conv2D:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit2_conv2/Conv2D [Conv] outputs: [StatefulPartitionedCall/model_1/stage2_unit2_conv2/Conv2D:0 -> (1, 128, 28, 28)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Parsing node: StatefulPartitionedCall/model_1/add_3/add [Add]\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage2_unit2_conv2/Conv2D:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/add_2/add:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/add_3/add [Add] inputs: [StatefulPartitionedCall/model_1/stage2_unit2_conv2/Conv2D:0 -> (1, 128, 28, 28)[FLOAT]], [StatefulPartitionedCall/model_1/add_2/add:0 -> (1, 128, 28, 28)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering layer: StatefulPartitionedCall/model_1/add_3/add for ONNX node: StatefulPartitionedCall/model_1/add_3/add\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering tensor: StatefulPartitionedCall/model_1/add_3/add:0 for ONNX tensor: StatefulPartitionedCall/model_1/add_3/add:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/add_3/add [Add] outputs: [StatefulPartitionedCall/model_1/add_3/add:0 -> (1, 128, 28, 28)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Parsing node: StatefulPartitionedCall/model_1/stage3_unit1_bn1/FusedBatchNormV3 [BatchNormalization]\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/add_3/add:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage3_unit1_bn1/ReadVariableOp:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage3_unit1_bn1/ReadVariableOp_1:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage3_unit1_bn1/FusedBatchNormV3/ReadVariableOp:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage3_unit1_bn1/FusedBatchNormV3/ReadVariableOp_1:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_bn1/FusedBatchNormV3 [BatchNormalization] inputs: [StatefulPartitionedCall/model_1/add_3/add:0 -> (1, 128, 28, 28)[FLOAT]], [StatefulPartitionedCall/model_1/stage3_unit1_bn1/ReadVariableOp:0 -> (128)[FLOAT]], [StatefulPartitionedCall/model_1/stage3_unit1_bn1/ReadVariableOp_1:0 -> (128)[FLOAT]], [StatefulPartitionedCall/model_1/stage3_unit1_bn1/FusedBatchNormV3/ReadVariableOp:0 -> (128)[FLOAT]], [StatefulPartitionedCall/model_1/stage3_unit1_bn1/FusedBatchNormV3/ReadVariableOp_1:0 -> (128)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering layer: StatefulPartitionedCall/model_1/stage3_unit1_bn1/FusedBatchNormV3 for ONNX node: StatefulPartitionedCall/model_1/stage3_unit1_bn1/FusedBatchNormV3\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering tensor: StatefulPartitionedCall/model_1/stage3_unit1_bn1/FusedBatchNormV3:0 for ONNX tensor: StatefulPartitionedCall/model_1/stage3_unit1_bn1/FusedBatchNormV3:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_bn1/FusedBatchNormV3 [BatchNormalization] outputs: [StatefulPartitionedCall/model_1/stage3_unit1_bn1/FusedBatchNormV3:0 -> (1, 128, 28, 28)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Parsing node: StatefulPartitionedCall/model_1/stage3_unit1_relu1/Relu [Relu]\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage3_unit1_bn1/FusedBatchNormV3:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_relu1/Relu [Relu] inputs: [StatefulPartitionedCall/model_1/stage3_unit1_bn1/FusedBatchNormV3:0 -> (1, 128, 28, 28)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering layer: StatefulPartitionedCall/model_1/stage3_unit1_relu1/Relu for ONNX node: StatefulPartitionedCall/model_1/stage3_unit1_relu1/Relu\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering tensor: StatefulPartitionedCall/model_1/stage3_unit1_relu1/Relu:0 for ONNX tensor: StatefulPartitionedCall/model_1/stage3_unit1_relu1/Relu:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_relu1/Relu [Relu] outputs: [StatefulPartitionedCall/model_1/stage3_unit1_relu1/Relu:0 -> (1, 128, 28, 28)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Parsing node: StatefulPartitionedCall/model_1/stage3_unit1_sc/Conv2D [Conv]\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage3_unit1_relu1/Relu:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage3_unit1_sc/Conv2D/ReadVariableOp:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_sc/Conv2D [Conv] inputs: [StatefulPartitionedCall/model_1/stage3_unit1_relu1/Relu:0 -> (1, 128, 28, 28)[FLOAT]], [StatefulPartitionedCall/model_1/stage3_unit1_sc/Conv2D/ReadVariableOp:0 -> (256, 128, 1, 1)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Convolution input dimensions: (1, 128, 28, 28)\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering layer: StatefulPartitionedCall/model_1/stage3_unit1_sc/Conv2D for ONNX node: StatefulPartitionedCall/model_1/stage3_unit1_sc/Conv2D\n",
      "[04/10/2022-15:17:22] [V] [TRT] Using kernel: (1, 1), strides: (2, 2), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 256\n",
      "[04/10/2022-15:17:22] [V] [TRT] Convolution output dimensions: (1, 256, 14, 14)\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering tensor: StatefulPartitionedCall/model_1/stage3_unit1_sc/Conv2D:0 for ONNX tensor: StatefulPartitionedCall/model_1/stage3_unit1_sc/Conv2D:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_sc/Conv2D [Conv] outputs: [StatefulPartitionedCall/model_1/stage3_unit1_sc/Conv2D:0 -> (1, 256, 14, 14)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Parsing node: StatefulPartitionedCall/model_1/stage3_unit1_conv1/Conv2D [Conv]\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage3_unit1_relu1/Relu:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage3_unit1_conv1/Conv2D_weights_fused_bn\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage3_unit1_conv1/Conv2D_bias_fused_bn\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_conv1/Conv2D [Conv] inputs: [StatefulPartitionedCall/model_1/stage3_unit1_relu1/Relu:0 -> (1, 128, 28, 28)[FLOAT]], [StatefulPartitionedCall/model_1/stage3_unit1_conv1/Conv2D_weights_fused_bn -> (256, 128, 3, 3)[FLOAT]], [StatefulPartitionedCall/model_1/stage3_unit1_conv1/Conv2D_bias_fused_bn -> (256)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Convolution input dimensions: (1, 128, 28, 28)\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering layer: StatefulPartitionedCall/model_1/stage3_unit1_conv1/Conv2D for ONNX node: StatefulPartitionedCall/model_1/stage3_unit1_conv1/Conv2D\n",
      "[04/10/2022-15:17:22] [V] [TRT] Using kernel: (3, 3), strides: (2, 2), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 256\n",
      "[04/10/2022-15:17:22] [V] [TRT] Convolution output dimensions: (1, 256, 14, 14)\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering tensor: StatefulPartitionedCall/model_1/stage3_unit1_bn2/FusedBatchNormV3:0 for ONNX tensor: StatefulPartitionedCall/model_1/stage3_unit1_bn2/FusedBatchNormV3:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_conv1/Conv2D [Conv] outputs: [StatefulPartitionedCall/model_1/stage3_unit1_bn2/FusedBatchNormV3:0 -> (1, 256, 14, 14)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Parsing node: StatefulPartitionedCall/model_1/stage3_unit1_relu2/Relu [Relu]\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage3_unit1_bn2/FusedBatchNormV3:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_relu2/Relu [Relu] inputs: [StatefulPartitionedCall/model_1/stage3_unit1_bn2/FusedBatchNormV3:0 -> (1, 256, 14, 14)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering layer: StatefulPartitionedCall/model_1/stage3_unit1_relu2/Relu for ONNX node: StatefulPartitionedCall/model_1/stage3_unit1_relu2/Relu\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering tensor: StatefulPartitionedCall/model_1/stage3_unit1_relu2/Relu:0 for ONNX tensor: StatefulPartitionedCall/model_1/stage3_unit1_relu2/Relu:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_relu2/Relu [Relu] outputs: [StatefulPartitionedCall/model_1/stage3_unit1_relu2/Relu:0 -> (1, 256, 14, 14)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Parsing node: StatefulPartitionedCall/model_1/stage3_unit1_conv2/Conv2D [Conv]\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage3_unit1_relu2/Relu:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage3_unit1_conv2/Conv2D/ReadVariableOp:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_conv2/Conv2D [Conv] inputs: [StatefulPartitionedCall/model_1/stage3_unit1_relu2/Relu:0 -> (1, 256, 14, 14)[FLOAT]], [StatefulPartitionedCall/model_1/stage3_unit1_conv2/Conv2D/ReadVariableOp:0 -> (256, 256, 3, 3)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Convolution input dimensions: (1, 256, 14, 14)\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering layer: StatefulPartitionedCall/model_1/stage3_unit1_conv2/Conv2D for ONNX node: StatefulPartitionedCall/model_1/stage3_unit1_conv2/Conv2D\n",
      "[04/10/2022-15:17:22] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 256\n",
      "[04/10/2022-15:17:22] [V] [TRT] Convolution output dimensions: (1, 256, 14, 14)\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering tensor: StatefulPartitionedCall/model_1/stage3_unit1_conv2/Conv2D:0 for ONNX tensor: StatefulPartitionedCall/model_1/stage3_unit1_conv2/Conv2D:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_conv2/Conv2D [Conv] outputs: [StatefulPartitionedCall/model_1/stage3_unit1_conv2/Conv2D:0 -> (1, 256, 14, 14)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Parsing node: StatefulPartitionedCall/model_1/add_4/add [Add]\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage3_unit1_conv2/Conv2D:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage3_unit1_sc/Conv2D:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/add_4/add [Add] inputs: [StatefulPartitionedCall/model_1/stage3_unit1_conv2/Conv2D:0 -> (1, 256, 14, 14)[FLOAT]], [StatefulPartitionedCall/model_1/stage3_unit1_sc/Conv2D:0 -> (1, 256, 14, 14)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering layer: StatefulPartitionedCall/model_1/add_4/add for ONNX node: StatefulPartitionedCall/model_1/add_4/add\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering tensor: StatefulPartitionedCall/model_1/add_4/add:0 for ONNX tensor: StatefulPartitionedCall/model_1/add_4/add:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/add_4/add [Add] outputs: [StatefulPartitionedCall/model_1/add_4/add:0 -> (1, 256, 14, 14)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Parsing node: StatefulPartitionedCall/model_1/stage3_unit2_bn1/FusedBatchNormV3 [BatchNormalization]\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/add_4/add:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage3_unit2_bn1/ReadVariableOp:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage3_unit2_bn1/ReadVariableOp_1:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage3_unit2_bn1/FusedBatchNormV3/ReadVariableOp:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage3_unit2_bn1/FusedBatchNormV3/ReadVariableOp_1:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit2_bn1/FusedBatchNormV3 [BatchNormalization] inputs: [StatefulPartitionedCall/model_1/add_4/add:0 -> (1, 256, 14, 14)[FLOAT]], [StatefulPartitionedCall/model_1/stage3_unit2_bn1/ReadVariableOp:0 -> (256)[FLOAT]], [StatefulPartitionedCall/model_1/stage3_unit2_bn1/ReadVariableOp_1:0 -> (256)[FLOAT]], [StatefulPartitionedCall/model_1/stage3_unit2_bn1/FusedBatchNormV3/ReadVariableOp:0 -> (256)[FLOAT]], [StatefulPartitionedCall/model_1/stage3_unit2_bn1/FusedBatchNormV3/ReadVariableOp_1:0 -> (256)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering layer: StatefulPartitionedCall/model_1/stage3_unit2_bn1/FusedBatchNormV3 for ONNX node: StatefulPartitionedCall/model_1/stage3_unit2_bn1/FusedBatchNormV3\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering tensor: StatefulPartitionedCall/model_1/stage3_unit2_bn1/FusedBatchNormV3:0 for ONNX tensor: StatefulPartitionedCall/model_1/stage3_unit2_bn1/FusedBatchNormV3:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit2_bn1/FusedBatchNormV3 [BatchNormalization] outputs: [StatefulPartitionedCall/model_1/stage3_unit2_bn1/FusedBatchNormV3:0 -> (1, 256, 14, 14)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Parsing node: StatefulPartitionedCall/model_1/stage3_unit2_relu1/Relu [Relu]\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage3_unit2_bn1/FusedBatchNormV3:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit2_relu1/Relu [Relu] inputs: [StatefulPartitionedCall/model_1/stage3_unit2_bn1/FusedBatchNormV3:0 -> (1, 256, 14, 14)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering layer: StatefulPartitionedCall/model_1/stage3_unit2_relu1/Relu for ONNX node: StatefulPartitionedCall/model_1/stage3_unit2_relu1/Relu\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering tensor: StatefulPartitionedCall/model_1/stage3_unit2_relu1/Relu:0 for ONNX tensor: StatefulPartitionedCall/model_1/stage3_unit2_relu1/Relu:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit2_relu1/Relu [Relu] outputs: [StatefulPartitionedCall/model_1/stage3_unit2_relu1/Relu:0 -> (1, 256, 14, 14)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Parsing node: StatefulPartitionedCall/model_1/stage3_unit2_conv1/Conv2D [Conv]\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage3_unit2_relu1/Relu:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage3_unit2_conv1/Conv2D_weights_fused_bn\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage3_unit2_conv1/Conv2D_bias_fused_bn\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit2_conv1/Conv2D [Conv] inputs: [StatefulPartitionedCall/model_1/stage3_unit2_relu1/Relu:0 -> (1, 256, 14, 14)[FLOAT]], [StatefulPartitionedCall/model_1/stage3_unit2_conv1/Conv2D_weights_fused_bn -> (256, 256, 3, 3)[FLOAT]], [StatefulPartitionedCall/model_1/stage3_unit2_conv1/Conv2D_bias_fused_bn -> (256)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Convolution input dimensions: (1, 256, 14, 14)\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering layer: StatefulPartitionedCall/model_1/stage3_unit2_conv1/Conv2D for ONNX node: StatefulPartitionedCall/model_1/stage3_unit2_conv1/Conv2D\n",
      "[04/10/2022-15:17:22] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 256\n",
      "[04/10/2022-15:17:22] [V] [TRT] Convolution output dimensions: (1, 256, 14, 14)\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering tensor: StatefulPartitionedCall/model_1/stage3_unit2_bn2/FusedBatchNormV3:0 for ONNX tensor: StatefulPartitionedCall/model_1/stage3_unit2_bn2/FusedBatchNormV3:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit2_conv1/Conv2D [Conv] outputs: [StatefulPartitionedCall/model_1/stage3_unit2_bn2/FusedBatchNormV3:0 -> (1, 256, 14, 14)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Parsing node: StatefulPartitionedCall/model_1/stage3_unit2_relu2/Relu [Relu]\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage3_unit2_bn2/FusedBatchNormV3:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit2_relu2/Relu [Relu] inputs: [StatefulPartitionedCall/model_1/stage3_unit2_bn2/FusedBatchNormV3:0 -> (1, 256, 14, 14)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering layer: StatefulPartitionedCall/model_1/stage3_unit2_relu2/Relu for ONNX node: StatefulPartitionedCall/model_1/stage3_unit2_relu2/Relu\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering tensor: StatefulPartitionedCall/model_1/stage3_unit2_relu2/Relu:0 for ONNX tensor: StatefulPartitionedCall/model_1/stage3_unit2_relu2/Relu:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit2_relu2/Relu [Relu] outputs: [StatefulPartitionedCall/model_1/stage3_unit2_relu2/Relu:0 -> (1, 256, 14, 14)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Parsing node: StatefulPartitionedCall/model_1/stage3_unit2_conv2/Conv2D [Conv]\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage3_unit2_relu2/Relu:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage3_unit2_conv2/Conv2D/ReadVariableOp:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit2_conv2/Conv2D [Conv] inputs: [StatefulPartitionedCall/model_1/stage3_unit2_relu2/Relu:0 -> (1, 256, 14, 14)[FLOAT]], [StatefulPartitionedCall/model_1/stage3_unit2_conv2/Conv2D/ReadVariableOp:0 -> (256, 256, 3, 3)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Convolution input dimensions: (1, 256, 14, 14)\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering layer: StatefulPartitionedCall/model_1/stage3_unit2_conv2/Conv2D for ONNX node: StatefulPartitionedCall/model_1/stage3_unit2_conv2/Conv2D\n",
      "[04/10/2022-15:17:22] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 256\n",
      "[04/10/2022-15:17:22] [V] [TRT] Convolution output dimensions: (1, 256, 14, 14)\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering tensor: StatefulPartitionedCall/model_1/stage3_unit2_conv2/Conv2D:0 for ONNX tensor: StatefulPartitionedCall/model_1/stage3_unit2_conv2/Conv2D:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit2_conv2/Conv2D [Conv] outputs: [StatefulPartitionedCall/model_1/stage3_unit2_conv2/Conv2D:0 -> (1, 256, 14, 14)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Parsing node: StatefulPartitionedCall/model_1/add_5/add [Add]\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage3_unit2_conv2/Conv2D:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/add_4/add:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/add_5/add [Add] inputs: [StatefulPartitionedCall/model_1/stage3_unit2_conv2/Conv2D:0 -> (1, 256, 14, 14)[FLOAT]], [StatefulPartitionedCall/model_1/add_4/add:0 -> (1, 256, 14, 14)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering layer: StatefulPartitionedCall/model_1/add_5/add for ONNX node: StatefulPartitionedCall/model_1/add_5/add\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering tensor: StatefulPartitionedCall/model_1/add_5/add:0 for ONNX tensor: StatefulPartitionedCall/model_1/add_5/add:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/add_5/add [Add] outputs: [StatefulPartitionedCall/model_1/add_5/add:0 -> (1, 256, 14, 14)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Parsing node: StatefulPartitionedCall/model_1/stage4_unit1_bn1/FusedBatchNormV3 [BatchNormalization]\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/add_5/add:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage4_unit1_bn1/ReadVariableOp:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage4_unit1_bn1/ReadVariableOp_1:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage4_unit1_bn1/FusedBatchNormV3/ReadVariableOp:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage4_unit1_bn1/FusedBatchNormV3/ReadVariableOp_1:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage4_unit1_bn1/FusedBatchNormV3 [BatchNormalization] inputs: [StatefulPartitionedCall/model_1/add_5/add:0 -> (1, 256, 14, 14)[FLOAT]], [StatefulPartitionedCall/model_1/stage4_unit1_bn1/ReadVariableOp:0 -> (256)[FLOAT]], [StatefulPartitionedCall/model_1/stage4_unit1_bn1/ReadVariableOp_1:0 -> (256)[FLOAT]], [StatefulPartitionedCall/model_1/stage4_unit1_bn1/FusedBatchNormV3/ReadVariableOp:0 -> (256)[FLOAT]], [StatefulPartitionedCall/model_1/stage4_unit1_bn1/FusedBatchNormV3/ReadVariableOp_1:0 -> (256)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering layer: StatefulPartitionedCall/model_1/stage4_unit1_bn1/FusedBatchNormV3 for ONNX node: StatefulPartitionedCall/model_1/stage4_unit1_bn1/FusedBatchNormV3\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering tensor: StatefulPartitionedCall/model_1/stage4_unit1_bn1/FusedBatchNormV3:0 for ONNX tensor: StatefulPartitionedCall/model_1/stage4_unit1_bn1/FusedBatchNormV3:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage4_unit1_bn1/FusedBatchNormV3 [BatchNormalization] outputs: [StatefulPartitionedCall/model_1/stage4_unit1_bn1/FusedBatchNormV3:0 -> (1, 256, 14, 14)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Parsing node: StatefulPartitionedCall/model_1/stage4_unit1_relu1/Relu [Relu]\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage4_unit1_bn1/FusedBatchNormV3:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage4_unit1_relu1/Relu [Relu] inputs: [StatefulPartitionedCall/model_1/stage4_unit1_bn1/FusedBatchNormV3:0 -> (1, 256, 14, 14)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering layer: StatefulPartitionedCall/model_1/stage4_unit1_relu1/Relu for ONNX node: StatefulPartitionedCall/model_1/stage4_unit1_relu1/Relu\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering tensor: StatefulPartitionedCall/model_1/stage4_unit1_relu1/Relu:0 for ONNX tensor: StatefulPartitionedCall/model_1/stage4_unit1_relu1/Relu:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage4_unit1_relu1/Relu [Relu] outputs: [StatefulPartitionedCall/model_1/stage4_unit1_relu1/Relu:0 -> (1, 256, 14, 14)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Parsing node: StatefulPartitionedCall/model_1/stage4_unit1_sc/Conv2D [Conv]\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage4_unit1_relu1/Relu:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage4_unit1_sc/Conv2D/ReadVariableOp:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage4_unit1_sc/Conv2D [Conv] inputs: [StatefulPartitionedCall/model_1/stage4_unit1_relu1/Relu:0 -> (1, 256, 14, 14)[FLOAT]], [StatefulPartitionedCall/model_1/stage4_unit1_sc/Conv2D/ReadVariableOp:0 -> (512, 256, 1, 1)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Convolution input dimensions: (1, 256, 14, 14)\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering layer: StatefulPartitionedCall/model_1/stage4_unit1_sc/Conv2D for ONNX node: StatefulPartitionedCall/model_1/stage4_unit1_sc/Conv2D\n",
      "[04/10/2022-15:17:22] [V] [TRT] Using kernel: (1, 1), strides: (2, 2), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 512\n",
      "[04/10/2022-15:17:22] [V] [TRT] Convolution output dimensions: (1, 512, 7, 7)\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering tensor: StatefulPartitionedCall/model_1/stage4_unit1_sc/Conv2D:0 for ONNX tensor: StatefulPartitionedCall/model_1/stage4_unit1_sc/Conv2D:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage4_unit1_sc/Conv2D [Conv] outputs: [StatefulPartitionedCall/model_1/stage4_unit1_sc/Conv2D:0 -> (1, 512, 7, 7)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Parsing node: StatefulPartitionedCall/model_1/stage4_unit1_conv1/Conv2D [Conv]\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage4_unit1_relu1/Relu:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage4_unit1_conv1/Conv2D_weights_fused_bn\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage4_unit1_conv1/Conv2D_bias_fused_bn\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage4_unit1_conv1/Conv2D [Conv] inputs: [StatefulPartitionedCall/model_1/stage4_unit1_relu1/Relu:0 -> (1, 256, 14, 14)[FLOAT]], [StatefulPartitionedCall/model_1/stage4_unit1_conv1/Conv2D_weights_fused_bn -> (512, 256, 3, 3)[FLOAT]], [StatefulPartitionedCall/model_1/stage4_unit1_conv1/Conv2D_bias_fused_bn -> (512)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Convolution input dimensions: (1, 256, 14, 14)\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering layer: StatefulPartitionedCall/model_1/stage4_unit1_conv1/Conv2D for ONNX node: StatefulPartitionedCall/model_1/stage4_unit1_conv1/Conv2D\n",
      "[04/10/2022-15:17:22] [V] [TRT] Using kernel: (3, 3), strides: (2, 2), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 512\n",
      "[04/10/2022-15:17:22] [V] [TRT] Convolution output dimensions: (1, 512, 7, 7)\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering tensor: StatefulPartitionedCall/model_1/stage4_unit1_bn2/FusedBatchNormV3:0 for ONNX tensor: StatefulPartitionedCall/model_1/stage4_unit1_bn2/FusedBatchNormV3:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage4_unit1_conv1/Conv2D [Conv] outputs: [StatefulPartitionedCall/model_1/stage4_unit1_bn2/FusedBatchNormV3:0 -> (1, 512, 7, 7)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Parsing node: StatefulPartitionedCall/model_1/stage4_unit1_relu2/Relu [Relu]\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage4_unit1_bn2/FusedBatchNormV3:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage4_unit1_relu2/Relu [Relu] inputs: [StatefulPartitionedCall/model_1/stage4_unit1_bn2/FusedBatchNormV3:0 -> (1, 512, 7, 7)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering layer: StatefulPartitionedCall/model_1/stage4_unit1_relu2/Relu for ONNX node: StatefulPartitionedCall/model_1/stage4_unit1_relu2/Relu\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering tensor: StatefulPartitionedCall/model_1/stage4_unit1_relu2/Relu:0 for ONNX tensor: StatefulPartitionedCall/model_1/stage4_unit1_relu2/Relu:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage4_unit1_relu2/Relu [Relu] outputs: [StatefulPartitionedCall/model_1/stage4_unit1_relu2/Relu:0 -> (1, 512, 7, 7)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Parsing node: StatefulPartitionedCall/model_1/stage4_unit1_conv2/Conv2D [Conv]\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage4_unit1_relu2/Relu:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage4_unit1_conv2/Conv2D/ReadVariableOp:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage4_unit1_conv2/Conv2D [Conv] inputs: [StatefulPartitionedCall/model_1/stage4_unit1_relu2/Relu:0 -> (1, 512, 7, 7)[FLOAT]], [StatefulPartitionedCall/model_1/stage4_unit1_conv2/Conv2D/ReadVariableOp:0 -> (512, 512, 3, 3)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Convolution input dimensions: (1, 512, 7, 7)\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering layer: StatefulPartitionedCall/model_1/stage4_unit1_conv2/Conv2D for ONNX node: StatefulPartitionedCall/model_1/stage4_unit1_conv2/Conv2D\n",
      "[04/10/2022-15:17:22] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 512\n",
      "[04/10/2022-15:17:22] [V] [TRT] Convolution output dimensions: (1, 512, 7, 7)\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering tensor: StatefulPartitionedCall/model_1/stage4_unit1_conv2/Conv2D:0 for ONNX tensor: StatefulPartitionedCall/model_1/stage4_unit1_conv2/Conv2D:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage4_unit1_conv2/Conv2D [Conv] outputs: [StatefulPartitionedCall/model_1/stage4_unit1_conv2/Conv2D:0 -> (1, 512, 7, 7)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Parsing node: StatefulPartitionedCall/model_1/add_6/add [Add]\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage4_unit1_conv2/Conv2D:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage4_unit1_sc/Conv2D:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/add_6/add [Add] inputs: [StatefulPartitionedCall/model_1/stage4_unit1_conv2/Conv2D:0 -> (1, 512, 7, 7)[FLOAT]], [StatefulPartitionedCall/model_1/stage4_unit1_sc/Conv2D:0 -> (1, 512, 7, 7)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering layer: StatefulPartitionedCall/model_1/add_6/add for ONNX node: StatefulPartitionedCall/model_1/add_6/add\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering tensor: StatefulPartitionedCall/model_1/add_6/add:0 for ONNX tensor: StatefulPartitionedCall/model_1/add_6/add:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/add_6/add [Add] outputs: [StatefulPartitionedCall/model_1/add_6/add:0 -> (1, 512, 7, 7)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Parsing node: StatefulPartitionedCall/model_1/stage4_unit2_bn1/FusedBatchNormV3 [BatchNormalization]\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/add_6/add:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage4_unit2_bn1/ReadVariableOp:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage4_unit2_bn1/ReadVariableOp_1:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage4_unit2_bn1/FusedBatchNormV3/ReadVariableOp:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage4_unit2_bn1/FusedBatchNormV3/ReadVariableOp_1:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage4_unit2_bn1/FusedBatchNormV3 [BatchNormalization] inputs: [StatefulPartitionedCall/model_1/add_6/add:0 -> (1, 512, 7, 7)[FLOAT]], [StatefulPartitionedCall/model_1/stage4_unit2_bn1/ReadVariableOp:0 -> (512)[FLOAT]], [StatefulPartitionedCall/model_1/stage4_unit2_bn1/ReadVariableOp_1:0 -> (512)[FLOAT]], [StatefulPartitionedCall/model_1/stage4_unit2_bn1/FusedBatchNormV3/ReadVariableOp:0 -> (512)[FLOAT]], [StatefulPartitionedCall/model_1/stage4_unit2_bn1/FusedBatchNormV3/ReadVariableOp_1:0 -> (512)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering layer: StatefulPartitionedCall/model_1/stage4_unit2_bn1/FusedBatchNormV3 for ONNX node: StatefulPartitionedCall/model_1/stage4_unit2_bn1/FusedBatchNormV3\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering tensor: StatefulPartitionedCall/model_1/stage4_unit2_bn1/FusedBatchNormV3:0 for ONNX tensor: StatefulPartitionedCall/model_1/stage4_unit2_bn1/FusedBatchNormV3:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage4_unit2_bn1/FusedBatchNormV3 [BatchNormalization] outputs: [StatefulPartitionedCall/model_1/stage4_unit2_bn1/FusedBatchNormV3:0 -> (1, 512, 7, 7)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Parsing node: StatefulPartitionedCall/model_1/stage4_unit2_relu1/Relu [Relu]\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage4_unit2_bn1/FusedBatchNormV3:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage4_unit2_relu1/Relu [Relu] inputs: [StatefulPartitionedCall/model_1/stage4_unit2_bn1/FusedBatchNormV3:0 -> (1, 512, 7, 7)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering layer: StatefulPartitionedCall/model_1/stage4_unit2_relu1/Relu for ONNX node: StatefulPartitionedCall/model_1/stage4_unit2_relu1/Relu\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering tensor: StatefulPartitionedCall/model_1/stage4_unit2_relu1/Relu:0 for ONNX tensor: StatefulPartitionedCall/model_1/stage4_unit2_relu1/Relu:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage4_unit2_relu1/Relu [Relu] outputs: [StatefulPartitionedCall/model_1/stage4_unit2_relu1/Relu:0 -> (1, 512, 7, 7)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Parsing node: StatefulPartitionedCall/model_1/stage4_unit2_conv1/Conv2D [Conv]\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage4_unit2_relu1/Relu:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage4_unit2_conv1/Conv2D_weights_fused_bn\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage4_unit2_conv1/Conv2D_bias_fused_bn\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage4_unit2_conv1/Conv2D [Conv] inputs: [StatefulPartitionedCall/model_1/stage4_unit2_relu1/Relu:0 -> (1, 512, 7, 7)[FLOAT]], [StatefulPartitionedCall/model_1/stage4_unit2_conv1/Conv2D_weights_fused_bn -> (512, 512, 3, 3)[FLOAT]], [StatefulPartitionedCall/model_1/stage4_unit2_conv1/Conv2D_bias_fused_bn -> (512)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Convolution input dimensions: (1, 512, 7, 7)\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering layer: StatefulPartitionedCall/model_1/stage4_unit2_conv1/Conv2D for ONNX node: StatefulPartitionedCall/model_1/stage4_unit2_conv1/Conv2D\n",
      "[04/10/2022-15:17:22] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 512\n",
      "[04/10/2022-15:17:22] [V] [TRT] Convolution output dimensions: (1, 512, 7, 7)\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering tensor: StatefulPartitionedCall/model_1/stage4_unit2_bn2/FusedBatchNormV3:0 for ONNX tensor: StatefulPartitionedCall/model_1/stage4_unit2_bn2/FusedBatchNormV3:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage4_unit2_conv1/Conv2D [Conv] outputs: [StatefulPartitionedCall/model_1/stage4_unit2_bn2/FusedBatchNormV3:0 -> (1, 512, 7, 7)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Parsing node: StatefulPartitionedCall/model_1/stage4_unit2_relu2/Relu [Relu]\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage4_unit2_bn2/FusedBatchNormV3:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage4_unit2_relu2/Relu [Relu] inputs: [StatefulPartitionedCall/model_1/stage4_unit2_bn2/FusedBatchNormV3:0 -> (1, 512, 7, 7)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering layer: StatefulPartitionedCall/model_1/stage4_unit2_relu2/Relu for ONNX node: StatefulPartitionedCall/model_1/stage4_unit2_relu2/Relu\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering tensor: StatefulPartitionedCall/model_1/stage4_unit2_relu2/Relu:0 for ONNX tensor: StatefulPartitionedCall/model_1/stage4_unit2_relu2/Relu:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage4_unit2_relu2/Relu [Relu] outputs: [StatefulPartitionedCall/model_1/stage4_unit2_relu2/Relu:0 -> (1, 512, 7, 7)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Parsing node: StatefulPartitionedCall/model_1/stage4_unit2_conv2/Conv2D [Conv]\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage4_unit2_relu2/Relu:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage4_unit2_conv2/Conv2D/ReadVariableOp:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage4_unit2_conv2/Conv2D [Conv] inputs: [StatefulPartitionedCall/model_1/stage4_unit2_relu2/Relu:0 -> (1, 512, 7, 7)[FLOAT]], [StatefulPartitionedCall/model_1/stage4_unit2_conv2/Conv2D/ReadVariableOp:0 -> (512, 512, 3, 3)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Convolution input dimensions: (1, 512, 7, 7)\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering layer: StatefulPartitionedCall/model_1/stage4_unit2_conv2/Conv2D for ONNX node: StatefulPartitionedCall/model_1/stage4_unit2_conv2/Conv2D\n",
      "[04/10/2022-15:17:22] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 512\n",
      "[04/10/2022-15:17:22] [V] [TRT] Convolution output dimensions: (1, 512, 7, 7)\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering tensor: StatefulPartitionedCall/model_1/stage4_unit2_conv2/Conv2D:0 for ONNX tensor: StatefulPartitionedCall/model_1/stage4_unit2_conv2/Conv2D:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/stage4_unit2_conv2/Conv2D [Conv] outputs: [StatefulPartitionedCall/model_1/stage4_unit2_conv2/Conv2D:0 -> (1, 512, 7, 7)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Parsing node: StatefulPartitionedCall/model_1/add_7/add [Add]\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/stage4_unit2_conv2/Conv2D:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/add_6/add:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/add_7/add [Add] inputs: [StatefulPartitionedCall/model_1/stage4_unit2_conv2/Conv2D:0 -> (1, 512, 7, 7)[FLOAT]], [StatefulPartitionedCall/model_1/add_6/add:0 -> (1, 512, 7, 7)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering layer: StatefulPartitionedCall/model_1/add_7/add for ONNX node: StatefulPartitionedCall/model_1/add_7/add\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering tensor: StatefulPartitionedCall/model_1/add_7/add:0 for ONNX tensor: StatefulPartitionedCall/model_1/add_7/add:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/add_7/add [Add] outputs: [StatefulPartitionedCall/model_1/add_7/add:0 -> (1, 512, 7, 7)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Parsing node: StatefulPartitionedCall/model_1/bn1/FusedBatchNormV3 [BatchNormalization]\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/add_7/add:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/bn1/ReadVariableOp:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/bn1/ReadVariableOp_1:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/bn1/FusedBatchNormV3/ReadVariableOp:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/bn1/FusedBatchNormV3/ReadVariableOp_1:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/bn1/FusedBatchNormV3 [BatchNormalization] inputs: [StatefulPartitionedCall/model_1/add_7/add:0 -> (1, 512, 7, 7)[FLOAT]], [StatefulPartitionedCall/model_1/bn1/ReadVariableOp:0 -> (512)[FLOAT]], [StatefulPartitionedCall/model_1/bn1/ReadVariableOp_1:0 -> (512)[FLOAT]], [StatefulPartitionedCall/model_1/bn1/FusedBatchNormV3/ReadVariableOp:0 -> (512)[FLOAT]], [StatefulPartitionedCall/model_1/bn1/FusedBatchNormV3/ReadVariableOp_1:0 -> (512)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering layer: StatefulPartitionedCall/model_1/bn1/FusedBatchNormV3 for ONNX node: StatefulPartitionedCall/model_1/bn1/FusedBatchNormV3\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering tensor: StatefulPartitionedCall/model_1/bn1/FusedBatchNormV3:0 for ONNX tensor: StatefulPartitionedCall/model_1/bn1/FusedBatchNormV3:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/bn1/FusedBatchNormV3 [BatchNormalization] outputs: [StatefulPartitionedCall/model_1/bn1/FusedBatchNormV3:0 -> (1, 512, 7, 7)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Parsing node: StatefulPartitionedCall/model_1/relu1/Relu [Relu]\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/bn1/FusedBatchNormV3:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/relu1/Relu [Relu] inputs: [StatefulPartitionedCall/model_1/bn1/FusedBatchNormV3:0 -> (1, 512, 7, 7)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering layer: StatefulPartitionedCall/model_1/relu1/Relu for ONNX node: StatefulPartitionedCall/model_1/relu1/Relu\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering tensor: StatefulPartitionedCall/model_1/relu1/Relu:0 for ONNX tensor: StatefulPartitionedCall/model_1/relu1/Relu:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/relu1/Relu [Relu] outputs: [StatefulPartitionedCall/model_1/relu1/Relu:0 -> (1, 512, 7, 7)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Parsing node: StatefulPartitionedCall/model_1/global_average_pooling2d/Mean [GlobalAveragePool]\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/relu1/Relu:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/global_average_pooling2d/Mean [GlobalAveragePool] inputs: [StatefulPartitionedCall/model_1/relu1/Relu:0 -> (1, 512, 7, 7)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering layer: StatefulPartitionedCall/model_1/global_average_pooling2d/Mean for ONNX node: StatefulPartitionedCall/model_1/global_average_pooling2d/Mean\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering tensor: StatefulPartitionedCall/model_1/global_average_pooling2d/Mean:0 for ONNX tensor: StatefulPartitionedCall/model_1/global_average_pooling2d/Mean:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/global_average_pooling2d/Mean [GlobalAveragePool] outputs: [StatefulPartitionedCall/model_1/global_average_pooling2d/Mean:0 -> (1, 512, 1, 1)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Parsing node: StatefulPartitionedCall/model_1/global_average_pooling2d/Mean_Squeeze__202 [Squeeze]\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/global_average_pooling2d/Mean:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/global_average_pooling2d/Mean_Squeeze__202 [Squeeze] inputs: [StatefulPartitionedCall/model_1/global_average_pooling2d/Mean:0 -> (1, 512, 1, 1)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Original shape: (1, 512, 1, 1), squeezing to: (1, 512)\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering layer: StatefulPartitionedCall/model_1/global_average_pooling2d/Mean_Squeeze__202 for ONNX node: StatefulPartitionedCall/model_1/global_average_pooling2d/Mean_Squeeze__202\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering tensor: StatefulPartitionedCall/model_1/global_average_pooling2d/Mean_Squeeze__202:0 for ONNX tensor: StatefulPartitionedCall/model_1/global_average_pooling2d/Mean_Squeeze__202:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/global_average_pooling2d/Mean_Squeeze__202 [Squeeze] outputs: [StatefulPartitionedCall/model_1/global_average_pooling2d/Mean_Squeeze__202:0 -> (1, 512)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Parsing node: StatefulPartitionedCall/model_1/dense/MatMul [MatMul]\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/global_average_pooling2d/Mean_Squeeze__202:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/dense/MatMul/ReadVariableOp:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/dense/MatMul [MatMul] inputs: [StatefulPartitionedCall/model_1/global_average_pooling2d/Mean_Squeeze__202:0 -> (1, 512)[FLOAT]], [StatefulPartitionedCall/model_1/dense/MatMul/ReadVariableOp:0 -> (512, 2)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering layer: StatefulPartitionedCall/model_1/dense/MatMul/ReadVariableOp:0 for ONNX node: StatefulPartitionedCall/model_1/dense/MatMul/ReadVariableOp:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] GEMM: using FC layer instead of MM because all criteria were met.\n",
      "[04/10/2022-15:17:22] [V] [TRT] Original shape: (1, 512), unsqueezing to: (1, 512, 1, 1)\n",
      "[04/10/2022-15:17:22] [W] [TRT] ShapedWeights.cpp:173: Weights StatefulPartitionedCall/model_1/dense/MatMul/ReadVariableOp:0 has been transposed with permutation of (1, 0)! If you plan on overwriting the weights with the Refitter API, the new weights must be pre-transposed.\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering layer: StatefulPartitionedCall/model_1/dense/MatMul for ONNX node: StatefulPartitionedCall/model_1/dense/MatMul\n",
      "[04/10/2022-15:17:22] [V] [TRT] Original shape: (1, 2, 1, 1), squeezing to: (1, 2)\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering tensor: StatefulPartitionedCall/model_1/dense/MatMul:0 for ONNX tensor: StatefulPartitionedCall/model_1/dense/MatMul:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/dense/MatMul [MatMul] outputs: [StatefulPartitionedCall/model_1/dense/MatMul:0 -> (1, 2)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Parsing node: StatefulPartitionedCall/model_1/dense/BiasAdd [Add]\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/dense/MatMul:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Searching for input: StatefulPartitionedCall/model_1/dense/BiasAdd/ReadVariableOp:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/dense/BiasAdd [Add] inputs: [StatefulPartitionedCall/model_1/dense/MatMul:0 -> (1, 2)[FLOAT]], [StatefulPartitionedCall/model_1/dense/BiasAdd/ReadVariableOp:0 -> (2)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering layer: StatefulPartitionedCall/model_1/dense/BiasAdd/ReadVariableOp:0 for ONNX node: StatefulPartitionedCall/model_1/dense/BiasAdd/ReadVariableOp:0\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering layer: StatefulPartitionedCall/model_1/dense/BiasAdd for ONNX node: StatefulPartitionedCall/model_1/dense/BiasAdd\n",
      "[04/10/2022-15:17:22] [V] [TRT] Registering tensor: dense_0 for ONNX tensor: dense\n",
      "[04/10/2022-15:17:22] [V] [TRT] StatefulPartitionedCall/model_1/dense/BiasAdd [Add] outputs: [dense -> (1, 2)[FLOAT]], \n",
      "[04/10/2022-15:17:22] [V] [TRT] Marking dense_0 as output: dense\n",
      "[04/10/2022-15:17:22] [I] Finish parsing network model\n",
      "[04/10/2022-15:17:22] [I] [TRT] [MemUsageChange] Init CUDA: CPU +0, GPU +0, now: CPU 264, GPU 2217 (MiB)\n",
      "[04/10/2022-15:17:22] [I] [TRT] [MemUsageSnapshot] Builder begin: CPU 264 MiB, GPU 2217 MiB\n",
      "[04/10/2022-15:17:22] [V] [TRT] Applying generic optimizations to the graph for inference.\n",
      "[04/10/2022-15:17:22] [V] [TRT] Original: 69 layers\n",
      "[04/10/2022-15:17:22] [V] [TRT] After dead-layer removal: 69 layers\n",
      "[04/10/2022-15:17:22] [V] [TRT] ShuffleShuffleFusion: Fusing StatefulPartitionedCall/model_1/global_average_pooling2d/Mean_Squeeze__202 with (Unnamed Layer* 64) [Shuffle]\n",
      "[04/10/2022-15:17:22] [V] [TRT] Removing StatefulPartitionedCall/model_1/global_average_pooling2d/Mean_Squeeze__202 + (Unnamed Layer* 64) [Shuffle]\n",
      "[04/10/2022-15:17:22] [V] [TRT] ConstShuffleFusion: Fusing StatefulPartitionedCall/model_1/dense/BiasAdd/ReadVariableOp:0 with (Unnamed Layer* 68) [Shuffle]\n",
      "[04/10/2022-15:17:22] [V] [TRT] After Myelin optimization: 66 layers\n",
      "[04/10/2022-15:17:22] [V] [TRT] Convert layer type of StatefulPartitionedCall/model_1/dense/MatMul from FULLY_CONNECTED to CONVOLUTION\n",
      "[04/10/2022-15:17:22] [V] [TRT] Removing shuffle_between_StatefulPartitionedCall/model_1/global_average_pooling2d/Mean:0_and_StatefulPartitionedCall/model_1/dense/MatMul\n",
      "[04/10/2022-15:17:22] [V] [TRT] Fusing convolution weights from StatefulPartitionedCall/model_1/conv0/Conv2D with scale StatefulPartitionedCall/model_1/bn0/FusedBatchNormV3\n",
      "[04/10/2022-15:17:22] [V] [TRT] After scale fusion: 65 layers\n",
      "[04/10/2022-15:17:22] [V] [TRT] -----------SqueezePushDown kSQUEEZE_JOIN case: StatefulPartitionedCall/model_1/dense/MatMul --> (Unnamed Layer* 66) [Shuffle] --> StatefulPartitionedCall/model_1/dense/BiasAdd\n",
      "[04/10/2022-15:17:22] [V] [TRT] ConstShuffleFusion: Fusing StatefulPartitionedCall/model_1/dense/BiasAdd/ReadVariableOp:0 + (Unnamed Layer* 68) [Shuffle] with unsqueeze_node_after_StatefulPartitionedCall/model_1/dense/BiasAdd/ReadVariableOp:0 + (Unnamed Layer* 68) [Shuffle]\n",
      "[04/10/2022-15:17:22] [V] [TRT] ConvReluFusion: Fusing StatefulPartitionedCall/model_1/conv0/Conv2D with StatefulPartitionedCall/model_1/relu0/Relu\n",
      "[04/10/2022-15:17:22] [V] [TRT] ScaleActivationFusion: Fusing StatefulPartitionedCall/model_1/stage1_unit1_bn1/FusedBatchNormV3 with StatefulPartitionedCall/model_1/stage1_unit1_relu1/Relu\n",
      "[04/10/2022-15:17:22] [V] [TRT] ConvEltwiseSumFusion: Fusing StatefulPartitionedCall/model_1/stage1_unit1_sc/Conv2D with StatefulPartitionedCall/model_1/add/add\n",
      "[04/10/2022-15:17:22] [V] [TRT] ConvReluFusion: Fusing StatefulPartitionedCall/model_1/stage1_unit1_conv1/Conv2D with StatefulPartitionedCall/model_1/stage1_unit1_relu2/Relu\n",
      "[04/10/2022-15:17:22] [V] [TRT] ScaleActivationFusion: Fusing StatefulPartitionedCall/model_1/stage1_unit2_bn1/FusedBatchNormV3 with StatefulPartitionedCall/model_1/stage1_unit2_relu1/Relu\n",
      "[04/10/2022-15:17:22] [V] [TRT] ConvReluFusion: Fusing StatefulPartitionedCall/model_1/stage1_unit2_conv1/Conv2D with StatefulPartitionedCall/model_1/stage1_unit2_relu2/Relu\n",
      "[04/10/2022-15:17:22] [V] [TRT] ConvEltwiseSumFusion: Fusing StatefulPartitionedCall/model_1/stage1_unit2_conv2/Conv2D with StatefulPartitionedCall/model_1/add_1/add\n",
      "[04/10/2022-15:17:22] [V] [TRT] ScaleActivationFusion: Fusing StatefulPartitionedCall/model_1/stage2_unit1_bn1/FusedBatchNormV3 with StatefulPartitionedCall/model_1/stage2_unit1_relu1/Relu\n",
      "[04/10/2022-15:17:22] [V] [TRT] ConvEltwiseSumFusion: Fusing StatefulPartitionedCall/model_1/stage2_unit1_sc/Conv2D with StatefulPartitionedCall/model_1/add_2/add\n",
      "[04/10/2022-15:17:22] [V] [TRT] ConvReluFusion: Fusing StatefulPartitionedCall/model_1/stage2_unit1_conv1/Conv2D with StatefulPartitionedCall/model_1/stage2_unit1_relu2/Relu\n",
      "[04/10/2022-15:17:22] [V] [TRT] ScaleActivationFusion: Fusing StatefulPartitionedCall/model_1/stage2_unit2_bn1/FusedBatchNormV3 with StatefulPartitionedCall/model_1/stage2_unit2_relu1/Relu\n",
      "[04/10/2022-15:17:22] [V] [TRT] ConvReluFusion: Fusing StatefulPartitionedCall/model_1/stage2_unit2_conv1/Conv2D with StatefulPartitionedCall/model_1/stage2_unit2_relu2/Relu\n",
      "[04/10/2022-15:17:22] [V] [TRT] ConvEltwiseSumFusion: Fusing StatefulPartitionedCall/model_1/stage2_unit2_conv2/Conv2D with StatefulPartitionedCall/model_1/add_3/add\n",
      "[04/10/2022-15:17:22] [V] [TRT] ScaleActivationFusion: Fusing StatefulPartitionedCall/model_1/stage3_unit1_bn1/FusedBatchNormV3 with StatefulPartitionedCall/model_1/stage3_unit1_relu1/Relu\n",
      "[04/10/2022-15:17:22] [V] [TRT] ConvEltwiseSumFusion: Fusing StatefulPartitionedCall/model_1/stage3_unit1_sc/Conv2D with StatefulPartitionedCall/model_1/add_4/add\n",
      "[04/10/2022-15:17:22] [V] [TRT] ConvReluFusion: Fusing StatefulPartitionedCall/model_1/stage3_unit1_conv1/Conv2D with StatefulPartitionedCall/model_1/stage3_unit1_relu2/Relu\n",
      "[04/10/2022-15:17:22] [V] [TRT] ScaleActivationFusion: Fusing StatefulPartitionedCall/model_1/stage3_unit2_bn1/FusedBatchNormV3 with StatefulPartitionedCall/model_1/stage3_unit2_relu1/Relu\n",
      "[04/10/2022-15:17:22] [V] [TRT] ConvReluFusion: Fusing StatefulPartitionedCall/model_1/stage3_unit2_conv1/Conv2D with StatefulPartitionedCall/model_1/stage3_unit2_relu2/Relu\n",
      "[04/10/2022-15:17:22] [V] [TRT] ConvEltwiseSumFusion: Fusing StatefulPartitionedCall/model_1/stage3_unit2_conv2/Conv2D with StatefulPartitionedCall/model_1/add_5/add\n",
      "[04/10/2022-15:17:22] [V] [TRT] ScaleActivationFusion: Fusing StatefulPartitionedCall/model_1/stage4_unit1_bn1/FusedBatchNormV3 with StatefulPartitionedCall/model_1/stage4_unit1_relu1/Relu\n",
      "[04/10/2022-15:17:22] [V] [TRT] ConvEltwiseSumFusion: Fusing StatefulPartitionedCall/model_1/stage4_unit1_sc/Conv2D with StatefulPartitionedCall/model_1/add_6/add\n",
      "[04/10/2022-15:17:22] [V] [TRT] ConvReluFusion: Fusing StatefulPartitionedCall/model_1/stage4_unit1_conv1/Conv2D with StatefulPartitionedCall/model_1/stage4_unit1_relu2/Relu\n",
      "[04/10/2022-15:17:22] [V] [TRT] ScaleActivationFusion: Fusing StatefulPartitionedCall/model_1/stage4_unit2_bn1/FusedBatchNormV3 with StatefulPartitionedCall/model_1/stage4_unit2_relu1/Relu\n",
      "[04/10/2022-15:17:22] [V] [TRT] ConvReluFusion: Fusing StatefulPartitionedCall/model_1/stage4_unit2_conv1/Conv2D with StatefulPartitionedCall/model_1/stage4_unit2_relu2/Relu\n",
      "[04/10/2022-15:17:22] [V] [TRT] ConvEltwiseSumFusion: Fusing StatefulPartitionedCall/model_1/stage4_unit2_conv2/Conv2D with StatefulPartitionedCall/model_1/add_7/add\n",
      "[04/10/2022-15:17:22] [V] [TRT] ScaleActivationFusion: Fusing StatefulPartitionedCall/model_1/bn1/FusedBatchNormV3 with StatefulPartitionedCall/model_1/relu1/Relu\n",
      "[04/10/2022-15:17:22] [V] [TRT] Swap the layer type of StatefulPartitionedCall/model_1/global_average_pooling2d/Mean from REDUCE to POOLING\n",
      "[04/10/2022-15:17:22] [V] [TRT] ConvEltwiseSumFusion: Fusing StatefulPartitionedCall/model_1/dense/MatMul with StatefulPartitionedCall/model_1/dense/BiasAdd\n",
      "[04/10/2022-15:17:22] [V] [TRT] After vertical fusions: 38 layers\n",
      "[04/10/2022-15:17:22] [V] [TRT] After dupe layer removal: 37 layers\n",
      "[04/10/2022-15:17:22] [V] [TRT] After final dead-layer removal: 37 layers\n",
      "[04/10/2022-15:17:22] [V] [TRT] After tensor merging: 37 layers\n",
      "[04/10/2022-15:17:22] [V] [TRT] After concat removal: 37 layers\n",
      "[04/10/2022-15:17:22] [V] [TRT] Graph construction and optimization completed in 0.0171753 seconds.\n",
      "[04/10/2022-15:17:22] [I] [TRT] ---------- Layers Running on DLA ----------\n",
      "[04/10/2022-15:17:22] [I] [TRT] ---------- Layers Running on GPU ----------\n",
      "[04/10/2022-15:17:22] [I] [TRT] [GpuLayer] StatefulPartitionedCall/model_1/bn_data/FusedBatchNormV3__74\n",
      "[04/10/2022-15:17:22] [I] [TRT] [GpuLayer] StatefulPartitionedCall/model_1/bn_data/FusedBatchNormV3\n",
      "[04/10/2022-15:17:22] [I] [TRT] [GpuLayer] StatefulPartitionedCall/model_1/conv0/Conv2D + StatefulPartitionedCall/model_1/relu0/Relu\n",
      "[04/10/2022-15:17:22] [I] [TRT] [GpuLayer] StatefulPartitionedCall/model_1/zero_padding2d_1/Pad\n",
      "[04/10/2022-15:17:22] [I] [TRT] [GpuLayer] StatefulPartitionedCall/model_1/pooling0/MaxPool\n",
      "[04/10/2022-15:17:22] [I] [TRT] [GpuLayer] StatefulPartitionedCall/model_1/stage1_unit1_bn1/FusedBatchNormV3 + StatefulPartitionedCall/model_1/stage1_unit1_relu1/Relu\n",
      "[04/10/2022-15:17:22] [I] [TRT] [GpuLayer] StatefulPartitionedCall/model_1/stage1_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage1_unit1_relu2/Relu\n",
      "[04/10/2022-15:17:22] [I] [TRT] [GpuLayer] StatefulPartitionedCall/model_1/stage1_unit1_conv2/Conv2D\n",
      "[04/10/2022-15:17:22] [I] [TRT] [GpuLayer] StatefulPartitionedCall/model_1/stage1_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add/add\n",
      "[04/10/2022-15:17:22] [I] [TRT] [GpuLayer] StatefulPartitionedCall/model_1/stage1_unit2_bn1/FusedBatchNormV3 + StatefulPartitionedCall/model_1/stage1_unit2_relu1/Relu\n",
      "[04/10/2022-15:17:22] [I] [TRT] [GpuLayer] StatefulPartitionedCall/model_1/stage1_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage1_unit2_relu2/Relu\n",
      "[04/10/2022-15:17:22] [I] [TRT] [GpuLayer] StatefulPartitionedCall/model_1/stage1_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_1/add\n",
      "[04/10/2022-15:17:22] [I] [TRT] [GpuLayer] StatefulPartitionedCall/model_1/stage2_unit1_bn1/FusedBatchNormV3 + StatefulPartitionedCall/model_1/stage2_unit1_relu1/Relu\n",
      "[04/10/2022-15:17:22] [I] [TRT] [GpuLayer] StatefulPartitionedCall/model_1/stage2_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit1_relu2/Relu\n",
      "[04/10/2022-15:17:22] [I] [TRT] [GpuLayer] StatefulPartitionedCall/model_1/stage2_unit1_conv2/Conv2D\n",
      "[04/10/2022-15:17:22] [I] [TRT] [GpuLayer] StatefulPartitionedCall/model_1/stage2_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_2/add\n",
      "[04/10/2022-15:17:22] [I] [TRT] [GpuLayer] StatefulPartitionedCall/model_1/stage2_unit2_bn1/FusedBatchNormV3 + StatefulPartitionedCall/model_1/stage2_unit2_relu1/Relu\n",
      "[04/10/2022-15:17:22] [I] [TRT] [GpuLayer] StatefulPartitionedCall/model_1/stage2_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit2_relu2/Relu\n",
      "[04/10/2022-15:17:22] [I] [TRT] [GpuLayer] StatefulPartitionedCall/model_1/stage2_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_3/add\n",
      "[04/10/2022-15:17:22] [I] [TRT] [GpuLayer] StatefulPartitionedCall/model_1/stage3_unit1_bn1/FusedBatchNormV3 + StatefulPartitionedCall/model_1/stage3_unit1_relu1/Relu\n",
      "[04/10/2022-15:17:22] [I] [TRT] [GpuLayer] StatefulPartitionedCall/model_1/stage3_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit1_relu2/Relu\n",
      "[04/10/2022-15:17:22] [I] [TRT] [GpuLayer] StatefulPartitionedCall/model_1/stage3_unit1_conv2/Conv2D\n",
      "[04/10/2022-15:17:22] [I] [TRT] [GpuLayer] StatefulPartitionedCall/model_1/stage3_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_4/add\n",
      "[04/10/2022-15:17:22] [I] [TRT] [GpuLayer] StatefulPartitionedCall/model_1/stage3_unit2_bn1/FusedBatchNormV3 + StatefulPartitionedCall/model_1/stage3_unit2_relu1/Relu\n",
      "[04/10/2022-15:17:22] [I] [TRT] [GpuLayer] StatefulPartitionedCall/model_1/stage3_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit2_relu2/Relu\n",
      "[04/10/2022-15:17:22] [I] [TRT] [GpuLayer] StatefulPartitionedCall/model_1/stage3_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_5/add\n",
      "[04/10/2022-15:17:22] [I] [TRT] [GpuLayer] StatefulPartitionedCall/model_1/stage4_unit1_bn1/FusedBatchNormV3 + StatefulPartitionedCall/model_1/stage4_unit1_relu1/Relu\n",
      "[04/10/2022-15:17:22] [I] [TRT] [GpuLayer] StatefulPartitionedCall/model_1/stage4_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage4_unit1_relu2/Relu\n",
      "[04/10/2022-15:17:22] [I] [TRT] [GpuLayer] StatefulPartitionedCall/model_1/stage4_unit1_conv2/Conv2D\n",
      "[04/10/2022-15:17:22] [I] [TRT] [GpuLayer] StatefulPartitionedCall/model_1/stage4_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_6/add\n",
      "[04/10/2022-15:17:22] [I] [TRT] [GpuLayer] StatefulPartitionedCall/model_1/stage4_unit2_bn1/FusedBatchNormV3 + StatefulPartitionedCall/model_1/stage4_unit2_relu1/Relu\n",
      "[04/10/2022-15:17:22] [I] [TRT] [GpuLayer] StatefulPartitionedCall/model_1/stage4_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage4_unit2_relu2/Relu\n",
      "[04/10/2022-15:17:22] [I] [TRT] [GpuLayer] StatefulPartitionedCall/model_1/stage4_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_7/add\n",
      "[04/10/2022-15:17:22] [I] [TRT] [GpuLayer] StatefulPartitionedCall/model_1/bn1/FusedBatchNormV3 + StatefulPartitionedCall/model_1/relu1/Relu\n",
      "[04/10/2022-15:17:22] [I] [TRT] [GpuLayer] StatefulPartitionedCall/model_1/global_average_pooling2d/Mean\n",
      "[04/10/2022-15:17:22] [I] [TRT] [GpuLayer] StatefulPartitionedCall/model_1/dense/MatMul + StatefulPartitionedCall/model_1/dense/BiasAdd\n",
      "[04/10/2022-15:17:22] [I] [TRT] [GpuLayer] copied_squeeze_after_StatefulPartitionedCall/model_1/dense/BiasAdd\n",
      "[04/10/2022-15:17:25] [V] [TRT] Using cublas a tactic source\n",
      "[04/10/2022-15:17:25] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +158, GPU +227, now: CPU 422, GPU 2444 (MiB)\n",
      "[04/10/2022-15:17:25] [V] [TRT] Using cuDNN as a tactic source\n",
      "[04/10/2022-15:17:28] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +241, GPU +362, now: CPU 663, GPU 2806 (MiB)\n",
      "[04/10/2022-15:17:28] [W] [TRT] Detected invalid timing cache, setup a local cache instead\n",
      "[04/10/2022-15:17:28] [V] [TRT] Constructing optimization profile number 0 [1/1].\n",
      "[04/10/2022-15:17:28] [V] [TRT] *************** Autotuning Reformat:Float(150528,672,3,1) -> Float(150528,1,672,224) ***************\n",
      "[04/10/2022-15:17:28] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:17:28] [V] [TRT] Tactic: 1002 Time: 2.06215\n",
      "[04/10/2022-15:17:28] [V] [TRT] Tactic: 0 Time: 1.33214\n",
      "[04/10/2022-15:17:28] [V] [TRT] Fastest Tactic: 0 Time: 1.33214\n",
      "[04/10/2022-15:17:28] [V] [TRT] *************** Autotuning Reformat:Float(150528,672,3,1) -> Float(4704,672:32,3,1) ***************\n",
      "[04/10/2022-15:17:28] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:17:28] [V] [TRT] Tactic: 1002 Time: 1.03886\n",
      "[04/10/2022-15:17:28] [V] [TRT] Tactic: 0 Time: 2.0262\n",
      "[04/10/2022-15:17:28] [V] [TRT] Fastest Tactic: 1002 Time: 1.03886\n",
      "[04/10/2022-15:17:28] [V] [TRT] *************** Autotuning Reformat:Float(150528,672,3,1) -> Half(150528,672,3,1) ***************\n",
      "[04/10/2022-15:17:28] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:17:28] [V] [TRT] Tactic: 1002 Time: 1.64524\n",
      "[04/10/2022-15:17:28] [V] [TRT] Tactic: 0 Time: 0.925853\n",
      "[04/10/2022-15:17:28] [V] [TRT] Fastest Tactic: 0 Time: 0.925853\n",
      "[04/10/2022-15:17:28] [V] [TRT] *************** Autotuning Reformat:Float(150528,672,3,1) -> Half(75264,672:2,3,1) ***************\n",
      "[04/10/2022-15:17:28] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:17:29] [V] [TRT] Tactic: 1002 Time: 1.30012\n",
      "[04/10/2022-15:17:29] [V] [TRT] Tactic: 0 Time: 0.741341\n",
      "[04/10/2022-15:17:29] [V] [TRT] Fastest Tactic: 0 Time: 0.741341\n",
      "[04/10/2022-15:17:29] [V] [TRT] *************** Autotuning format combination: Float(150528,672,3,1) -> Float(150528,50176,224,1) ***************\n",
      "[04/10/2022-15:17:29] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/bn_data/FusedBatchNormV3__74 (Shuffle)\n",
      "[04/10/2022-15:17:29] [V] [TRT] Tactic: 0 Time: 1.22954\n",
      "[04/10/2022-15:17:29] [V] [TRT] Fastest Tactic: 0 Time: 1.22954\n",
      "[04/10/2022-15:17:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[04/10/2022-15:17:29] [V] [TRT] *************** Autotuning format combination: Float(150528,1,672,224) -> Float(150528,1,672,3) ***************\n",
      "[04/10/2022-15:17:29] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/bn_data/FusedBatchNormV3__74 (Shuffle)\n",
      "[04/10/2022-15:17:29] [V] [TRT] Tactic: 0 Time: 1.35193\n",
      "[04/10/2022-15:17:29] [V] [TRT] Fastest Tactic: 0 Time: 1.35193\n",
      "[04/10/2022-15:17:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[04/10/2022-15:17:29] [V] [TRT] *************** Autotuning format combination: Float(4704,672:32,3,1) -> Float(50176,50176:32,224,1) ***************\n",
      "[04/10/2022-15:17:29] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/bn_data/FusedBatchNormV3__74 (Shuffle)\n",
      "[04/10/2022-15:17:29] [V] [TRT] Tactic: 0 Time: 6.99671\n",
      "[04/10/2022-15:17:29] [V] [TRT] Fastest Tactic: 0 Time: 6.99671\n",
      "[04/10/2022-15:17:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[04/10/2022-15:17:29] [V] [TRT] *************** Autotuning format combination: Half(150528,672,3,1) -> Half(150528,50176,224,1) ***************\n",
      "[04/10/2022-15:17:29] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/bn_data/FusedBatchNormV3__74 (Shuffle)\n",
      "[04/10/2022-15:17:29] [V] [TRT] Tactic: 0 Time: 0.333704\n",
      "[04/10/2022-15:17:29] [V] [TRT] Fastest Tactic: 0 Time: 0.333704\n",
      "[04/10/2022-15:17:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[04/10/2022-15:17:29] [V] [TRT] *************** Autotuning format combination: Half(75264,672:2,3,1) -> Half(100352,50176:2,224,1) ***************\n",
      "[04/10/2022-15:17:29] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/bn_data/FusedBatchNormV3__74 (Shuffle)\n",
      "[04/10/2022-15:17:29] [V] [TRT] Tactic: 0 Time: 0.583236\n",
      "[04/10/2022-15:17:29] [V] [TRT] Fastest Tactic: 0 Time: 0.583236\n",
      "[04/10/2022-15:17:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0\n",
      "[04/10/2022-15:17:29] [V] [TRT] *************** Autotuning Reformat:Float(150528,50176,224,1) -> Float(150528,1,672,3) ***************\n",
      "[04/10/2022-15:17:29] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:17:29] [V] [TRT] Tactic: 1002 Time: 5.6061\n",
      "[04/10/2022-15:17:29] [V] [TRT] Tactic: 0 Time: 0.383522\n",
      "[04/10/2022-15:17:29] [V] [TRT] Fastest Tactic: 0 Time: 0.383522\n",
      "[04/10/2022-15:17:29] [V] [TRT] *************** Autotuning Reformat:Float(150528,50176,224,1) -> Half(150528,50176,224,1) ***************\n",
      "[04/10/2022-15:17:29] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:17:29] [V] [TRT] Tactic: 1002 Time: 0.322956\n",
      "[04/10/2022-15:17:29] [V] [TRT] Tactic: 0 Time: 0.234342\n",
      "[04/10/2022-15:17:29] [V] [TRT] Fastest Tactic: 0 Time: 0.234342\n",
      "[04/10/2022-15:17:29] [V] [TRT] *************** Autotuning Reformat:Float(150528,50176,224,1) -> Half(100352,50176:2,224,1) ***************\n",
      "[04/10/2022-15:17:29] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:17:29] [V] [TRT] Tactic: 1002 Time: 0.623314\n",
      "[04/10/2022-15:17:29] [V] [TRT] Tactic: 0 Time: 0.24776\n",
      "[04/10/2022-15:17:29] [V] [TRT] Fastest Tactic: 0 Time: 0.24776\n",
      "[04/10/2022-15:17:29] [V] [TRT] *************** Autotuning Reformat:Float(150528,1,672,3) -> Float(150528,50176,224,1) ***************\n",
      "[04/10/2022-15:17:29] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:17:29] [V] [TRT] Tactic: 1002 Time: 3.80047\n",
      "[04/10/2022-15:17:29] [V] [TRT] Tactic: 0 Time: 0.210098\n",
      "[04/10/2022-15:17:29] [V] [TRT] Fastest Tactic: 0 Time: 0.210098\n",
      "[04/10/2022-15:17:29] [V] [TRT] *************** Autotuning Reformat:Float(150528,1,672,3) -> Half(150528,50176,224,1) ***************\n",
      "[04/10/2022-15:17:29] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:17:29] [V] [TRT] Tactic: 1002 Time: 1.47834\n",
      "[04/10/2022-15:17:29] [V] [TRT] Tactic: 0 Time: 0.213106\n",
      "[04/10/2022-15:17:29] [V] [TRT] Fastest Tactic: 0 Time: 0.213106\n",
      "[04/10/2022-15:17:29] [V] [TRT] *************** Autotuning Reformat:Float(150528,1,672,3) -> Half(100352,50176:2,224,1) ***************\n",
      "[04/10/2022-15:17:29] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:17:29] [V] [TRT] Tactic: 1002 Time: 0.205007\n",
      "[04/10/2022-15:17:29] [V] [TRT] Tactic: 0 Time: 0.33545\n",
      "[04/10/2022-15:17:29] [V] [TRT] Fastest Tactic: 1002 Time: 0.205007\n",
      "[04/10/2022-15:17:29] [V] [TRT] *************** Autotuning Reformat:Float(50176,50176:32,224,1) -> Float(150528,50176,224,1) ***************\n",
      "[04/10/2022-15:17:29] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:17:29] [V] [TRT] Tactic: 1002 Time: 3.48531\n",
      "[04/10/2022-15:17:29] [V] [TRT] Tactic: 0 Time: 0.508626\n",
      "[04/10/2022-15:17:29] [V] [TRT] Fastest Tactic: 0 Time: 0.508626\n",
      "[04/10/2022-15:17:29] [V] [TRT] *************** Autotuning Reformat:Float(50176,50176:32,224,1) -> Float(150528,1,672,3) ***************\n",
      "[04/10/2022-15:17:29] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:17:29] [V] [TRT] Tactic: 1002 Time: 2.02517\n",
      "[04/10/2022-15:17:29] [V] [TRT] Tactic: 0 Time: 0.288737\n",
      "[04/10/2022-15:17:29] [V] [TRT] Fastest Tactic: 0 Time: 0.288737\n",
      "[04/10/2022-15:17:29] [V] [TRT] *************** Autotuning Reformat:Float(50176,50176:32,224,1) -> Half(150528,50176,224,1) ***************\n",
      "[04/10/2022-15:17:29] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:17:29] [V] [TRT] Tactic: 1002 Time: 1.65224\n",
      "[04/10/2022-15:17:29] [V] [TRT] Tactic: 0 Time: 0.498522\n",
      "[04/10/2022-15:17:29] [V] [TRT] Fastest Tactic: 0 Time: 0.498522\n",
      "[04/10/2022-15:17:29] [V] [TRT] *************** Autotuning Reformat:Float(50176,50176:32,224,1) -> Half(100352,50176:2,224,1) ***************\n",
      "[04/10/2022-15:17:29] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:17:29] [V] [TRT] Tactic: 1002 Time: 0.350983\n",
      "[04/10/2022-15:17:29] [V] [TRT] Tactic: 0 Time: 0.604955\n",
      "[04/10/2022-15:17:29] [V] [TRT] Fastest Tactic: 1002 Time: 0.350983\n",
      "[04/10/2022-15:17:29] [V] [TRT] *************** Autotuning Reformat:Half(150528,50176,224,1) -> Float(150528,50176,224,1) ***************\n",
      "[04/10/2022-15:17:29] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:17:29] [V] [TRT] Tactic: 1002 Time: 0.19459\n",
      "[04/10/2022-15:17:29] [V] [TRT] Tactic: 0 Time: 0.136497\n",
      "[04/10/2022-15:17:29] [V] [TRT] Fastest Tactic: 0 Time: 0.136497\n",
      "[04/10/2022-15:17:29] [V] [TRT] *************** Autotuning Reformat:Half(150528,50176,224,1) -> Float(150528,1,672,3) ***************\n",
      "[04/10/2022-15:17:29] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:17:29] [V] [TRT] Tactic: 1002 Time: 1.60757\n",
      "[04/10/2022-15:17:29] [V] [TRT] Tactic: 0 Time: 0.230938\n",
      "[04/10/2022-15:17:29] [V] [TRT] Fastest Tactic: 0 Time: 0.230938\n",
      "[04/10/2022-15:17:29] [V] [TRT] *************** Autotuning Reformat:Half(150528,50176,224,1) -> Half(100352,50176:2,224,1) ***************\n",
      "[04/10/2022-15:17:29] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:17:30] [V] [TRT] Tactic: 1002 Time: 0.185983\n",
      "[04/10/2022-15:17:30] [V] [TRT] Tactic: 0 Time: 0.167884\n",
      "[04/10/2022-15:17:30] [V] [TRT] Fastest Tactic: 0 Time: 0.167884\n",
      "[04/10/2022-15:17:30] [V] [TRT] *************** Autotuning Reformat:Half(100352,50176:2,224,1) -> Float(150528,50176,224,1) ***************\n",
      "[04/10/2022-15:17:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:17:30] [V] [TRT] Tactic: 1002 Time: 1.48837\n",
      "[04/10/2022-15:17:30] [V] [TRT] Tactic: 0 Time: 0.112871\n",
      "[04/10/2022-15:17:30] [V] [TRT] Fastest Tactic: 0 Time: 0.112871\n",
      "[04/10/2022-15:17:30] [V] [TRT] *************** Autotuning Reformat:Half(100352,50176:2,224,1) -> Float(150528,1,672,3) ***************\n",
      "[04/10/2022-15:17:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:17:30] [V] [TRT] Tactic: 1002 Time: 1.58525\n",
      "[04/10/2022-15:17:30] [V] [TRT] Tactic: 0 Time: 0.268366\n",
      "[04/10/2022-15:17:30] [V] [TRT] Fastest Tactic: 0 Time: 0.268366\n",
      "[04/10/2022-15:17:30] [V] [TRT] *************** Autotuning Reformat:Half(100352,50176:2,224,1) -> Half(150528,50176,224,1) ***************\n",
      "[04/10/2022-15:17:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:17:30] [V] [TRT] Tactic: 1002 Time: 4.10105\n",
      "[04/10/2022-15:17:30] [V] [TRT] Tactic: 0 Time: 0.109609\n",
      "[04/10/2022-15:17:30] [V] [TRT] Fastest Tactic: 0 Time: 0.109609\n",
      "[04/10/2022-15:17:30] [V] [TRT] *************** Autotuning format combination: Float(150528,50176,224,1) -> Float(150528,50176,224,1) ***************\n",
      "[04/10/2022-15:17:30] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/bn_data/FusedBatchNormV3 (Scale)\n",
      "[04/10/2022-15:17:30] [V] [TRT] Tactic: 0 Time: 0.101986\n",
      "[04/10/2022-15:17:30] [V] [TRT] Fastest Tactic: 0 Time: 0.101986\n",
      "[04/10/2022-15:17:30] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Scale Tactic: 0\n",
      "[04/10/2022-15:17:30] [V] [TRT] *************** Autotuning format combination: Float(150528,1,672,3) -> Float(150528,1,672,3) ***************\n",
      "[04/10/2022-15:17:30] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/bn_data/FusedBatchNormV3 (Scale)\n",
      "[04/10/2022-15:17:30] [V] [TRT] Scale has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:17:30] [V] [TRT] *************** Autotuning format combination: Half(150528,50176,224,1) -> Half(150528,50176,224,1) ***************\n",
      "[04/10/2022-15:17:30] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/bn_data/FusedBatchNormV3 (Scale)\n",
      "[04/10/2022-15:17:30] [V] [TRT] Tactic: 0 Time: 0.0948633\n",
      "[04/10/2022-15:17:30] [V] [TRT] Fastest Tactic: 0 Time: 0.0948633\n",
      "[04/10/2022-15:17:30] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Scale Tactic: 0\n",
      "[04/10/2022-15:17:30] [V] [TRT] *************** Autotuning format combination: Half(100352,50176:2,224,1) -> Half(100352,50176:2,224,1) ***************\n",
      "[04/10/2022-15:17:30] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/bn_data/FusedBatchNormV3 (Scale)\n",
      "[04/10/2022-15:17:30] [V] [TRT] Tactic: 0 Time: 0.135566\n",
      "[04/10/2022-15:17:30] [V] [TRT] Fastest Tactic: 0 Time: 0.135566\n",
      "[04/10/2022-15:17:30] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Scale Tactic: 0\n",
      "[04/10/2022-15:17:30] [V] [TRT] *************** Autotuning Reformat:Float(150528,50176,224,1) -> Float(150528,1,672,3) ***************\n",
      "[04/10/2022-15:17:30] [V] [TRT] *************** Autotuning Reformat:Float(150528,50176,224,1) -> Half(150528,50176,224,1) ***************\n",
      "[04/10/2022-15:17:30] [V] [TRT] *************** Autotuning Reformat:Float(150528,50176,224,1) -> Half(100352,50176:2,224,1) ***************\n",
      "[04/10/2022-15:17:30] [V] [TRT] *************** Autotuning Reformat:Float(150528,1,672,3) -> Float(150528,50176,224,1) ***************\n",
      "[04/10/2022-15:17:30] [V] [TRT] *************** Autotuning Reformat:Float(150528,1,672,3) -> Half(150528,50176,224,1) ***************\n",
      "[04/10/2022-15:17:30] [V] [TRT] *************** Autotuning Reformat:Float(150528,1,672,3) -> Half(100352,50176:2,224,1) ***************\n",
      "[04/10/2022-15:17:30] [V] [TRT] *************** Autotuning Reformat:Half(150528,50176,224,1) -> Float(150528,50176,224,1) ***************\n",
      "[04/10/2022-15:17:30] [V] [TRT] *************** Autotuning Reformat:Half(150528,50176,224,1) -> Float(150528,1,672,3) ***************\n",
      "[04/10/2022-15:17:30] [V] [TRT] *************** Autotuning Reformat:Half(150528,50176,224,1) -> Half(100352,50176:2,224,1) ***************\n",
      "[04/10/2022-15:17:30] [V] [TRT] *************** Autotuning Reformat:Half(100352,50176:2,224,1) -> Float(150528,50176,224,1) ***************\n",
      "[04/10/2022-15:17:30] [V] [TRT] *************** Autotuning Reformat:Half(100352,50176:2,224,1) -> Float(150528,1,672,3) ***************\n",
      "[04/10/2022-15:17:30] [V] [TRT] *************** Autotuning Reformat:Half(100352,50176:2,224,1) -> Half(150528,50176,224,1) ***************\n",
      "[04/10/2022-15:17:30] [V] [TRT] *************** Autotuning format combination: Float(150528,50176,224,1) -> Float(802816,12544,112,1) ***************\n",
      "[04/10/2022-15:17:30] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/conv0/Conv2D + StatefulPartitionedCall/model_1/relu0/Relu (CudaDepthwiseConvolution)\n",
      "[04/10/2022-15:17:30] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:17:30] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/conv0/Conv2D + StatefulPartitionedCall/model_1/relu0/Relu (FusedConvActConvolution)\n",
      "[04/10/2022-15:17:30] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:17:30] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/conv0/Conv2D + StatefulPartitionedCall/model_1/relu0/Relu (CudnnConvolution)\n",
      "[04/10/2022-15:17:34] [V] [TRT] Tactic: 0 Time: 8.64441\n",
      "[04/10/2022-15:17:35] [V] [TRT] Tactic: 1 Time: 2.86557\n",
      "[04/10/2022-15:17:35] [V] [TRT] Tactic: 2 Time: 5.93769\n",
      "[04/10/2022-15:17:36] [V] [TRT] Tactic: 5 Time: 103.366\n",
      "[04/10/2022-15:17:36] [V] [TRT] Fastest Tactic: 1 Time: 2.86557\n",
      "[04/10/2022-15:17:36] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/conv0/Conv2D + StatefulPartitionedCall/model_1/relu0/Relu (CaskConvolution)\n",
      "[04/10/2022-15:17:36] [V] [TRT] StatefulPartitionedCall/model_1/conv0/Conv2D + StatefulPartitionedCall/model_1/relu0/Relu Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758\n",
      "[04/10/2022-15:17:36] [V] [TRT] Tactic: 1062367460111450758 Time: 1.89295\n",
      "[04/10/2022-15:17:36] [V] [TRT] StatefulPartitionedCall/model_1/conv0/Conv2D + StatefulPartitionedCall/model_1/relu0/Relu Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v0 Tactic: 1754984623894446479\n",
      "[04/10/2022-15:17:36] [V] [TRT] Tactic: 1754984623894446479 Time: 1.9508\n",
      "[04/10/2022-15:17:36] [V] [TRT] StatefulPartitionedCall/model_1/conv0/Conv2D + StatefulPartitionedCall/model_1/relu0/Relu Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v0 Tactic: 3611739942397549984\n",
      "[04/10/2022-15:17:37] [V] [TRT] Tactic: 3611739942397549984 Time: 2.98148\n",
      "[04/10/2022-15:17:37] [V] [TRT] StatefulPartitionedCall/model_1/conv0/Conv2D + StatefulPartitionedCall/model_1/relu0/Relu Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379\n",
      "[04/10/2022-15:17:37] [V] [TRT] Tactic: 4337000649858996379 Time: 1.51304\n",
      "[04/10/2022-15:17:37] [V] [TRT] StatefulPartitionedCall/model_1/conv0/Conv2D + StatefulPartitionedCall/model_1/relu0/Relu Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441\n",
      "[04/10/2022-15:17:37] [V] [TRT] Tactic: 4501471010995462441 Time: 2.98983\n",
      "[04/10/2022-15:17:37] [V] [TRT] StatefulPartitionedCall/model_1/conv0/Conv2D + StatefulPartitionedCall/model_1/relu0/Relu Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056\n",
      "[04/10/2022-15:17:37] [V] [TRT] Tactic: 6645123197870846056 Time: 1.47359\n",
      "[04/10/2022-15:17:37] [V] [TRT] StatefulPartitionedCall/model_1/conv0/Conv2D + StatefulPartitionedCall/model_1/relu0/Relu Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713\n",
      "[04/10/2022-15:17:37] [V] [TRT] Tactic: -9137461792520977713 Time: 2.96364\n",
      "[04/10/2022-15:17:37] [V] [TRT] StatefulPartitionedCall/model_1/conv0/Conv2D + StatefulPartitionedCall/model_1/relu0/Relu Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730\n",
      "[04/10/2022-15:17:37] [V] [TRT] Tactic: -8262349710178828730 Time: 2.99688\n",
      "[04/10/2022-15:17:37] [V] [TRT] StatefulPartitionedCall/model_1/conv0/Conv2D + StatefulPartitionedCall/model_1/relu0/Relu Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v0 Tactic: -8133971918129952780\n",
      "[04/10/2022-15:17:37] [V] [TRT] Tactic: -8133971918129952780 Time: 1.55855\n",
      "[04/10/2022-15:17:37] [V] [TRT] StatefulPartitionedCall/model_1/conv0/Conv2D + StatefulPartitionedCall/model_1/relu0/Relu Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144\n",
      "[04/10/2022-15:17:37] [V] [TRT] Tactic: -6092040395344634144 Time: 1.95294\n",
      "[04/10/2022-15:17:37] [V] [TRT] StatefulPartitionedCall/model_1/conv0/Conv2D + StatefulPartitionedCall/model_1/relu0/Relu Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159\n",
      "[04/10/2022-15:17:37] [V] [TRT] Tactic: -4787320710726427159 Time: 1.93492\n",
      "[04/10/2022-15:17:37] [V] [TRT] StatefulPartitionedCall/model_1/conv0/Conv2D + StatefulPartitionedCall/model_1/relu0/Relu Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241\n",
      "[04/10/2022-15:17:37] [V] [TRT] Tactic: -1218658103698133241 Time: 1.58451\n",
      "[04/10/2022-15:17:37] [V] [TRT] Fastest Tactic: 6645123197870846056 Time: 1.47359\n",
      "[04/10/2022-15:17:37] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 6645123197870846056\n",
      "[04/10/2022-15:17:37] [V] [TRT] *************** Autotuning format combination: Float(150528,1,672,3) -> Float(802816,1,7168,64) ***************\n",
      "[04/10/2022-15:17:37] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/conv0/Conv2D + StatefulPartitionedCall/model_1/relu0/Relu (CudnnConvolution)\n",
      "[04/10/2022-15:17:37] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:17:37] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/conv0/Conv2D + StatefulPartitionedCall/model_1/relu0/Relu (CaskConvolution)\n",
      "[04/10/2022-15:17:37] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:17:37] [V] [TRT] *************** Autotuning format combination: Half(150528,50176,224,1) -> Half(802816,12544,112,1) ***************\n",
      "[04/10/2022-15:17:37] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/conv0/Conv2D + StatefulPartitionedCall/model_1/relu0/Relu (CudnnConvolution)\n",
      "[04/10/2022-15:17:37] [V] [TRT] Tactic: 0 Time: 3.7895\n",
      "[04/10/2022-15:17:37] [V] [TRT] Tactic: 1 Time: 3.29466\n",
      "[04/10/2022-15:17:37] [V] [TRT] Tactic: 2 Time: 4.82167\n",
      "[04/10/2022-15:17:39] [V] [TRT] Tactic: 5 Time: 102.173\n",
      "[04/10/2022-15:17:39] [V] [TRT] Fastest Tactic: 1 Time: 3.29466\n",
      "[04/10/2022-15:17:39] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/conv0/Conv2D + StatefulPartitionedCall/model_1/relu0/Relu (CaskConvolution)\n",
      "[04/10/2022-15:17:39] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:17:39] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 1\n",
      "[04/10/2022-15:17:39] [V] [TRT] *************** Autotuning format combination: Half(100352,50176:2,224,1) -> Half(401408,12544:2,112,1) ***************\n",
      "[04/10/2022-15:17:39] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/conv0/Conv2D + StatefulPartitionedCall/model_1/relu0/Relu (FusedConvActConvolution)\n",
      "[04/10/2022-15:17:39] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:17:39] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/conv0/Conv2D + StatefulPartitionedCall/model_1/relu0/Relu (CudnnConvolution)\n",
      "[04/10/2022-15:17:39] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:17:39] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/conv0/Conv2D + StatefulPartitionedCall/model_1/relu0/Relu (CaskConvolution)\n",
      "[04/10/2022-15:17:39] [V] [TRT] StatefulPartitionedCall/model_1/conv0/Conv2D + StatefulPartitionedCall/model_1/relu0/Relu Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998\n",
      "[04/10/2022-15:17:39] [V] [TRT] Tactic: 3564772625446233998 Time: 1.31704\n",
      "[04/10/2022-15:17:39] [V] [TRT] StatefulPartitionedCall/model_1/conv0/Conv2D + StatefulPartitionedCall/model_1/relu0/Relu Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_large_nn_v1 Tactic: 3650389455493082349\n",
      "[04/10/2022-15:17:39] [V] [TRT] Tactic: 3650389455493082349 Time: 1.35292\n",
      "[04/10/2022-15:17:39] [V] [TRT] StatefulPartitionedCall/model_1/conv0/Conv2D + StatefulPartitionedCall/model_1/relu0/Relu Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848\n",
      "[04/10/2022-15:17:39] [V] [TRT] Tactic: 7205456024582378848 Time: 1.02984\n",
      "[04/10/2022-15:17:39] [V] [TRT] StatefulPartitionedCall/model_1/conv0/Conv2D + StatefulPartitionedCall/model_1/relu0/Relu Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_large_nn_v1 Tactic: -6490690591794140522\n",
      "[04/10/2022-15:17:39] [V] [TRT] Tactic: -6490690591794140522 Time: 1.03338\n",
      "[04/10/2022-15:17:39] [V] [TRT] StatefulPartitionedCall/model_1/conv0/Conv2D + StatefulPartitionedCall/model_1/relu0/Relu Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_large_nn_v1 Tactic: -4686027666808657977\n",
      "[04/10/2022-15:17:39] [V] [TRT] Tactic: -4686027666808657977 Time: 2.03618\n",
      "[04/10/2022-15:17:39] [V] [TRT] StatefulPartitionedCall/model_1/conv0/Conv2D + StatefulPartitionedCall/model_1/relu0/Relu Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110\n",
      "[04/10/2022-15:17:39] [V] [TRT] Tactic: -3898373634979201110 Time: 2.01451\n",
      "[04/10/2022-15:17:39] [V] [TRT] Fastest Tactic: 7205456024582378848 Time: 1.02984\n",
      "[04/10/2022-15:17:39] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 7205456024582378848\n",
      "[04/10/2022-15:17:39] [V] [TRT] *************** Autotuning Reformat:Float(802816,12544,112,1) -> Half(802816,12544,112,1) ***************\n",
      "[04/10/2022-15:17:39] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:17:39] [V] [TRT] Tactic: 1002 Time: 1.00013\n",
      "[04/10/2022-15:17:39] [V] [TRT] Tactic: 0 Time: 0.815983\n",
      "[04/10/2022-15:17:39] [V] [TRT] Fastest Tactic: 0 Time: 0.815983\n",
      "[04/10/2022-15:17:39] [V] [TRT] *************** Autotuning Reformat:Float(802816,12544,112,1) -> Half(401408,12544:2,112,1) ***************\n",
      "[04/10/2022-15:17:39] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:17:39] [V] [TRT] Tactic: 1002 Time: 1.19424\n",
      "[04/10/2022-15:17:39] [V] [TRT] Tactic: 0 Time: 0.65276\n",
      "[04/10/2022-15:17:39] [V] [TRT] Fastest Tactic: 0 Time: 0.65276\n",
      "[04/10/2022-15:17:39] [V] [TRT] *************** Autotuning Reformat:Float(802816,1,7168,64) -> Float(802816,12544,112,1) ***************\n",
      "[04/10/2022-15:17:39] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:17:39] [V] [TRT] Tactic: 1002 Time: 0.95724\n",
      "[04/10/2022-15:17:39] [V] [TRT] Tactic: 0 Time: 2.70883\n",
      "[04/10/2022-15:17:39] [V] [TRT] Fastest Tactic: 1002 Time: 0.95724\n",
      "[04/10/2022-15:17:39] [V] [TRT] *************** Autotuning Reformat:Float(802816,1,7168,64) -> Half(802816,12544,112,1) ***************\n",
      "[04/10/2022-15:17:39] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:17:39] [V] [TRT] Tactic: 1002 Time: 0.747227\n",
      "[04/10/2022-15:17:39] [V] [TRT] Tactic: 0 Time: 2.65922\n",
      "[04/10/2022-15:17:39] [V] [TRT] Fastest Tactic: 1002 Time: 0.747227\n",
      "[04/10/2022-15:17:39] [V] [TRT] *************** Autotuning Reformat:Float(802816,1,7168,64) -> Half(401408,12544:2,112,1) ***************\n",
      "[04/10/2022-15:17:39] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:17:39] [V] [TRT] Tactic: 1002 Time: 1.0199\n",
      "[04/10/2022-15:17:39] [V] [TRT] Tactic: 0 Time: 2.84734\n",
      "[04/10/2022-15:17:39] [V] [TRT] Fastest Tactic: 1002 Time: 1.0199\n",
      "[04/10/2022-15:17:39] [V] [TRT] *************** Autotuning Reformat:Half(802816,12544,112,1) -> Float(802816,12544,112,1) ***************\n",
      "[04/10/2022-15:17:39] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:17:39] [V] [TRT] Tactic: 1002 Time: 1.00978\n",
      "[04/10/2022-15:17:40] [V] [TRT] Tactic: 0 Time: 0.696347\n",
      "[04/10/2022-15:17:40] [V] [TRT] Fastest Tactic: 0 Time: 0.696347\n",
      "[04/10/2022-15:17:40] [V] [TRT] *************** Autotuning Reformat:Half(802816,12544,112,1) -> Half(401408,12544:2,112,1) ***************\n",
      "[04/10/2022-15:17:40] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:17:40] [V] [TRT] Tactic: 1002 Time: 0.678737\n",
      "[04/10/2022-15:17:40] [V] [TRT] Tactic: 0 Time: 0.645684\n",
      "[04/10/2022-15:17:40] [V] [TRT] Fastest Tactic: 0 Time: 0.645684\n",
      "[04/10/2022-15:17:40] [V] [TRT] *************** Autotuning Reformat:Half(401408,12544:2,112,1) -> Float(802816,12544,112,1) ***************\n",
      "[04/10/2022-15:17:40] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:17:40] [V] [TRT] Tactic: 1002 Time: 0.971849\n",
      "[04/10/2022-15:17:40] [V] [TRT] Tactic: 0 Time: 0.564095\n",
      "[04/10/2022-15:17:40] [V] [TRT] Fastest Tactic: 0 Time: 0.564095\n",
      "[04/10/2022-15:17:40] [V] [TRT] *************** Autotuning Reformat:Half(401408,12544:2,112,1) -> Half(802816,12544,112,1) ***************\n",
      "[04/10/2022-15:17:40] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:17:40] [V] [TRT] Tactic: 1002 Time: 1.50162\n",
      "[04/10/2022-15:17:40] [V] [TRT] Tactic: 0 Time: 0.551387\n",
      "[04/10/2022-15:17:40] [V] [TRT] Fastest Tactic: 0 Time: 0.551387\n",
      "[04/10/2022-15:17:40] [V] [TRT] *************** Autotuning format combination: Float(802816,12544,112,1) -> Float(831744,12996,114,1) ***************\n",
      "[04/10/2022-15:17:40] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/zero_padding2d_1/Pad (Padding)\n",
      "[04/10/2022-15:17:40] [V] [TRT] Tactic: 0 Time: 0.70444\n",
      "[04/10/2022-15:17:40] [V] [TRT] Fastest Tactic: 0 Time: 0.70444\n",
      "[04/10/2022-15:17:40] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Padding Tactic: 0\n",
      "[04/10/2022-15:17:40] [V] [TRT] *************** Autotuning format combination: Half(802816,12544,112,1) -> Half(831744,12996,114,1) ***************\n",
      "[04/10/2022-15:17:40] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/zero_padding2d_1/Pad (Padding)\n",
      "[04/10/2022-15:17:40] [V] [TRT] Tactic: 0 Time: 0.720085\n",
      "[04/10/2022-15:17:40] [V] [TRT] Fastest Tactic: 0 Time: 0.720085\n",
      "[04/10/2022-15:17:40] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Padding Tactic: 0\n",
      "[04/10/2022-15:17:40] [V] [TRT] *************** Autotuning format combination: Half(401408,12544:2,112,1) -> Half(415872,12996:2,114,1) ***************\n",
      "[04/10/2022-15:17:40] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/zero_padding2d_1/Pad (Padding)\n",
      "[04/10/2022-15:17:40] [V] [TRT] Tactic: 0 Time: 0.364837\n",
      "[04/10/2022-15:17:40] [V] [TRT] Fastest Tactic: 0 Time: 0.364837\n",
      "[04/10/2022-15:17:40] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Padding Tactic: 0\n",
      "[04/10/2022-15:17:40] [V] [TRT] *************** Autotuning Reformat:Float(831744,12996,114,1) -> Half(831744,12996,114,1) ***************\n",
      "[04/10/2022-15:17:40] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:17:40] [V] [TRT] Tactic: 1002 Time: 1.03997\n",
      "[04/10/2022-15:17:40] [V] [TRT] Tactic: 0 Time: 0.844779\n",
      "[04/10/2022-15:17:40] [V] [TRT] Fastest Tactic: 0 Time: 0.844779\n",
      "[04/10/2022-15:17:40] [V] [TRT] *************** Autotuning Reformat:Float(831744,12996,114,1) -> Half(415872,12996:2,114,1) ***************\n",
      "[04/10/2022-15:17:40] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:17:40] [V] [TRT] Tactic: 1002 Time: 1.28043\n",
      "[04/10/2022-15:17:40] [V] [TRT] Tactic: 0 Time: 0.675794\n",
      "[04/10/2022-15:17:40] [V] [TRT] Fastest Tactic: 0 Time: 0.675794\n",
      "[04/10/2022-15:17:40] [V] [TRT] *************** Autotuning Reformat:Half(831744,12996,114,1) -> Float(831744,12996,114,1) ***************\n",
      "[04/10/2022-15:17:40] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:17:40] [V] [TRT] Tactic: 1002 Time: 1.05572\n",
      "[04/10/2022-15:17:40] [V] [TRT] Tactic: 0 Time: 0.721881\n",
      "[04/10/2022-15:17:40] [V] [TRT] Fastest Tactic: 0 Time: 0.721881\n",
      "[04/10/2022-15:17:40] [V] [TRT] *************** Autotuning Reformat:Half(831744,12996,114,1) -> Half(415872,12996:2,114,1) ***************\n",
      "[04/10/2022-15:17:40] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:17:40] [V] [TRT] Tactic: 1002 Time: 0.751068\n",
      "[04/10/2022-15:17:40] [V] [TRT] Tactic: 0 Time: 0.668646\n",
      "[04/10/2022-15:17:40] [V] [TRT] Fastest Tactic: 0 Time: 0.668646\n",
      "[04/10/2022-15:17:40] [V] [TRT] *************** Autotuning Reformat:Half(415872,12996:2,114,1) -> Float(831744,12996,114,1) ***************\n",
      "[04/10/2022-15:17:40] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:17:40] [V] [TRT] Tactic: 1002 Time: 1.20346\n",
      "[04/10/2022-15:17:40] [V] [TRT] Tactic: 0 Time: 0.585853\n",
      "[04/10/2022-15:17:40] [V] [TRT] Fastest Tactic: 0 Time: 0.585853\n",
      "[04/10/2022-15:17:40] [V] [TRT] *************** Autotuning Reformat:Half(415872,12996:2,114,1) -> Half(831744,12996,114,1) ***************\n",
      "[04/10/2022-15:17:40] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:17:40] [V] [TRT] Tactic: 1002 Time: 1.87079\n",
      "[04/10/2022-15:17:40] [V] [TRT] Tactic: 0 Time: 0.572474\n",
      "[04/10/2022-15:17:40] [V] [TRT] Fastest Tactic: 0 Time: 0.572474\n",
      "[04/10/2022-15:17:40] [V] [TRT] *************** Autotuning format combination: Float(831744,12996,114,1) -> Float(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:40] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/pooling0/MaxPool (TiledPooling)\n",
      "[04/10/2022-15:17:40] [V] [TRT] Tactic: 257 Time: 0.985196\n",
      "[04/10/2022-15:17:40] [V] [TRT] Tactic: 65793 Time: 0.831992\n",
      "[04/10/2022-15:17:40] [V] [TRT] Tactic: 131329 Time: 1.18061\n",
      "[04/10/2022-15:17:40] [V] [TRT] Tactic: 196865 Time: 1.24082\n",
      "[04/10/2022-15:17:40] [V] [TRT] Tactic: 262401 Time: 1.01805\n",
      "[04/10/2022-15:17:40] [V] [TRT] Tactic: 327937 Time: 1.08263\n",
      "[04/10/2022-15:17:40] [V] [TRT] Tactic: 393473 Time: 1.13025\n",
      "[04/10/2022-15:17:40] [V] [TRT] Tactic: 459009 Time: 0.648437\n",
      "[04/10/2022-15:17:40] [V] [TRT] Tactic: 524545 Time: 0.542597\n",
      "[04/10/2022-15:17:40] [V] [TRT] Tactic: 590081 Time: 0.77722\n",
      "[04/10/2022-15:17:40] [V] [TRT] Tactic: 655617 Time: 0.782122\n",
      "[04/10/2022-15:17:41] [V] [TRT] Tactic: 721153 Time: 0.635586\n",
      "[04/10/2022-15:17:41] [V] [TRT] Tactic: 786689 Time: 0.679661\n",
      "[04/10/2022-15:17:41] [V] [TRT] Tactic: 852225 Time: 0.728347\n",
      "[04/10/2022-15:17:41] [V] [TRT] Tactic: 917761 Time: 0.568138\n",
      "[04/10/2022-15:17:41] [V] [TRT] Tactic: 983297 Time: 0.458144\n",
      "[04/10/2022-15:17:41] [V] [TRT] Tactic: 1048833 Time: 0.658249\n",
      "[04/10/2022-15:17:41] [V] [TRT] Tactic: 1114369 Time: 0.634948\n",
      "[04/10/2022-15:17:41] [V] [TRT] Tactic: 1179905 Time: 0.521341\n",
      "[04/10/2022-15:17:41] [V] [TRT] Tactic: 1245441 Time: 0.571471\n",
      "[04/10/2022-15:17:41] [V] [TRT] Tactic: 1310977 Time: 0.606504\n",
      "[04/10/2022-15:17:41] [V] [TRT] Tactic: 1376513 Time: 0.562207\n",
      "[04/10/2022-15:17:41] [V] [TRT] Tactic: 1442049 Time: 0.442363\n",
      "[04/10/2022-15:17:41] [V] [TRT] Tactic: 1507585 Time: 0.55487\n",
      "[04/10/2022-15:17:41] [V] [TRT] Tactic: 1573121 Time: 0.532396\n",
      "[04/10/2022-15:17:41] [V] [TRT] Tactic: 1638657 Time: 0.438913\n",
      "[04/10/2022-15:17:41] [V] [TRT] Tactic: 1704193 Time: 0.48155\n",
      "[04/10/2022-15:17:41] [V] [TRT] Tactic: 1769729 Time: 0.514909\n",
      "[04/10/2022-15:17:41] [V] [TRT] Tactic: 1835265 Time: 0.569147\n",
      "[04/10/2022-15:17:41] [V] [TRT] Tactic: 1900801 Time: 0.445651\n",
      "[04/10/2022-15:17:41] [V] [TRT] Tactic: 1966337 Time: 0.507305\n",
      "[04/10/2022-15:17:41] [V] [TRT] Tactic: 2031873 Time: 0.482181\n",
      "[04/10/2022-15:17:41] [V] [TRT] Tactic: 2097409 Time: 0.399798\n",
      "[04/10/2022-15:17:41] [V] [TRT] Tactic: 2162945 Time: 0.448131\n",
      "[04/10/2022-15:17:41] [V] [TRT] Tactic: 2228481 Time: 0.467409\n",
      "[04/10/2022-15:17:41] [V] [TRT] Tactic: 2294017 Time: 0.566061\n",
      "[04/10/2022-15:17:41] [V] [TRT] Tactic: 2359553 Time: 0.448242\n",
      "[04/10/2022-15:17:41] [V] [TRT] Tactic: 2425089 Time: 0.501576\n",
      "[04/10/2022-15:17:41] [V] [TRT] Tactic: 2490625 Time: 0.449674\n",
      "[04/10/2022-15:17:42] [V] [TRT] Tactic: 2556161 Time: 0.385332\n",
      "[04/10/2022-15:17:42] [V] [TRT] Tactic: 2621697 Time: 0.403483\n",
      "[04/10/2022-15:17:42] [V] [TRT] Tactic: 2687233 Time: 0.450098\n",
      "[04/10/2022-15:17:42] [V] [TRT] Tactic: 6947073 Time: 0.34515\n",
      "[04/10/2022-15:17:42] [V] [TRT] Fastest Tactic: 6947073 Time: 0.34515\n",
      "[04/10/2022-15:17:42] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/pooling0/MaxPool (CudnnPooling)\n",
      "[04/10/2022-15:17:42] [V] [TRT] Tactic: -1 Time: 0.578477\n",
      "[04/10/2022-15:17:42] [V] [TRT] Fastest Tactic: -1 Time: 0.578477\n",
      "[04/10/2022-15:17:42] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: TiledPooling Tactic: 6947073\n",
      "[04/10/2022-15:17:42] [V] [TRT] *************** Autotuning format combination: Half(831744,12996,114,1) -> Half(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:42] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/pooling0/MaxPool (TiledPooling)\n",
      "[04/10/2022-15:17:42] [V] [TRT] TiledPooling has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:17:42] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/pooling0/MaxPool (CudnnPooling)\n",
      "[04/10/2022-15:17:42] [V] [TRT] Tactic: -1 Time: 0.595488\n",
      "[04/10/2022-15:17:42] [V] [TRT] Fastest Tactic: -1 Time: 0.595488\n",
      "[04/10/2022-15:17:42] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnPooling Tactic: -1\n",
      "[04/10/2022-15:17:42] [V] [TRT] *************** Autotuning format combination: Half(415872,12996:2,114,1) -> Half(100352,3136:2,56,1) ***************\n",
      "[04/10/2022-15:17:42] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/pooling0/MaxPool (TiledPooling)\n",
      "[04/10/2022-15:17:42] [V] [TRT] Tactic: 257 Time: 0.511966\n",
      "[04/10/2022-15:17:42] [V] [TRT] Tactic: 65793 Time: 0.433112\n",
      "[04/10/2022-15:17:42] [V] [TRT] Tactic: 131329 Time: 0.605801\n",
      "[04/10/2022-15:17:42] [V] [TRT] Tactic: 196865 Time: 0.658548\n",
      "[04/10/2022-15:17:42] [V] [TRT] Tactic: 262401 Time: 0.528086\n",
      "[04/10/2022-15:17:42] [V] [TRT] Tactic: 327937 Time: 0.576829\n",
      "[04/10/2022-15:17:42] [V] [TRT] Tactic: 393473 Time: 0.585872\n",
      "[04/10/2022-15:17:42] [V] [TRT] Tactic: 459009 Time: 0.358711\n",
      "[04/10/2022-15:17:42] [V] [TRT] Tactic: 524545 Time: 0.294837\n",
      "[04/10/2022-15:17:42] [V] [TRT] Tactic: 590081 Time: 0.40584\n",
      "[04/10/2022-15:17:42] [V] [TRT] Tactic: 655617 Time: 0.423216\n",
      "[04/10/2022-15:17:42] [V] [TRT] Tactic: 721153 Time: 0.343906\n",
      "[04/10/2022-15:17:42] [V] [TRT] Tactic: 786689 Time: 0.370085\n",
      "[04/10/2022-15:17:42] [V] [TRT] Tactic: 852225 Time: 0.38778\n",
      "[04/10/2022-15:17:42] [V] [TRT] Tactic: 917761 Time: 0.288737\n",
      "[04/10/2022-15:17:42] [V] [TRT] Tactic: 983297 Time: 0.241777\n",
      "[04/10/2022-15:17:42] [V] [TRT] Tactic: 1048833 Time: 0.349101\n",
      "[04/10/2022-15:17:42] [V] [TRT] Tactic: 1114369 Time: 0.344707\n",
      "[04/10/2022-15:17:42] [V] [TRT] Tactic: 1179905 Time: 0.279831\n",
      "[04/10/2022-15:17:42] [V] [TRT] Tactic: 1245441 Time: 0.294049\n",
      "[04/10/2022-15:17:42] [V] [TRT] Tactic: 1310977 Time: 0.328431\n",
      "[04/10/2022-15:17:42] [V] [TRT] Tactic: 1376513 Time: 0.278984\n",
      "[04/10/2022-15:17:42] [V] [TRT] Tactic: 1442049 Time: 0.221126\n",
      "[04/10/2022-15:17:42] [V] [TRT] Tactic: 1507585 Time: 0.293483\n",
      "[04/10/2022-15:17:42] [V] [TRT] Tactic: 1573121 Time: 0.297109\n",
      "[04/10/2022-15:17:42] [V] [TRT] Tactic: 1638657 Time: 0.241029\n",
      "[04/10/2022-15:17:42] [V] [TRT] Tactic: 1704193 Time: 0.266575\n",
      "[04/10/2022-15:17:42] [V] [TRT] Tactic: 1769729 Time: 0.27679\n",
      "[04/10/2022-15:17:43] [V] [TRT] Tactic: 1835265 Time: 0.284186\n",
      "[04/10/2022-15:17:43] [V] [TRT] Tactic: 1900801 Time: 0.221719\n",
      "[04/10/2022-15:17:43] [V] [TRT] Tactic: 1966337 Time: 0.288581\n",
      "[04/10/2022-15:17:43] [V] [TRT] Tactic: 2031873 Time: 0.268008\n",
      "[04/10/2022-15:17:43] [V] [TRT] Tactic: 2097409 Time: 0.240384\n",
      "[04/10/2022-15:17:43] [V] [TRT] Tactic: 2162945 Time: 0.24582\n",
      "[04/10/2022-15:17:43] [V] [TRT] Tactic: 2228481 Time: 0.259857\n",
      "[04/10/2022-15:17:43] [V] [TRT] Tactic: 2294017 Time: 0.282891\n",
      "[04/10/2022-15:17:43] [V] [TRT] Tactic: 2359553 Time: 0.22183\n",
      "[04/10/2022-15:17:43] [V] [TRT] Tactic: 2425089 Time: 0.281628\n",
      "[04/10/2022-15:17:43] [V] [TRT] Tactic: 2490625 Time: 0.286491\n",
      "[04/10/2022-15:17:43] [V] [TRT] Tactic: 2556161 Time: 0.231986\n",
      "[04/10/2022-15:17:43] [V] [TRT] Tactic: 2621697 Time: 0.219453\n",
      "[04/10/2022-15:17:43] [V] [TRT] Tactic: 2687233 Time: 0.275221\n",
      "[04/10/2022-15:17:43] [V] [TRT] Tactic: 6947073 Time: 0.206302\n",
      "[04/10/2022-15:17:43] [V] [TRT] Fastest Tactic: 6947073 Time: 0.206302\n",
      "[04/10/2022-15:17:43] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/pooling0/MaxPool (CudaPooling)\n",
      "[04/10/2022-15:17:43] [V] [TRT] Tactic: -3 Time: 0.363633\n",
      "[04/10/2022-15:17:43] [V] [TRT] Fastest Tactic: -3 Time: 0.363633\n",
      "[04/10/2022-15:17:43] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: TiledPooling Tactic: 6947073\n",
      "[04/10/2022-15:17:43] [V] [TRT] *************** Autotuning Reformat:Float(200704,3136,56,1) -> Float(200704,1,3584,64) ***************\n",
      "[04/10/2022-15:17:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:17:43] [V] [TRT] Tactic: 1002 Time: 0.210579\n",
      "[04/10/2022-15:17:43] [V] [TRT] Tactic: 0 Time: 0.338679\n",
      "[04/10/2022-15:17:43] [V] [TRT] Fastest Tactic: 1002 Time: 0.210579\n",
      "[04/10/2022-15:17:43] [V] [TRT] *************** Autotuning Reformat:Float(200704,3136,56,1) -> Half(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:17:43] [V] [TRT] Tactic: 1002 Time: 0.28446\n",
      "[04/10/2022-15:17:43] [V] [TRT] Tactic: 0 Time: 0.211829\n",
      "[04/10/2022-15:17:43] [V] [TRT] Fastest Tactic: 0 Time: 0.211829\n",
      "[04/10/2022-15:17:43] [V] [TRT] *************** Autotuning Reformat:Float(200704,3136,56,1) -> Half(100352,3136:2,56,1) ***************\n",
      "[04/10/2022-15:17:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:17:43] [V] [TRT] Tactic: 1002 Time: 0.302188\n",
      "[04/10/2022-15:17:43] [V] [TRT] Tactic: 0 Time: 0.169935\n",
      "[04/10/2022-15:17:43] [V] [TRT] Fastest Tactic: 0 Time: 0.169935\n",
      "[04/10/2022-15:17:43] [V] [TRT] *************** Autotuning Reformat:Float(200704,1,3584,64) -> Float(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:17:43] [V] [TRT] Tactic: 1002 Time: 0.253008\n",
      "[04/10/2022-15:17:43] [V] [TRT] Tactic: 0 Time: 0.681634\n",
      "[04/10/2022-15:17:43] [V] [TRT] Fastest Tactic: 1002 Time: 0.253008\n",
      "[04/10/2022-15:17:43] [V] [TRT] *************** Autotuning Reformat:Float(200704,1,3584,64) -> Half(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:17:43] [V] [TRT] Tactic: 1002 Time: 0.193998\n",
      "[04/10/2022-15:17:43] [V] [TRT] Tactic: 0 Time: 0.671888\n",
      "[04/10/2022-15:17:43] [V] [TRT] Fastest Tactic: 1002 Time: 0.193998\n",
      "[04/10/2022-15:17:43] [V] [TRT] *************** Autotuning Reformat:Float(200704,1,3584,64) -> Half(100352,3136:2,56,1) ***************\n",
      "[04/10/2022-15:17:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:17:43] [V] [TRT] Tactic: 1002 Time: 0.257305\n",
      "[04/10/2022-15:17:43] [V] [TRT] Tactic: 0 Time: 0.713873\n",
      "[04/10/2022-15:17:43] [V] [TRT] Fastest Tactic: 1002 Time: 0.257305\n",
      "[04/10/2022-15:17:43] [V] [TRT] *************** Autotuning Reformat:Half(200704,3136,56,1) -> Float(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:17:43] [V] [TRT] Tactic: 1002 Time: 0.286999\n",
      "[04/10/2022-15:17:43] [V] [TRT] Tactic: 0 Time: 0.180319\n",
      "[04/10/2022-15:17:43] [V] [TRT] Fastest Tactic: 0 Time: 0.180319\n",
      "[04/10/2022-15:17:43] [V] [TRT] *************** Autotuning Reformat:Half(200704,3136,56,1) -> Float(200704,1,3584,64) ***************\n",
      "[04/10/2022-15:17:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:17:43] [V] [TRT] Tactic: 1002 Time: 0.183112\n",
      "[04/10/2022-15:17:43] [V] [TRT] Tactic: 0 Time: 0.307487\n",
      "[04/10/2022-15:17:43] [V] [TRT] Fastest Tactic: 1002 Time: 0.183112\n",
      "[04/10/2022-15:17:43] [V] [TRT] *************** Autotuning Reformat:Half(200704,3136,56,1) -> Half(100352,3136:2,56,1) ***************\n",
      "[04/10/2022-15:17:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:17:43] [V] [TRT] Tactic: 1002 Time: 0.182129\n",
      "[04/10/2022-15:17:43] [V] [TRT] Tactic: 0 Time: 0.1678\n",
      "[04/10/2022-15:17:43] [V] [TRT] Fastest Tactic: 0 Time: 0.1678\n",
      "[04/10/2022-15:17:43] [V] [TRT] *************** Autotuning Reformat:Half(100352,3136:2,56,1) -> Float(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:17:43] [V] [TRT] Tactic: 1002 Time: 0.244837\n",
      "[04/10/2022-15:17:43] [V] [TRT] Tactic: 0 Time: 0.146999\n",
      "[04/10/2022-15:17:43] [V] [TRT] Fastest Tactic: 0 Time: 0.146999\n",
      "[04/10/2022-15:17:43] [V] [TRT] *************** Autotuning Reformat:Half(100352,3136:2,56,1) -> Float(200704,1,3584,64) ***************\n",
      "[04/10/2022-15:17:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:17:43] [V] [TRT] Tactic: 1002 Time: 0.185313\n",
      "[04/10/2022-15:17:43] [V] [TRT] Tactic: 0 Time: 0.354909\n",
      "[04/10/2022-15:17:43] [V] [TRT] Fastest Tactic: 1002 Time: 0.185313\n",
      "[04/10/2022-15:17:43] [V] [TRT] *************** Autotuning Reformat:Half(100352,3136:2,56,1) -> Half(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:17:43] [V] [TRT] Tactic: 1002 Time: 0.380853\n",
      "[04/10/2022-15:17:43] [V] [TRT] Tactic: 0 Time: 0.143815\n",
      "[04/10/2022-15:17:43] [V] [TRT] Fastest Tactic: 0 Time: 0.143815\n",
      "[04/10/2022-15:17:43] [V] [TRT] *************** Autotuning format combination: Float(200704,3136,56,1) -> Float(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:43] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage1_unit1_bn1/FusedBatchNormV3 + StatefulPartitionedCall/model_1/stage1_unit1_relu1/Relu (Scale)\n",
      "[04/10/2022-15:17:43] [V] [TRT] Tactic: 0 Time: 0.135586\n",
      "[04/10/2022-15:17:43] [V] [TRT] Fastest Tactic: 0 Time: 0.135586\n",
      "[04/10/2022-15:17:43] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Scale Tactic: 0\n",
      "[04/10/2022-15:17:43] [V] [TRT] *************** Autotuning format combination: Float(200704,1,3584,64) -> Float(200704,1,3584,64) ***************\n",
      "[04/10/2022-15:17:43] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage1_unit1_bn1/FusedBatchNormV3 + StatefulPartitionedCall/model_1/stage1_unit1_relu1/Relu (Scale)\n",
      "[04/10/2022-15:17:43] [V] [TRT] Scale has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:17:43] [V] [TRT] *************** Autotuning format combination: Half(200704,3136,56,1) -> Half(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:43] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage1_unit1_bn1/FusedBatchNormV3 + StatefulPartitionedCall/model_1/stage1_unit1_relu1/Relu (Scale)\n",
      "[04/10/2022-15:17:43] [V] [TRT] Tactic: 0 Time: 0.130196\n",
      "[04/10/2022-15:17:43] [V] [TRT] Fastest Tactic: 0 Time: 0.130196\n",
      "[04/10/2022-15:17:43] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Scale Tactic: 0\n",
      "[04/10/2022-15:17:43] [V] [TRT] *************** Autotuning format combination: Half(100352,3136:2,56,1) -> Half(100352,3136:2,56,1) ***************\n",
      "[04/10/2022-15:17:43] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage1_unit1_bn1/FusedBatchNormV3 + StatefulPartitionedCall/model_1/stage1_unit1_relu1/Relu (Scale)\n",
      "[04/10/2022-15:17:43] [V] [TRT] Tactic: 0 Time: 0.158613\n",
      "[04/10/2022-15:17:43] [V] [TRT] Fastest Tactic: 0 Time: 0.158613\n",
      "[04/10/2022-15:17:43] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Scale Tactic: 0\n",
      "[04/10/2022-15:17:43] [V] [TRT] *************** Autotuning Reformat:Float(200704,3136,56,1) -> Float(200704,1,3584,64) ***************\n",
      "[04/10/2022-15:17:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:17:43] [V] [TRT] Tactic: 1002 Time: 0.210091\n",
      "[04/10/2022-15:17:43] [V] [TRT] Tactic: 0 Time: 0.336354\n",
      "[04/10/2022-15:17:43] [V] [TRT] Fastest Tactic: 1002 Time: 0.210091\n",
      "[04/10/2022-15:17:43] [V] [TRT] *************** Autotuning Reformat:Float(200704,3136,56,1) -> Half(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:17:43] [V] [TRT] Tactic: 1002 Time: 0.284538\n",
      "[04/10/2022-15:17:43] [V] [TRT] Tactic: 0 Time: 0.212292\n",
      "[04/10/2022-15:17:43] [V] [TRT] Fastest Tactic: 0 Time: 0.212292\n",
      "[04/10/2022-15:17:43] [V] [TRT] *************** Autotuning Reformat:Float(200704,3136,56,1) -> Half(100352,3136:2,56,1) ***************\n",
      "[04/10/2022-15:17:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:17:43] [V] [TRT] Tactic: 1002 Time: 0.302858\n",
      "[04/10/2022-15:17:43] [V] [TRT] Tactic: 0 Time: 0.169609\n",
      "[04/10/2022-15:17:43] [V] [TRT] Fastest Tactic: 0 Time: 0.169609\n",
      "[04/10/2022-15:17:43] [V] [TRT] *************** Autotuning Reformat:Float(200704,1,3584,64) -> Float(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:17:43] [V] [TRT] Tactic: 1002 Time: 0.257702\n",
      "[04/10/2022-15:17:43] [V] [TRT] Tactic: 0 Time: 0.683262\n",
      "[04/10/2022-15:17:43] [V] [TRT] Fastest Tactic: 1002 Time: 0.257702\n",
      "[04/10/2022-15:17:43] [V] [TRT] *************** Autotuning Reformat:Float(200704,1,3584,64) -> Half(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:17:43] [V] [TRT] Tactic: 1002 Time: 0.194193\n",
      "[04/10/2022-15:17:43] [V] [TRT] Tactic: 0 Time: 0.670645\n",
      "[04/10/2022-15:17:43] [V] [TRT] Fastest Tactic: 1002 Time: 0.194193\n",
      "[04/10/2022-15:17:43] [V] [TRT] *************** Autotuning Reformat:Float(200704,1,3584,64) -> Half(100352,3136:2,56,1) ***************\n",
      "[04/10/2022-15:17:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:17:43] [V] [TRT] Tactic: 1002 Time: 0.25778\n",
      "[04/10/2022-15:17:43] [V] [TRT] Tactic: 0 Time: 0.715951\n",
      "[04/10/2022-15:17:43] [V] [TRT] Fastest Tactic: 1002 Time: 0.25778\n",
      "[04/10/2022-15:17:43] [V] [TRT] *************** Autotuning Reformat:Half(200704,3136,56,1) -> Float(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:17:43] [V] [TRT] Tactic: 1002 Time: 0.287181\n",
      "[04/10/2022-15:17:43] [V] [TRT] Tactic: 0 Time: 0.179981\n",
      "[04/10/2022-15:17:43] [V] [TRT] Fastest Tactic: 0 Time: 0.179981\n",
      "[04/10/2022-15:17:43] [V] [TRT] *************** Autotuning Reformat:Half(200704,3136,56,1) -> Float(200704,1,3584,64) ***************\n",
      "[04/10/2022-15:17:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:17:43] [V] [TRT] Tactic: 1002 Time: 0.182943\n",
      "[04/10/2022-15:17:43] [V] [TRT] Tactic: 0 Time: 0.307227\n",
      "[04/10/2022-15:17:43] [V] [TRT] Fastest Tactic: 1002 Time: 0.182943\n",
      "[04/10/2022-15:17:43] [V] [TRT] *************** Autotuning Reformat:Half(200704,3136,56,1) -> Half(100352,3136:2,56,1) ***************\n",
      "[04/10/2022-15:17:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:17:43] [V] [TRT] Tactic: 1002 Time: 0.181276\n",
      "[04/10/2022-15:17:43] [V] [TRT] Tactic: 0 Time: 0.167663\n",
      "[04/10/2022-15:17:43] [V] [TRT] Fastest Tactic: 0 Time: 0.167663\n",
      "[04/10/2022-15:17:43] [V] [TRT] *************** Autotuning Reformat:Half(100352,3136:2,56,1) -> Float(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:17:43] [V] [TRT] Tactic: 1002 Time: 0.244531\n",
      "[04/10/2022-15:17:43] [V] [TRT] Tactic: 0 Time: 0.146966\n",
      "[04/10/2022-15:17:43] [V] [TRT] Fastest Tactic: 0 Time: 0.146966\n",
      "[04/10/2022-15:17:43] [V] [TRT] *************** Autotuning Reformat:Half(100352,3136:2,56,1) -> Float(200704,1,3584,64) ***************\n",
      "[04/10/2022-15:17:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:17:43] [V] [TRT] Tactic: 1002 Time: 0.186413\n",
      "[04/10/2022-15:17:43] [V] [TRT] Tactic: 0 Time: 0.355261\n",
      "[04/10/2022-15:17:43] [V] [TRT] Fastest Tactic: 1002 Time: 0.186413\n",
      "[04/10/2022-15:17:43] [V] [TRT] *************** Autotuning Reformat:Half(100352,3136:2,56,1) -> Half(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:17:43] [V] [TRT] Tactic: 1002 Time: 0.378555\n",
      "[04/10/2022-15:17:43] [V] [TRT] Tactic: 0 Time: 0.143522\n",
      "[04/10/2022-15:17:43] [V] [TRT] Fastest Tactic: 0 Time: 0.143522\n",
      "[04/10/2022-15:17:43] [V] [TRT] *************** Autotuning Reformat:Float(200704,3136,56,1) -> Float(200704,1,3584,64) ***************\n",
      "[04/10/2022-15:17:43] [V] [TRT] *************** Autotuning Reformat:Float(200704,3136,56,1) -> Half(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:43] [V] [TRT] *************** Autotuning Reformat:Float(200704,3136,56,1) -> Half(100352,3136:2,56,1) ***************\n",
      "[04/10/2022-15:17:43] [V] [TRT] *************** Autotuning Reformat:Float(200704,1,3584,64) -> Float(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:43] [V] [TRT] *************** Autotuning Reformat:Float(200704,1,3584,64) -> Half(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:43] [V] [TRT] *************** Autotuning Reformat:Float(200704,1,3584,64) -> Half(100352,3136:2,56,1) ***************\n",
      "[04/10/2022-15:17:43] [V] [TRT] *************** Autotuning Reformat:Half(200704,3136,56,1) -> Float(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:43] [V] [TRT] *************** Autotuning Reformat:Half(200704,3136,56,1) -> Float(200704,1,3584,64) ***************\n",
      "[04/10/2022-15:17:43] [V] [TRT] *************** Autotuning Reformat:Half(200704,3136,56,1) -> Half(100352,3136:2,56,1) ***************\n",
      "[04/10/2022-15:17:43] [V] [TRT] *************** Autotuning Reformat:Half(100352,3136:2,56,1) -> Float(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:43] [V] [TRT] *************** Autotuning Reformat:Half(100352,3136:2,56,1) -> Float(200704,1,3584,64) ***************\n",
      "[04/10/2022-15:17:43] [V] [TRT] *************** Autotuning Reformat:Half(100352,3136:2,56,1) -> Half(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:43] [V] [TRT] *************** Autotuning format combination: Float(200704,3136,56,1) -> Float(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:43] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage1_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage1_unit1_relu2/Relu (CudaDepthwiseConvolution)\n",
      "[04/10/2022-15:17:43] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:17:43] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage1_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage1_unit1_relu2/Relu (FusedConvActConvolution)\n",
      "[04/10/2022-15:17:43] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:17:43] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage1_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage1_unit1_relu2/Relu (CudnnConvolution)\n",
      "[04/10/2022-15:17:44] [V] [TRT] Tactic: 0 Time: 4.22203\n",
      "[04/10/2022-15:17:44] [V] [TRT] Tactic: 1 Time: 1.61132\n",
      "[04/10/2022-15:17:44] [V] [TRT] Tactic: 2 Time: 4.36721\n",
      "[04/10/2022-15:17:44] [V] [TRT] Tactic: 4 Time: 26.4996\n",
      "[04/10/2022-15:17:44] [V] [TRT] Tactic: 5 Time: 12.9642\n",
      "[04/10/2022-15:17:44] [V] [TRT] Tactic: 6 Time: 1.28447\n",
      "[04/10/2022-15:17:44] [V] [TRT] Fastest Tactic: 6 Time: 1.28447\n",
      "[04/10/2022-15:17:44] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage1_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage1_unit1_relu2/Relu (CaskConvolution)\n",
      "[04/10/2022-15:17:45] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage1_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758\n",
      "[04/10/2022-15:17:45] [V] [TRT] Tactic: 1062367460111450758 Time: 1.58306\n",
      "[04/10/2022-15:17:45] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage1_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v0 Tactic: 1754984623894446479\n",
      "[04/10/2022-15:17:45] [V] [TRT] Tactic: 1754984623894446479 Time: 1.73375\n",
      "[04/10/2022-15:17:45] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage1_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v0 Tactic: 3611739942397549984\n",
      "[04/10/2022-15:17:45] [V] [TRT] Tactic: 3611739942397549984 Time: 2.47658\n",
      "[04/10/2022-15:17:45] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage1_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v1 Tactic: 3827454225649558724\n",
      "[04/10/2022-15:17:45] [V] [TRT] Tactic: 3827454225649558724 Time: 1.38611\n",
      "[04/10/2022-15:17:45] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage1_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379\n",
      "[04/10/2022-15:17:45] [V] [TRT] Tactic: 4337000649858996379 Time: 1.2801\n",
      "[04/10/2022-15:17:45] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage1_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441\n",
      "[04/10/2022-15:17:45] [V] [TRT] Tactic: 4501471010995462441 Time: 2.47426\n",
      "[04/10/2022-15:17:45] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage1_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826\n",
      "[04/10/2022-15:17:45] [V] [TRT] Tactic: 5137655947464784826 Time: 1.23542\n",
      "[04/10/2022-15:17:45] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage1_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929\n",
      "[04/10/2022-15:17:45] [V] [TRT] Tactic: 5288347012147084929 Time: 2.43352\n",
      "[04/10/2022-15:17:45] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage1_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 5921334924264294896\n",
      "[04/10/2022-15:17:45] [V] [TRT] Tactic: 5921334924264294896 Time: 0.996126\n",
      "[04/10/2022-15:17:45] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage1_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056\n",
      "[04/10/2022-15:17:45] [V] [TRT] Tactic: 6645123197870846056 Time: 1.26785\n",
      "[04/10/2022-15:17:45] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage1_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478\n",
      "[04/10/2022-15:17:45] [V] [TRT] Tactic: 7144526460361122478 Time: 1.57217\n",
      "[04/10/2022-15:17:45] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage1_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: 7852627285308570038\n",
      "[04/10/2022-15:17:45] [V] [TRT] Tactic: 7852627285308570038 Time: 1.43865\n",
      "[04/10/2022-15:17:45] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage1_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713\n",
      "[04/10/2022-15:17:45] [V] [TRT] Tactic: -9137461792520977713 Time: 2.52716\n",
      "[04/10/2022-15:17:45] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage1_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v0 Tactic: -8776506421218919509\n",
      "[04/10/2022-15:17:45] [V] [TRT] Tactic: -8776506421218919509 Time: 1.37544\n",
      "[04/10/2022-15:17:45] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage1_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730\n",
      "[04/10/2022-15:17:45] [V] [TRT] Tactic: -8262349710178828730 Time: 2.48736\n",
      "[04/10/2022-15:17:45] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage1_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v0 Tactic: -8133971918129952780\n",
      "[04/10/2022-15:17:45] [V] [TRT] Tactic: -8133971918129952780 Time: 1.47659\n",
      "[04/10/2022-15:17:45] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage1_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144\n",
      "[04/10/2022-15:17:45] [V] [TRT] Tactic: -6092040395344634144 Time: 1.64827\n",
      "[04/10/2022-15:17:45] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage1_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159\n",
      "[04/10/2022-15:17:45] [V] [TRT] Tactic: -4787320710726427159 Time: 1.72533\n",
      "[04/10/2022-15:17:45] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage1_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839\n",
      "[04/10/2022-15:17:45] [V] [TRT] Tactic: -3456450830548107839 Time: 1.43107\n",
      "[04/10/2022-15:17:45] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage1_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v0 Tactic: -2318106587342035239\n",
      "[04/10/2022-15:17:45] [V] [TRT] Tactic: -2318106587342035239 Time: 1.39659\n",
      "[04/10/2022-15:17:45] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage1_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_mobile_relu_tile148t_nt_v0 Tactic: -1343271414618805657\n",
      "[04/10/2022-15:17:45] [V] [TRT] Tactic: -1343271414618805657 Time: 0.916693\n",
      "[04/10/2022-15:17:45] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage1_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241\n",
      "[04/10/2022-15:17:45] [V] [TRT] Tactic: -1218658103698133241 Time: 1.39663\n",
      "[04/10/2022-15:17:45] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage1_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091\n",
      "[04/10/2022-15:17:45] [V] [TRT] Tactic: -836875257600482091 Time: 1.32063\n",
      "[04/10/2022-15:17:45] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage1_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746\n",
      "[04/10/2022-15:17:45] [V] [TRT] Tactic: -410470605513481746 Time: 2.43055\n",
      "[04/10/2022-15:17:45] [V] [TRT] Fastest Tactic: -1343271414618805657 Time: 0.916693\n",
      "[04/10/2022-15:17:45] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -1343271414618805657\n",
      "[04/10/2022-15:17:45] [V] [TRT] *************** Autotuning format combination: Float(200704,1,3584,64) -> Float(200704,1,3584,64) ***************\n",
      "[04/10/2022-15:17:45] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage1_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage1_unit1_relu2/Relu (CudnnConvolution)\n",
      "[04/10/2022-15:17:45] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:17:46] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage1_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage1_unit1_relu2/Relu (CaskConvolution)\n",
      "[04/10/2022-15:17:46] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage1_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824\n",
      "[04/10/2022-15:17:46] [V] [TRT] Tactic: -9153228964338181824 Time: 1.72111\n",
      "[04/10/2022-15:17:46] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage1_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025\n",
      "[04/10/2022-15:17:46] [V] [TRT] Tactic: -7394439838318485025 Time: 1.24796\n",
      "[04/10/2022-15:17:46] [V] [TRT] Fastest Tactic: -7394439838318485025 Time: 1.24796\n",
      "[04/10/2022-15:17:46] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7394439838318485025\n",
      "[04/10/2022-15:17:46] [V] [TRT] *************** Autotuning format combination: Half(200704,3136,56,1) -> Half(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:46] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage1_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage1_unit1_relu2/Relu (CudnnConvolution)\n",
      "[04/10/2022-15:17:46] [V] [TRT] Tactic: 0 Time: 2.97943\n",
      "[04/10/2022-15:17:46] [V] [TRT] Tactic: 1 Time: 2.9805\n",
      "[04/10/2022-15:17:46] [V] [TRT] Tactic: 2 Time: 4.18173\n",
      "[04/10/2022-15:17:46] [V] [TRT] Tactic: 4 Time: 26.9074\n",
      "[04/10/2022-15:17:47] [V] [TRT] Tactic: 5 Time: 12.5279\n",
      "[04/10/2022-15:17:47] [V] [TRT] Tactic: 6 Time: 2.19973\n",
      "[04/10/2022-15:17:47] [V] [TRT] Fastest Tactic: 6 Time: 2.19973\n",
      "[04/10/2022-15:17:47] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage1_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage1_unit1_relu2/Relu (CaskConvolution)\n",
      "[04/10/2022-15:17:47] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:17:47] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 6\n",
      "[04/10/2022-15:17:47] [V] [TRT] *************** Autotuning format combination: Half(100352,3136:2,56,1) -> Half(100352,3136:2,56,1) ***************\n",
      "[04/10/2022-15:17:47] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage1_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage1_unit1_relu2/Relu (FusedConvActConvolution)\n",
      "[04/10/2022-15:17:47] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:17:47] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage1_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage1_unit1_relu2/Relu (CudnnConvolution)\n",
      "[04/10/2022-15:17:47] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:17:47] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage1_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage1_unit1_relu2/Relu (CaskConvolution)\n",
      "[04/10/2022-15:17:47] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage1_unit1_relu2/Relu Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998\n",
      "[04/10/2022-15:17:47] [V] [TRT] Tactic: 3564772625446233998 Time: 0.820762\n",
      "[04/10/2022-15:17:47] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage1_unit1_relu2/Relu Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_large_nn_v1 Tactic: 3650389455493082349\n",
      "[04/10/2022-15:17:47] [V] [TRT] Tactic: 3650389455493082349 Time: 0.849935\n",
      "[04/10/2022-15:17:47] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage1_unit1_relu2/Relu Set Tactic Name: maxwell_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 4772821744921268633\n",
      "[04/10/2022-15:17:47] [V] [TRT] Tactic: 4772821744921268633 Time: 0.51278\n",
      "[04/10/2022-15:17:47] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage1_unit1_relu2/Relu Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452\n",
      "[04/10/2022-15:17:47] [V] [TRT] Tactic: 5319956359050645452 Time: 0.745364\n",
      "[04/10/2022-15:17:47] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage1_unit1_relu2/Relu Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848\n",
      "[04/10/2022-15:17:47] [V] [TRT] Tactic: 7205456024582378848 Time: 0.653659\n",
      "[04/10/2022-15:17:47] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage1_unit1_relu2/Relu Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_large_nn_v1 Tactic: -6490690591794140522\n",
      "[04/10/2022-15:17:47] [V] [TRT] Tactic: -6490690591794140522 Time: 0.66209\n",
      "[04/10/2022-15:17:47] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage1_unit1_relu2/Relu Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_large_nn_v1 Tactic: -4686027666808657977\n",
      "[04/10/2022-15:17:47] [V] [TRT] Tactic: -4686027666808657977 Time: 1.27851\n",
      "[04/10/2022-15:17:47] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage1_unit1_relu2/Relu Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890\n",
      "[04/10/2022-15:17:47] [V] [TRT] Tactic: -4212163711445252890 Time: 1.23507\n",
      "[04/10/2022-15:17:47] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage1_unit1_relu2/Relu Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110\n",
      "[04/10/2022-15:17:47] [V] [TRT] Tactic: -3898373634979201110 Time: 1.26919\n",
      "[04/10/2022-15:17:47] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage1_unit1_relu2/Relu Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473\n",
      "[04/10/2022-15:17:47] [V] [TRT] Tactic: -2409163523992614473 Time: 0.635755\n",
      "[04/10/2022-15:17:47] [V] [TRT] Fastest Tactic: 4772821744921268633 Time: 0.51278\n",
      "[04/10/2022-15:17:47] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 4772821744921268633\n",
      "[04/10/2022-15:17:47] [V] [TRT] *************** Autotuning Reformat:Float(200704,3136,56,1) -> Float(200704,1,3584,64) ***************\n",
      "[04/10/2022-15:17:47] [V] [TRT] *************** Autotuning Reformat:Float(200704,3136,56,1) -> Half(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:47] [V] [TRT] *************** Autotuning Reformat:Float(200704,3136,56,1) -> Half(100352,3136:2,56,1) ***************\n",
      "[04/10/2022-15:17:47] [V] [TRT] *************** Autotuning Reformat:Float(200704,1,3584,64) -> Float(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:47] [V] [TRT] *************** Autotuning Reformat:Float(200704,1,3584,64) -> Half(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:47] [V] [TRT] *************** Autotuning Reformat:Float(200704,1,3584,64) -> Half(100352,3136:2,56,1) ***************\n",
      "[04/10/2022-15:17:47] [V] [TRT] *************** Autotuning Reformat:Half(200704,3136,56,1) -> Float(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:47] [V] [TRT] *************** Autotuning Reformat:Half(200704,3136,56,1) -> Float(200704,1,3584,64) ***************\n",
      "[04/10/2022-15:17:47] [V] [TRT] *************** Autotuning Reformat:Half(200704,3136,56,1) -> Half(100352,3136:2,56,1) ***************\n",
      "[04/10/2022-15:17:47] [V] [TRT] *************** Autotuning Reformat:Half(100352,3136:2,56,1) -> Float(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:47] [V] [TRT] *************** Autotuning Reformat:Half(100352,3136:2,56,1) -> Float(200704,1,3584,64) ***************\n",
      "[04/10/2022-15:17:47] [V] [TRT] *************** Autotuning Reformat:Half(100352,3136:2,56,1) -> Half(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:47] [V] [TRT] *************** Autotuning format combination: Float(200704,3136,56,1) -> Float(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:47] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage1_unit1_conv2/Conv2D (CudaDepthwiseConvolution)\n",
      "[04/10/2022-15:17:47] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:17:47] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage1_unit1_conv2/Conv2D (FusedConvActConvolution)\n",
      "[04/10/2022-15:17:47] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:17:47] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage1_unit1_conv2/Conv2D (CudnnConvolution)\n",
      "[04/10/2022-15:17:47] [V] [TRT] Tactic: 0 Time: 4.02279\n",
      "[04/10/2022-15:17:47] [V] [TRT] Tactic: 1 Time: 1.36241\n",
      "[04/10/2022-15:17:47] [V] [TRT] Tactic: 2 Time: 4.1549\n",
      "[04/10/2022-15:17:48] [V] [TRT] Tactic: 4 Time: 26.2949\n",
      "[04/10/2022-15:17:48] [V] [TRT] Tactic: 5 Time: 12.715\n",
      "[04/10/2022-15:17:48] [V] [TRT] Tactic: 6 Time: 1.0254\n",
      "[04/10/2022-15:17:48] [V] [TRT] Fastest Tactic: 6 Time: 1.0254\n",
      "[04/10/2022-15:17:48] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage1_unit1_conv2/Conv2D (CaskConvolution)\n",
      "[04/10/2022-15:17:48] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758\n",
      "[04/10/2022-15:17:48] [V] [TRT] Tactic: 1062367460111450758 Time: 1.57981\n",
      "[04/10/2022-15:17:48] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v0 Tactic: 1754984623894446479\n",
      "[04/10/2022-15:17:48] [V] [TRT] Tactic: 1754984623894446479 Time: 1.73111\n",
      "[04/10/2022-15:17:48] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v0 Tactic: 3611739942397549984\n",
      "[04/10/2022-15:17:48] [V] [TRT] Tactic: 3611739942397549984 Time: 2.47461\n",
      "[04/10/2022-15:17:48] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v1 Tactic: 3827454225649558724\n",
      "[04/10/2022-15:17:48] [V] [TRT] Tactic: 3827454225649558724 Time: 1.3797\n",
      "[04/10/2022-15:17:48] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379\n",
      "[04/10/2022-15:17:48] [V] [TRT] Tactic: 4337000649858996379 Time: 1.27988\n",
      "[04/10/2022-15:17:48] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441\n",
      "[04/10/2022-15:17:48] [V] [TRT] Tactic: 4501471010995462441 Time: 2.4761\n",
      "[04/10/2022-15:17:48] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826\n",
      "[04/10/2022-15:17:48] [V] [TRT] Tactic: 5137655947464784826 Time: 1.21963\n",
      "[04/10/2022-15:17:48] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929\n",
      "[04/10/2022-15:17:48] [V] [TRT] Tactic: 5288347012147084929 Time: 2.42955\n",
      "[04/10/2022-15:17:48] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 5921334924264294896\n",
      "[04/10/2022-15:17:48] [V] [TRT] Tactic: 5921334924264294896 Time: 0.952116\n",
      "[04/10/2022-15:17:48] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056\n",
      "[04/10/2022-15:17:48] [V] [TRT] Tactic: 6645123197870846056 Time: 1.26936\n",
      "[04/10/2022-15:17:48] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478\n",
      "[04/10/2022-15:17:48] [V] [TRT] Tactic: 7144526460361122478 Time: 1.5826\n",
      "[04/10/2022-15:17:48] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: 7852627285308570038\n",
      "[04/10/2022-15:17:48] [V] [TRT] Tactic: 7852627285308570038 Time: 1.40132\n",
      "[04/10/2022-15:17:48] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713\n",
      "[04/10/2022-15:17:48] [V] [TRT] Tactic: -9137461792520977713 Time: 2.52627\n",
      "[04/10/2022-15:17:48] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v0 Tactic: -8776506421218919509\n",
      "[04/10/2022-15:17:49] [V] [TRT] Tactic: -8776506421218919509 Time: 1.37307\n",
      "[04/10/2022-15:17:49] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730\n",
      "[04/10/2022-15:17:49] [V] [TRT] Tactic: -8262349710178828730 Time: 2.48487\n",
      "[04/10/2022-15:17:49] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v0 Tactic: -8133971918129952780\n",
      "[04/10/2022-15:17:49] [V] [TRT] Tactic: -8133971918129952780 Time: 1.4229\n",
      "[04/10/2022-15:17:49] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144\n",
      "[04/10/2022-15:17:49] [V] [TRT] Tactic: -6092040395344634144 Time: 1.64757\n",
      "[04/10/2022-15:17:49] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159\n",
      "[04/10/2022-15:17:49] [V] [TRT] Tactic: -4787320710726427159 Time: 1.7261\n",
      "[04/10/2022-15:17:49] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839\n",
      "[04/10/2022-15:17:49] [V] [TRT] Tactic: -3456450830548107839 Time: 1.41796\n",
      "[04/10/2022-15:17:49] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v0 Tactic: -2318106587342035239\n",
      "[04/10/2022-15:17:49] [V] [TRT] Tactic: -2318106587342035239 Time: 1.39121\n",
      "[04/10/2022-15:17:49] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_mobile_relu_tile148t_nt_v0 Tactic: -1343271414618805657\n",
      "[04/10/2022-15:17:49] [V] [TRT] Tactic: -1343271414618805657 Time: 0.921699\n",
      "[04/10/2022-15:17:49] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241\n",
      "[04/10/2022-15:17:49] [V] [TRT] Tactic: -1218658103698133241 Time: 1.39288\n",
      "[04/10/2022-15:17:49] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091\n",
      "[04/10/2022-15:17:49] [V] [TRT] Tactic: -836875257600482091 Time: 1.34799\n",
      "[04/10/2022-15:17:49] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746\n",
      "[04/10/2022-15:17:49] [V] [TRT] Tactic: -410470605513481746 Time: 2.43243\n",
      "[04/10/2022-15:17:49] [V] [TRT] Fastest Tactic: -1343271414618805657 Time: 0.921699\n",
      "[04/10/2022-15:17:49] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -1343271414618805657\n",
      "[04/10/2022-15:17:49] [V] [TRT] *************** Autotuning format combination: Float(200704,1,3584,64) -> Float(200704,1,3584,64) ***************\n",
      "[04/10/2022-15:17:49] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage1_unit1_conv2/Conv2D (CudnnConvolution)\n",
      "[04/10/2022-15:17:49] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:17:49] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage1_unit1_conv2/Conv2D (CaskConvolution)\n",
      "[04/10/2022-15:17:49] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824\n",
      "[04/10/2022-15:17:49] [V] [TRT] Tactic: -9153228964338181824 Time: 1.71249\n",
      "[04/10/2022-15:17:49] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025\n",
      "[04/10/2022-15:17:49] [V] [TRT] Tactic: -7394439838318485025 Time: 1.24426\n",
      "[04/10/2022-15:17:49] [V] [TRT] Fastest Tactic: -7394439838318485025 Time: 1.24426\n",
      "[04/10/2022-15:17:49] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7394439838318485025\n",
      "[04/10/2022-15:17:49] [V] [TRT] *************** Autotuning format combination: Half(200704,3136,56,1) -> Half(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:49] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage1_unit1_conv2/Conv2D (CudnnConvolution)\n",
      "[04/10/2022-15:17:49] [V] [TRT] Tactic: 0 Time: 2.8318\n",
      "[04/10/2022-15:17:49] [V] [TRT] Tactic: 1 Time: 2.83299\n",
      "[04/10/2022-15:17:49] [V] [TRT] Tactic: 2 Time: 3.98921\n",
      "[04/10/2022-15:17:50] [V] [TRT] Tactic: 4 Time: 26.8074\n",
      "[04/10/2022-15:17:50] [V] [TRT] Tactic: 5 Time: 12.7313\n",
      "[04/10/2022-15:17:50] [V] [TRT] Tactic: 6 Time: 2.08053\n",
      "[04/10/2022-15:17:50] [V] [TRT] Fastest Tactic: 6 Time: 2.08053\n",
      "[04/10/2022-15:17:50] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage1_unit1_conv2/Conv2D (CaskConvolution)\n",
      "[04/10/2022-15:17:50] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:17:50] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 6\n",
      "[04/10/2022-15:17:50] [V] [TRT] *************** Autotuning format combination: Half(100352,3136:2,56,1) -> Half(100352,3136:2,56,1) ***************\n",
      "[04/10/2022-15:17:50] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage1_unit1_conv2/Conv2D (FusedConvActConvolution)\n",
      "[04/10/2022-15:17:50] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:17:50] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage1_unit1_conv2/Conv2D (CudnnConvolution)\n",
      "[04/10/2022-15:17:50] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:17:50] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage1_unit1_conv2/Conv2D (CaskConvolution)\n",
      "[04/10/2022-15:17:50] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_conv2/Conv2D Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998\n",
      "[04/10/2022-15:17:50] [V] [TRT] Tactic: 3564772625446233998 Time: 0.821803\n",
      "[04/10/2022-15:17:50] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_conv2/Conv2D Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_large_nn_v1 Tactic: 3650389455493082349\n",
      "[04/10/2022-15:17:50] [V] [TRT] Tactic: 3650389455493082349 Time: 0.851686\n",
      "[04/10/2022-15:17:50] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_conv2/Conv2D Set Tactic Name: maxwell_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 4772821744921268633\n",
      "[04/10/2022-15:17:50] [V] [TRT] Tactic: 4772821744921268633 Time: 0.514473\n",
      "[04/10/2022-15:17:50] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_conv2/Conv2D Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452\n",
      "[04/10/2022-15:17:50] [V] [TRT] Tactic: 5319956359050645452 Time: 0.747357\n",
      "[04/10/2022-15:17:50] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_conv2/Conv2D Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848\n",
      "[04/10/2022-15:17:50] [V] [TRT] Tactic: 7205456024582378848 Time: 0.64946\n",
      "[04/10/2022-15:17:50] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_conv2/Conv2D Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_large_nn_v1 Tactic: -6490690591794140522\n",
      "[04/10/2022-15:17:50] [V] [TRT] Tactic: -6490690591794140522 Time: 0.665475\n",
      "[04/10/2022-15:17:50] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_conv2/Conv2D Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_large_nn_v1 Tactic: -4686027666808657977\n",
      "[04/10/2022-15:17:50] [V] [TRT] Tactic: -4686027666808657977 Time: 1.28197\n",
      "[04/10/2022-15:17:50] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_conv2/Conv2D Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890\n",
      "[04/10/2022-15:17:50] [V] [TRT] Tactic: -4212163711445252890 Time: 1.2257\n",
      "[04/10/2022-15:17:50] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_conv2/Conv2D Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110\n",
      "[04/10/2022-15:17:50] [V] [TRT] Tactic: -3898373634979201110 Time: 1.26624\n",
      "[04/10/2022-15:17:50] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_conv2/Conv2D Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473\n",
      "[04/10/2022-15:17:50] [V] [TRT] Tactic: -2409163523992614473 Time: 0.637897\n",
      "[04/10/2022-15:17:50] [V] [TRT] Fastest Tactic: 4772821744921268633 Time: 0.514473\n",
      "[04/10/2022-15:17:50] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 4772821744921268633\n",
      "[04/10/2022-15:17:50] [V] [TRT] *************** Autotuning Reformat:Float(200704,3136,56,1) -> Float(200704,1,3584,64) ***************\n",
      "[04/10/2022-15:17:50] [V] [TRT] *************** Autotuning Reformat:Float(200704,3136,56,1) -> Half(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:50] [V] [TRT] *************** Autotuning Reformat:Float(200704,3136,56,1) -> Half(100352,3136:2,56,1) ***************\n",
      "[04/10/2022-15:17:50] [V] [TRT] *************** Autotuning Reformat:Float(200704,1,3584,64) -> Float(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:50] [V] [TRT] *************** Autotuning Reformat:Float(200704,1,3584,64) -> Half(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:50] [V] [TRT] *************** Autotuning Reformat:Float(200704,1,3584,64) -> Half(100352,3136:2,56,1) ***************\n",
      "[04/10/2022-15:17:50] [V] [TRT] *************** Autotuning Reformat:Half(200704,3136,56,1) -> Float(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:50] [V] [TRT] *************** Autotuning Reformat:Half(200704,3136,56,1) -> Float(200704,1,3584,64) ***************\n",
      "[04/10/2022-15:17:50] [V] [TRT] *************** Autotuning Reformat:Half(200704,3136,56,1) -> Half(100352,3136:2,56,1) ***************\n",
      "[04/10/2022-15:17:50] [V] [TRT] *************** Autotuning Reformat:Half(100352,3136:2,56,1) -> Float(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:50] [V] [TRT] *************** Autotuning Reformat:Half(100352,3136:2,56,1) -> Float(200704,1,3584,64) ***************\n",
      "[04/10/2022-15:17:50] [V] [TRT] *************** Autotuning Reformat:Half(100352,3136:2,56,1) -> Half(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:50] [V] [TRT] *************** Autotuning Reformat:Float(200704,3136,56,1) -> Float(200704,1,3584,64) ***************\n",
      "[04/10/2022-15:17:50] [V] [TRT] *************** Autotuning Reformat:Float(200704,3136,56,1) -> Half(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:50] [V] [TRT] *************** Autotuning Reformat:Float(200704,3136,56,1) -> Half(100352,3136:2,56,1) ***************\n",
      "[04/10/2022-15:17:50] [V] [TRT] *************** Autotuning Reformat:Float(200704,1,3584,64) -> Float(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:50] [V] [TRT] *************** Autotuning Reformat:Float(200704,1,3584,64) -> Half(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:50] [V] [TRT] *************** Autotuning Reformat:Float(200704,1,3584,64) -> Half(100352,3136:2,56,1) ***************\n",
      "[04/10/2022-15:17:50] [V] [TRT] *************** Autotuning Reformat:Half(200704,3136,56,1) -> Float(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:50] [V] [TRT] *************** Autotuning Reformat:Half(200704,3136,56,1) -> Float(200704,1,3584,64) ***************\n",
      "[04/10/2022-15:17:50] [V] [TRT] *************** Autotuning Reformat:Half(200704,3136,56,1) -> Half(100352,3136:2,56,1) ***************\n",
      "[04/10/2022-15:17:50] [V] [TRT] *************** Autotuning Reformat:Half(100352,3136:2,56,1) -> Float(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:50] [V] [TRT] *************** Autotuning Reformat:Half(100352,3136:2,56,1) -> Float(200704,1,3584,64) ***************\n",
      "[04/10/2022-15:17:50] [V] [TRT] *************** Autotuning Reformat:Half(100352,3136:2,56,1) -> Half(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:50] [V] [TRT] *************** Autotuning format combination: Float(200704,3136,56,1), Float(200704,3136,56,1) -> Float(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:50] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage1_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add/add (CudaDepthwiseConvolution)\n",
      "[04/10/2022-15:17:50] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:17:50] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage1_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add/add (FusedConvActConvolution)\n",
      "[04/10/2022-15:17:50] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:17:50] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage1_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add/add (CudnnConvolution)\n",
      "[04/10/2022-15:17:50] [V] [TRT] Tactic: 0 Time: 0.508425\n",
      "[04/10/2022-15:17:50] [V] [TRT] Tactic: 1 Time: 0.456764\n",
      "[04/10/2022-15:17:50] [V] [TRT] Tactic: 2 Time: 0.783887\n",
      "[04/10/2022-15:17:51] [V] [TRT] Tactic: 4 Time: 26.2483\n",
      "[04/10/2022-15:17:51] [V] [TRT] Tactic: 5 Time: 1.2951\n",
      "[04/10/2022-15:17:51] [V] [TRT] Fastest Tactic: 1 Time: 0.456764\n",
      "[04/10/2022-15:17:51] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage1_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add/add (CublasConvolution)\n",
      "[04/10/2022-15:17:51] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:17:51] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage1_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add/add (CaskConvolution)\n",
      "[04/10/2022-15:17:51] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add/add Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758\n",
      "[04/10/2022-15:17:51] [V] [TRT] Tactic: 1062367460111450758 Time: 0.324785\n",
      "[04/10/2022-15:17:51] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add/add Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347\n",
      "[04/10/2022-15:17:51] [V] [TRT] Tactic: 1698681053543049347 Time: 0.277201\n",
      "[04/10/2022-15:17:51] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add/add Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441\n",
      "[04/10/2022-15:17:51] [V] [TRT] Tactic: 4501471010995462441 Time: 0.437155\n",
      "[04/10/2022-15:17:51] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add/add Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826\n",
      "[04/10/2022-15:17:51] [V] [TRT] Tactic: 5137655947464784826 Time: 0.230182\n",
      "[04/10/2022-15:17:51] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add/add Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929\n",
      "[04/10/2022-15:17:51] [V] [TRT] Tactic: 5288347012147084929 Time: 0.442819\n",
      "[04/10/2022-15:17:51] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add/add Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011\n",
      "[04/10/2022-15:17:51] [V] [TRT] Tactic: 5326823351883942011 Time: 0.412161\n",
      "[04/10/2022-15:17:51] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add/add Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314\n",
      "[04/10/2022-15:17:51] [V] [TRT] Tactic: 5500448035057547314 Time: 0.249674\n",
      "[04/10/2022-15:17:51] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add/add Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056\n",
      "[04/10/2022-15:17:51] [V] [TRT] Tactic: 6645123197870846056 Time: 0.233906\n",
      "[04/10/2022-15:17:51] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add/add Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478\n",
      "[04/10/2022-15:17:51] [V] [TRT] Tactic: 7144526460361122478 Time: 0.311973\n",
      "[04/10/2022-15:17:51] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add/add Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730\n",
      "[04/10/2022-15:17:51] [V] [TRT] Tactic: -8262349710178828730 Time: 0.447168\n",
      "[04/10/2022-15:17:51] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add/add Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580\n",
      "[04/10/2022-15:17:51] [V] [TRT] Tactic: -6576203419454146580 Time: 0.286419\n",
      "[04/10/2022-15:17:51] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add/add Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159\n",
      "[04/10/2022-15:17:51] [V] [TRT] Tactic: -4787320710726427159 Time: 0.318522\n",
      "[04/10/2022-15:17:51] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add/add Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839\n",
      "[04/10/2022-15:17:51] [V] [TRT] Tactic: -3456450830548107839 Time: 0.295534\n",
      "[04/10/2022-15:17:51] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add/add Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241\n",
      "[04/10/2022-15:17:51] [V] [TRT] Tactic: -1218658103698133241 Time: 0.258509\n",
      "[04/10/2022-15:17:51] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add/add Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091\n",
      "[04/10/2022-15:17:51] [V] [TRT] Tactic: -836875257600482091 Time: 0.258093\n",
      "[04/10/2022-15:17:51] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add/add Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746\n",
      "[04/10/2022-15:17:51] [V] [TRT] Tactic: -410470605513481746 Time: 0.419303\n",
      "[04/10/2022-15:17:51] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add/add Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884\n",
      "[04/10/2022-15:17:51] [V] [TRT] Tactic: -377491875521947884 Time: 0.435169\n",
      "[04/10/2022-15:17:51] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add/add Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163\n",
      "[04/10/2022-15:17:51] [V] [TRT] Tactic: -37215280111360163 Time: 0.228744\n",
      "[04/10/2022-15:17:51] [V] [TRT] Fastest Tactic: -37215280111360163 Time: 0.228744\n",
      "[04/10/2022-15:17:51] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -37215280111360163\n",
      "[04/10/2022-15:17:51] [V] [TRT] *************** Autotuning format combination: Float(200704,1,3584,64), Float(200704,1,3584,64) -> Float(200704,1,3584,64) ***************\n",
      "[04/10/2022-15:17:51] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage1_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add/add (CudnnConvolution)\n",
      "[04/10/2022-15:17:51] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:17:51] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage1_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add/add (CublasConvolution)\n",
      "[04/10/2022-15:17:51] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:17:51] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage1_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add/add (CaskConvolution)\n",
      "[04/10/2022-15:17:51] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add/add Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788\n",
      "[04/10/2022-15:17:51] [V] [TRT] Tactic: 3886731678879822788 Time: 0.298529\n",
      "[04/10/2022-15:17:51] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add/add Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200\n",
      "[04/10/2022-15:17:51] [V] [TRT] Tactic: 6629944304117643200 Time: 0.744297\n",
      "[04/10/2022-15:17:51] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add/add Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824\n",
      "[04/10/2022-15:17:51] [V] [TRT] Tactic: -9153228964338181824 Time: 0.750006\n",
      "[04/10/2022-15:17:51] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add/add Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025\n",
      "[04/10/2022-15:17:51] [V] [TRT] Tactic: -7394439838318485025 Time: 0.299981\n",
      "[04/10/2022-15:17:51] [V] [TRT] Fastest Tactic: 3886731678879822788 Time: 0.298529\n",
      "[04/10/2022-15:17:51] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 3886731678879822788\n",
      "[04/10/2022-15:17:51] [V] [TRT] *************** Autotuning format combination: Half(200704,3136,56,1), Half(200704,3136,56,1) -> Half(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:51] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage1_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add/add (CudnnConvolution)\n",
      "[04/10/2022-15:17:51] [V] [TRT] Tactic: 0 Time: 0.48543\n",
      "[04/10/2022-15:17:51] [V] [TRT] Tactic: 1 Time: 0.485853\n",
      "[04/10/2022-15:17:51] [V] [TRT] Tactic: 2 Time: 0.744837\n",
      "[04/10/2022-15:17:52] [V] [TRT] Tactic: 4 Time: 26.7437\n",
      "[04/10/2022-15:17:52] [V] [TRT] Tactic: 5 Time: 1.19538\n",
      "[04/10/2022-15:17:52] [V] [TRT] Fastest Tactic: 0 Time: 0.48543\n",
      "[04/10/2022-15:17:52] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage1_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add/add (CublasConvolution)\n",
      "[04/10/2022-15:17:52] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:17:52] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage1_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add/add (CaskConvolution)\n",
      "[04/10/2022-15:17:52] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:17:52] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 0\n",
      "[04/10/2022-15:17:52] [V] [TRT] *************** Autotuning format combination: Half(100352,3136:2,56,1), Half(100352,3136:2,56,1) -> Half(100352,3136:2,56,1) ***************\n",
      "[04/10/2022-15:17:52] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage1_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add/add (FusedConvActConvolution)\n",
      "[04/10/2022-15:17:52] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:17:52] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage1_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add/add (CudnnConvolution)\n",
      "[04/10/2022-15:17:52] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:17:52] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage1_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add/add (CublasConvolution)\n",
      "[04/10/2022-15:17:52] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:17:52] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage1_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add/add (CaskConvolution)\n",
      "[04/10/2022-15:17:52] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add/add Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_interior_nn_v1 Tactic: 3066127711859985668\n",
      "[04/10/2022-15:17:52] [V] [TRT] Tactic: 3066127711859985668 Time: 0.175247\n",
      "[04/10/2022-15:17:52] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add/add Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998\n",
      "[04/10/2022-15:17:52] [V] [TRT] Tactic: 3564772625446233998 Time: 0.185944\n",
      "[04/10/2022-15:17:52] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add/add Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452\n",
      "[04/10/2022-15:17:52] [V] [TRT] Tactic: 5319956359050645452 Time: 0.177793\n",
      "[04/10/2022-15:17:52] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add/add Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848\n",
      "[04/10/2022-15:17:52] [V] [TRT] Tactic: 7205456024582378848 Time: 0.13459\n",
      "[04/10/2022-15:17:52] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add/add Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 8163473458334948789\n",
      "[04/10/2022-15:17:52] [V] [TRT] Tactic: 8163473458334948789 Time: 0.132168\n",
      "[04/10/2022-15:17:52] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add/add Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890\n",
      "[04/10/2022-15:17:52] [V] [TRT] Tactic: -4212163711445252890 Time: 0.245612\n",
      "[04/10/2022-15:17:52] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add/add Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110\n",
      "[04/10/2022-15:17:52] [V] [TRT] Tactic: -3898373634979201110 Time: 0.246328\n",
      "[04/10/2022-15:17:52] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add/add Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473\n",
      "[04/10/2022-15:17:52] [V] [TRT] Tactic: -2409163523992614473 Time: 0.133991\n",
      "[04/10/2022-15:17:52] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add/add Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322\n",
      "[04/10/2022-15:17:52] [V] [TRT] Tactic: -1716393687483585322 Time: 0.238294\n",
      "[04/10/2022-15:17:52] [V] [TRT] Fastest Tactic: 8163473458334948789 Time: 0.132168\n",
      "[04/10/2022-15:17:52] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 8163473458334948789\n",
      "[04/10/2022-15:17:52] [V] [TRT] *************** Autotuning Reformat:Float(200704,3136,56,1) -> Float(200704,1,3584,64) ***************\n",
      "[04/10/2022-15:17:52] [V] [TRT] *************** Autotuning Reformat:Float(200704,3136,56,1) -> Half(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:52] [V] [TRT] *************** Autotuning Reformat:Float(200704,3136,56,1) -> Half(100352,3136:2,56,1) ***************\n",
      "[04/10/2022-15:17:52] [V] [TRT] *************** Autotuning Reformat:Float(200704,1,3584,64) -> Float(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:52] [V] [TRT] *************** Autotuning Reformat:Float(200704,1,3584,64) -> Half(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:52] [V] [TRT] *************** Autotuning Reformat:Float(200704,1,3584,64) -> Half(100352,3136:2,56,1) ***************\n",
      "[04/10/2022-15:17:52] [V] [TRT] *************** Autotuning Reformat:Half(200704,3136,56,1) -> Float(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:52] [V] [TRT] *************** Autotuning Reformat:Half(200704,3136,56,1) -> Float(200704,1,3584,64) ***************\n",
      "[04/10/2022-15:17:52] [V] [TRT] *************** Autotuning Reformat:Half(200704,3136,56,1) -> Half(100352,3136:2,56,1) ***************\n",
      "[04/10/2022-15:17:52] [V] [TRT] *************** Autotuning Reformat:Half(100352,3136:2,56,1) -> Float(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:52] [V] [TRT] *************** Autotuning Reformat:Half(100352,3136:2,56,1) -> Float(200704,1,3584,64) ***************\n",
      "[04/10/2022-15:17:52] [V] [TRT] *************** Autotuning Reformat:Half(100352,3136:2,56,1) -> Half(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:52] [V] [TRT] *************** Autotuning Reformat:Float(200704,3136,56,1) -> Float(200704,1,3584,64) ***************\n",
      "[04/10/2022-15:17:52] [V] [TRT] *************** Autotuning Reformat:Float(200704,3136,56,1) -> Half(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:52] [V] [TRT] *************** Autotuning Reformat:Float(200704,3136,56,1) -> Half(100352,3136:2,56,1) ***************\n",
      "[04/10/2022-15:17:52] [V] [TRT] *************** Autotuning Reformat:Float(200704,1,3584,64) -> Float(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:52] [V] [TRT] *************** Autotuning Reformat:Float(200704,1,3584,64) -> Half(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:52] [V] [TRT] *************** Autotuning Reformat:Float(200704,1,3584,64) -> Half(100352,3136:2,56,1) ***************\n",
      "[04/10/2022-15:17:52] [V] [TRT] *************** Autotuning Reformat:Half(200704,3136,56,1) -> Float(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:52] [V] [TRT] *************** Autotuning Reformat:Half(200704,3136,56,1) -> Float(200704,1,3584,64) ***************\n",
      "[04/10/2022-15:17:52] [V] [TRT] *************** Autotuning Reformat:Half(200704,3136,56,1) -> Half(100352,3136:2,56,1) ***************\n",
      "[04/10/2022-15:17:52] [V] [TRT] *************** Autotuning Reformat:Half(100352,3136:2,56,1) -> Float(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:52] [V] [TRT] *************** Autotuning Reformat:Half(100352,3136:2,56,1) -> Float(200704,1,3584,64) ***************\n",
      "[04/10/2022-15:17:52] [V] [TRT] *************** Autotuning Reformat:Half(100352,3136:2,56,1) -> Half(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:52] [V] [TRT] *************** Autotuning format combination: Float(200704,3136,56,1) -> Float(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:52] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage1_unit2_bn1/FusedBatchNormV3 + StatefulPartitionedCall/model_1/stage1_unit2_relu1/Relu (Scale)\n",
      "[04/10/2022-15:17:52] [V] [TRT] Tactic: 0 Time: 0.136022\n",
      "[04/10/2022-15:17:52] [V] [TRT] Fastest Tactic: 0 Time: 0.136022\n",
      "[04/10/2022-15:17:52] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Scale Tactic: 0\n",
      "[04/10/2022-15:17:52] [V] [TRT] *************** Autotuning format combination: Float(200704,1,3584,64) -> Float(200704,1,3584,64) ***************\n",
      "[04/10/2022-15:17:52] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage1_unit2_bn1/FusedBatchNormV3 + StatefulPartitionedCall/model_1/stage1_unit2_relu1/Relu (Scale)\n",
      "[04/10/2022-15:17:52] [V] [TRT] Scale has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:17:52] [V] [TRT] *************** Autotuning format combination: Half(200704,3136,56,1) -> Half(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:52] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage1_unit2_bn1/FusedBatchNormV3 + StatefulPartitionedCall/model_1/stage1_unit2_relu1/Relu (Scale)\n",
      "[04/10/2022-15:17:52] [V] [TRT] Tactic: 0 Time: 0.13114\n",
      "[04/10/2022-15:17:52] [V] [TRT] Fastest Tactic: 0 Time: 0.13114\n",
      "[04/10/2022-15:17:52] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Scale Tactic: 0\n",
      "[04/10/2022-15:17:52] [V] [TRT] *************** Autotuning format combination: Half(100352,3136:2,56,1) -> Half(100352,3136:2,56,1) ***************\n",
      "[04/10/2022-15:17:52] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage1_unit2_bn1/FusedBatchNormV3 + StatefulPartitionedCall/model_1/stage1_unit2_relu1/Relu (Scale)\n",
      "[04/10/2022-15:17:52] [V] [TRT] Tactic: 0 Time: 0.158626\n",
      "[04/10/2022-15:17:52] [V] [TRT] Fastest Tactic: 0 Time: 0.158626\n",
      "[04/10/2022-15:17:52] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Scale Tactic: 0\n",
      "[04/10/2022-15:17:52] [V] [TRT] *************** Autotuning Reformat:Float(200704,3136,56,1) -> Float(200704,1,3584,64) ***************\n",
      "[04/10/2022-15:17:52] [V] [TRT] *************** Autotuning Reformat:Float(200704,3136,56,1) -> Half(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:52] [V] [TRT] *************** Autotuning Reformat:Float(200704,3136,56,1) -> Half(100352,3136:2,56,1) ***************\n",
      "[04/10/2022-15:17:52] [V] [TRT] *************** Autotuning Reformat:Float(200704,1,3584,64) -> Float(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:52] [V] [TRT] *************** Autotuning Reformat:Float(200704,1,3584,64) -> Half(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:52] [V] [TRT] *************** Autotuning Reformat:Float(200704,1,3584,64) -> Half(100352,3136:2,56,1) ***************\n",
      "[04/10/2022-15:17:52] [V] [TRT] *************** Autotuning Reformat:Half(200704,3136,56,1) -> Float(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:52] [V] [TRT] *************** Autotuning Reformat:Half(200704,3136,56,1) -> Float(200704,1,3584,64) ***************\n",
      "[04/10/2022-15:17:52] [V] [TRT] *************** Autotuning Reformat:Half(200704,3136,56,1) -> Half(100352,3136:2,56,1) ***************\n",
      "[04/10/2022-15:17:52] [V] [TRT] *************** Autotuning Reformat:Half(100352,3136:2,56,1) -> Float(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:52] [V] [TRT] *************** Autotuning Reformat:Half(100352,3136:2,56,1) -> Float(200704,1,3584,64) ***************\n",
      "[04/10/2022-15:17:52] [V] [TRT] *************** Autotuning Reformat:Half(100352,3136:2,56,1) -> Half(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:52] [V] [TRT] *************** Autotuning format combination: Float(200704,3136,56,1) -> Float(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:52] [V] [TRT] *************** Autotuning format combination: Float(200704,1,3584,64) -> Float(200704,1,3584,64) ***************\n",
      "[04/10/2022-15:17:52] [V] [TRT] *************** Autotuning format combination: Half(200704,3136,56,1) -> Half(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:52] [V] [TRT] *************** Autotuning format combination: Half(100352,3136:2,56,1) -> Half(100352,3136:2,56,1) ***************\n",
      "[04/10/2022-15:17:52] [V] [TRT] *************** Autotuning Reformat:Float(200704,3136,56,1) -> Float(200704,1,3584,64) ***************\n",
      "[04/10/2022-15:17:52] [V] [TRT] *************** Autotuning Reformat:Float(200704,3136,56,1) -> Half(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:52] [V] [TRT] *************** Autotuning Reformat:Float(200704,3136,56,1) -> Half(100352,3136:2,56,1) ***************\n",
      "[04/10/2022-15:17:52] [V] [TRT] *************** Autotuning Reformat:Float(200704,1,3584,64) -> Float(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:52] [V] [TRT] *************** Autotuning Reformat:Float(200704,1,3584,64) -> Half(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:52] [V] [TRT] *************** Autotuning Reformat:Float(200704,1,3584,64) -> Half(100352,3136:2,56,1) ***************\n",
      "[04/10/2022-15:17:52] [V] [TRT] *************** Autotuning Reformat:Half(200704,3136,56,1) -> Float(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:52] [V] [TRT] *************** Autotuning Reformat:Half(200704,3136,56,1) -> Float(200704,1,3584,64) ***************\n",
      "[04/10/2022-15:17:52] [V] [TRT] *************** Autotuning Reformat:Half(200704,3136,56,1) -> Half(100352,3136:2,56,1) ***************\n",
      "[04/10/2022-15:17:52] [V] [TRT] *************** Autotuning Reformat:Half(100352,3136:2,56,1) -> Float(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:52] [V] [TRT] *************** Autotuning Reformat:Half(100352,3136:2,56,1) -> Float(200704,1,3584,64) ***************\n",
      "[04/10/2022-15:17:52] [V] [TRT] *************** Autotuning Reformat:Half(100352,3136:2,56,1) -> Half(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:52] [V] [TRT] *************** Autotuning Reformat:Float(200704,3136,56,1) -> Float(200704,1,3584,64) ***************\n",
      "[04/10/2022-15:17:52] [V] [TRT] *************** Autotuning Reformat:Float(200704,3136,56,1) -> Half(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:52] [V] [TRT] *************** Autotuning Reformat:Float(200704,3136,56,1) -> Half(100352,3136:2,56,1) ***************\n",
      "[04/10/2022-15:17:52] [V] [TRT] *************** Autotuning Reformat:Float(200704,1,3584,64) -> Float(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:52] [V] [TRT] *************** Autotuning Reformat:Float(200704,1,3584,64) -> Half(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:52] [V] [TRT] *************** Autotuning Reformat:Float(200704,1,3584,64) -> Half(100352,3136:2,56,1) ***************\n",
      "[04/10/2022-15:17:52] [V] [TRT] *************** Autotuning Reformat:Half(200704,3136,56,1) -> Float(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:52] [V] [TRT] *************** Autotuning Reformat:Half(200704,3136,56,1) -> Float(200704,1,3584,64) ***************\n",
      "[04/10/2022-15:17:52] [V] [TRT] *************** Autotuning Reformat:Half(200704,3136,56,1) -> Half(100352,3136:2,56,1) ***************\n",
      "[04/10/2022-15:17:52] [V] [TRT] *************** Autotuning Reformat:Half(100352,3136:2,56,1) -> Float(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:52] [V] [TRT] *************** Autotuning Reformat:Half(100352,3136:2,56,1) -> Float(200704,1,3584,64) ***************\n",
      "[04/10/2022-15:17:52] [V] [TRT] *************** Autotuning Reformat:Half(100352,3136:2,56,1) -> Half(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:52] [V] [TRT] *************** Autotuning format combination: Float(200704,3136,56,1), Float(200704,3136,56,1) -> Float(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:52] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage1_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_1/add (CudaDepthwiseConvolution)\n",
      "[04/10/2022-15:17:52] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:17:52] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage1_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_1/add (FusedConvActConvolution)\n",
      "[04/10/2022-15:17:52] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:17:52] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage1_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_1/add (CudnnConvolution)\n",
      "[04/10/2022-15:17:52] [V] [TRT] Tactic: 0 Time: 4.17364\n",
      "[04/10/2022-15:17:52] [V] [TRT] Tactic: 1 Time: 1.54387\n",
      "[04/10/2022-15:17:52] [V] [TRT] Tactic: 2 Time: 4.31749\n",
      "[04/10/2022-15:17:53] [V] [TRT] Tactic: 4 Time: 26.264\n",
      "[04/10/2022-15:17:53] [V] [TRT] Tactic: 5 Time: 13.1564\n",
      "[04/10/2022-15:17:53] [V] [TRT] Tactic: 6 Time: 1.12344\n",
      "[04/10/2022-15:17:53] [V] [TRT] Fastest Tactic: 6 Time: 1.12344\n",
      "[04/10/2022-15:17:53] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage1_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_1/add (CaskConvolution)\n",
      "[04/10/2022-15:17:53] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_1/add Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758\n",
      "[04/10/2022-15:17:53] [V] [TRT] Tactic: 1062367460111450758 Time: 1.6041\n",
      "[04/10/2022-15:17:53] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_1/add Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v0 Tactic: 1754984623894446479\n",
      "[04/10/2022-15:17:53] [V] [TRT] Tactic: 1754984623894446479 Time: 1.75941\n",
      "[04/10/2022-15:17:53] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_1/add Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v0 Tactic: 3611739942397549984\n",
      "[04/10/2022-15:17:53] [V] [TRT] Tactic: 3611739942397549984 Time: 2.50299\n",
      "[04/10/2022-15:17:53] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_1/add Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v1 Tactic: 3827454225649558724\n",
      "[04/10/2022-15:17:53] [V] [TRT] Tactic: 3827454225649558724 Time: 1.51306\n",
      "[04/10/2022-15:17:53] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_1/add Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379\n",
      "[04/10/2022-15:17:53] [V] [TRT] Tactic: 4337000649858996379 Time: 1.28947\n",
      "[04/10/2022-15:17:53] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_1/add Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441\n",
      "[04/10/2022-15:17:53] [V] [TRT] Tactic: 4501471010995462441 Time: 2.49582\n",
      "[04/10/2022-15:17:53] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_1/add Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826\n",
      "[04/10/2022-15:17:53] [V] [TRT] Tactic: 5137655947464784826 Time: 1.24592\n",
      "[04/10/2022-15:17:53] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_1/add Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929\n",
      "[04/10/2022-15:17:53] [V] [TRT] Tactic: 5288347012147084929 Time: 2.45866\n",
      "[04/10/2022-15:17:53] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_1/add Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 5921334924264294896\n",
      "[04/10/2022-15:17:53] [V] [TRT] Tactic: 5921334924264294896 Time: 1.06713\n",
      "[04/10/2022-15:17:53] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_1/add Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056\n",
      "[04/10/2022-15:17:53] [V] [TRT] Tactic: 6645123197870846056 Time: 1.27551\n",
      "[04/10/2022-15:17:53] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_1/add Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478\n",
      "[04/10/2022-15:17:54] [V] [TRT] Tactic: 7144526460361122478 Time: 1.60381\n",
      "[04/10/2022-15:17:54] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_1/add Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: 7852627285308570038\n",
      "[04/10/2022-15:17:54] [V] [TRT] Tactic: 7852627285308570038 Time: 1.52536\n",
      "[04/10/2022-15:17:54] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_1/add Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713\n",
      "[04/10/2022-15:17:54] [V] [TRT] Tactic: -9137461792520977713 Time: 2.51712\n",
      "[04/10/2022-15:17:54] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_1/add Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v0 Tactic: -8776506421218919509\n",
      "[04/10/2022-15:17:54] [V] [TRT] Tactic: -8776506421218919509 Time: 1.50254\n",
      "[04/10/2022-15:17:54] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_1/add Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730\n",
      "[04/10/2022-15:17:54] [V] [TRT] Tactic: -8262349710178828730 Time: 2.53499\n",
      "[04/10/2022-15:17:54] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_1/add Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v0 Tactic: -8133971918129952780\n",
      "[04/10/2022-15:17:54] [V] [TRT] Tactic: -8133971918129952780 Time: 1.4629\n",
      "[04/10/2022-15:17:54] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_1/add Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144\n",
      "[04/10/2022-15:17:54] [V] [TRT] Tactic: -6092040395344634144 Time: 1.6715\n",
      "[04/10/2022-15:17:54] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_1/add Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159\n",
      "[04/10/2022-15:17:54] [V] [TRT] Tactic: -4787320710726427159 Time: 1.75315\n",
      "[04/10/2022-15:17:54] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_1/add Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839\n",
      "[04/10/2022-15:17:54] [V] [TRT] Tactic: -3456450830548107839 Time: 1.43775\n",
      "[04/10/2022-15:17:54] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_1/add Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v0 Tactic: -2318106587342035239\n",
      "[04/10/2022-15:17:54] [V] [TRT] Tactic: -2318106587342035239 Time: 1.53372\n",
      "[04/10/2022-15:17:54] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_1/add Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_mobile_relu_tile148t_nt_v0 Tactic: -1343271414618805657\n",
      "[04/10/2022-15:17:54] [V] [TRT] Tactic: -1343271414618805657 Time: 0.981562\n",
      "[04/10/2022-15:17:54] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_1/add Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241\n",
      "[04/10/2022-15:17:54] [V] [TRT] Tactic: -1218658103698133241 Time: 1.44618\n",
      "[04/10/2022-15:17:54] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_1/add Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091\n",
      "[04/10/2022-15:17:54] [V] [TRT] Tactic: -836875257600482091 Time: 1.35167\n",
      "[04/10/2022-15:17:54] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_1/add Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746\n",
      "[04/10/2022-15:17:54] [V] [TRT] Tactic: -410470605513481746 Time: 2.42068\n",
      "[04/10/2022-15:17:54] [V] [TRT] Fastest Tactic: -1343271414618805657 Time: 0.981562\n",
      "[04/10/2022-15:17:54] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -1343271414618805657\n",
      "[04/10/2022-15:17:54] [V] [TRT] *************** Autotuning format combination: Float(200704,1,3584,64), Float(200704,1,3584,64) -> Float(200704,1,3584,64) ***************\n",
      "[04/10/2022-15:17:54] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage1_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_1/add (CudnnConvolution)\n",
      "[04/10/2022-15:17:54] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:17:54] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage1_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_1/add (CaskConvolution)\n",
      "[04/10/2022-15:17:54] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_1/add Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824\n",
      "[04/10/2022-15:17:54] [V] [TRT] Tactic: -9153228964338181824 Time: 1.86321\n",
      "[04/10/2022-15:17:54] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_1/add Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025\n",
      "[04/10/2022-15:17:54] [V] [TRT] Tactic: -7394439838318485025 Time: 1.25156\n",
      "[04/10/2022-15:17:54] [V] [TRT] Fastest Tactic: -7394439838318485025 Time: 1.25156\n",
      "[04/10/2022-15:17:54] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7394439838318485025\n",
      "[04/10/2022-15:17:54] [V] [TRT] *************** Autotuning format combination: Half(200704,3136,56,1), Half(200704,3136,56,1) -> Half(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:54] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage1_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_1/add (CudnnConvolution)\n",
      "[04/10/2022-15:17:54] [V] [TRT] Tactic: 0 Time: 2.92275\n",
      "[04/10/2022-15:17:54] [V] [TRT] Tactic: 1 Time: 2.93126\n",
      "[04/10/2022-15:17:54] [V] [TRT] Tactic: 2 Time: 4.08371\n",
      "[04/10/2022-15:17:55] [V] [TRT] Tactic: 4 Time: 26.9194\n",
      "[04/10/2022-15:17:55] [V] [TRT] Tactic: 5 Time: 12.6293\n",
      "[04/10/2022-15:17:55] [V] [TRT] Tactic: 6 Time: 2.13946\n",
      "[04/10/2022-15:17:55] [V] [TRT] Fastest Tactic: 6 Time: 2.13946\n",
      "[04/10/2022-15:17:55] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage1_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_1/add (CaskConvolution)\n",
      "[04/10/2022-15:17:55] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:17:55] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 6\n",
      "[04/10/2022-15:17:55] [V] [TRT] *************** Autotuning format combination: Half(100352,3136:2,56,1), Half(100352,3136:2,56,1) -> Half(100352,3136:2,56,1) ***************\n",
      "[04/10/2022-15:17:55] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage1_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_1/add (FusedConvActConvolution)\n",
      "[04/10/2022-15:17:55] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:17:55] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage1_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_1/add (CudnnConvolution)\n",
      "[04/10/2022-15:17:55] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:17:55] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage1_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_1/add (CaskConvolution)\n",
      "[04/10/2022-15:17:55] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_1/add Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998\n",
      "[04/10/2022-15:17:55] [V] [TRT] Tactic: 3564772625446233998 Time: 0.827884\n",
      "[04/10/2022-15:17:55] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_1/add Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_large_nn_v1 Tactic: 3650389455493082349\n",
      "[04/10/2022-15:17:55] [V] [TRT] Tactic: 3650389455493082349 Time: 0.857975\n",
      "[04/10/2022-15:17:55] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_1/add Set Tactic Name: maxwell_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 4772821744921268633\n",
      "[04/10/2022-15:17:55] [V] [TRT] Tactic: 4772821744921268633 Time: 0.54599\n",
      "[04/10/2022-15:17:55] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_1/add Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452\n",
      "[04/10/2022-15:17:55] [V] [TRT] Tactic: 5319956359050645452 Time: 0.755501\n",
      "[04/10/2022-15:17:55] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_1/add Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848\n",
      "[04/10/2022-15:17:55] [V] [TRT] Tactic: 7205456024582378848 Time: 0.661257\n",
      "[04/10/2022-15:17:55] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_1/add Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_large_nn_v1 Tactic: -6490690591794140522\n",
      "[04/10/2022-15:17:55] [V] [TRT] Tactic: -6490690591794140522 Time: 0.664206\n",
      "[04/10/2022-15:17:55] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_1/add Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_large_nn_v1 Tactic: -4686027666808657977\n",
      "[04/10/2022-15:17:55] [V] [TRT] Tactic: -4686027666808657977 Time: 1.28502\n",
      "[04/10/2022-15:17:55] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_1/add Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890\n",
      "[04/10/2022-15:17:55] [V] [TRT] Tactic: -4212163711445252890 Time: 1.24742\n",
      "[04/10/2022-15:17:55] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_1/add Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110\n",
      "[04/10/2022-15:17:55] [V] [TRT] Tactic: -3898373634979201110 Time: 1.28018\n",
      "[04/10/2022-15:17:55] [V] [TRT] StatefulPartitionedCall/model_1/stage1_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_1/add Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473\n",
      "[04/10/2022-15:17:55] [V] [TRT] Tactic: -2409163523992614473 Time: 0.638093\n",
      "[04/10/2022-15:17:55] [V] [TRT] Fastest Tactic: 4772821744921268633 Time: 0.54599\n",
      "[04/10/2022-15:17:55] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 4772821744921268633\n",
      "[04/10/2022-15:17:55] [V] [TRT] *************** Autotuning Reformat:Float(200704,3136,56,1) -> Float(200704,1,3584,64) ***************\n",
      "[04/10/2022-15:17:55] [V] [TRT] *************** Autotuning Reformat:Float(200704,3136,56,1) -> Half(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:55] [V] [TRT] *************** Autotuning Reformat:Float(200704,3136,56,1) -> Half(100352,3136:2,56,1) ***************\n",
      "[04/10/2022-15:17:55] [V] [TRT] *************** Autotuning Reformat:Float(200704,1,3584,64) -> Float(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:55] [V] [TRT] *************** Autotuning Reformat:Float(200704,1,3584,64) -> Half(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:55] [V] [TRT] *************** Autotuning Reformat:Float(200704,1,3584,64) -> Half(100352,3136:2,56,1) ***************\n",
      "[04/10/2022-15:17:55] [V] [TRT] *************** Autotuning Reformat:Half(200704,3136,56,1) -> Float(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:55] [V] [TRT] *************** Autotuning Reformat:Half(200704,3136,56,1) -> Float(200704,1,3584,64) ***************\n",
      "[04/10/2022-15:17:55] [V] [TRT] *************** Autotuning Reformat:Half(200704,3136,56,1) -> Half(100352,3136:2,56,1) ***************\n",
      "[04/10/2022-15:17:55] [V] [TRT] *************** Autotuning Reformat:Half(100352,3136:2,56,1) -> Float(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:55] [V] [TRT] *************** Autotuning Reformat:Half(100352,3136:2,56,1) -> Float(200704,1,3584,64) ***************\n",
      "[04/10/2022-15:17:55] [V] [TRT] *************** Autotuning Reformat:Half(100352,3136:2,56,1) -> Half(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:55] [V] [TRT] *************** Autotuning format combination: Float(200704,3136,56,1) -> Float(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:55] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage2_unit1_bn1/FusedBatchNormV3 + StatefulPartitionedCall/model_1/stage2_unit1_relu1/Relu (Scale)\n",
      "[04/10/2022-15:17:55] [V] [TRT] Tactic: 0 Time: 0.135449\n",
      "[04/10/2022-15:17:55] [V] [TRT] Fastest Tactic: 0 Time: 0.135449\n",
      "[04/10/2022-15:17:55] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Scale Tactic: 0\n",
      "[04/10/2022-15:17:55] [V] [TRT] *************** Autotuning format combination: Float(200704,1,3584,64) -> Float(200704,1,3584,64) ***************\n",
      "[04/10/2022-15:17:55] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage2_unit1_bn1/FusedBatchNormV3 + StatefulPartitionedCall/model_1/stage2_unit1_relu1/Relu (Scale)\n",
      "[04/10/2022-15:17:55] [V] [TRT] Scale has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:17:55] [V] [TRT] *************** Autotuning format combination: Half(200704,3136,56,1) -> Half(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:55] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage2_unit1_bn1/FusedBatchNormV3 + StatefulPartitionedCall/model_1/stage2_unit1_relu1/Relu (Scale)\n",
      "[04/10/2022-15:17:55] [V] [TRT] Tactic: 0 Time: 0.130436\n",
      "[04/10/2022-15:17:55] [V] [TRT] Fastest Tactic: 0 Time: 0.130436\n",
      "[04/10/2022-15:17:55] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Scale Tactic: 0\n",
      "[04/10/2022-15:17:55] [V] [TRT] *************** Autotuning format combination: Half(100352,3136:2,56,1) -> Half(100352,3136:2,56,1) ***************\n",
      "[04/10/2022-15:17:55] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage2_unit1_bn1/FusedBatchNormV3 + StatefulPartitionedCall/model_1/stage2_unit1_relu1/Relu (Scale)\n",
      "[04/10/2022-15:17:55] [V] [TRT] Tactic: 0 Time: 0.158529\n",
      "[04/10/2022-15:17:55] [V] [TRT] Fastest Tactic: 0 Time: 0.158529\n",
      "[04/10/2022-15:17:55] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Scale Tactic: 0\n",
      "[04/10/2022-15:17:55] [V] [TRT] *************** Autotuning Reformat:Float(200704,3136,56,1) -> Float(200704,1,3584,64) ***************\n",
      "[04/10/2022-15:17:55] [V] [TRT] *************** Autotuning Reformat:Float(200704,3136,56,1) -> Half(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:55] [V] [TRT] *************** Autotuning Reformat:Float(200704,3136,56,1) -> Half(100352,3136:2,56,1) ***************\n",
      "[04/10/2022-15:17:55] [V] [TRT] *************** Autotuning Reformat:Float(200704,1,3584,64) -> Float(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:55] [V] [TRT] *************** Autotuning Reformat:Float(200704,1,3584,64) -> Half(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:55] [V] [TRT] *************** Autotuning Reformat:Float(200704,1,3584,64) -> Half(100352,3136:2,56,1) ***************\n",
      "[04/10/2022-15:17:55] [V] [TRT] *************** Autotuning Reformat:Half(200704,3136,56,1) -> Float(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:55] [V] [TRT] *************** Autotuning Reformat:Half(200704,3136,56,1) -> Float(200704,1,3584,64) ***************\n",
      "[04/10/2022-15:17:55] [V] [TRT] *************** Autotuning Reformat:Half(200704,3136,56,1) -> Half(100352,3136:2,56,1) ***************\n",
      "[04/10/2022-15:17:55] [V] [TRT] *************** Autotuning Reformat:Half(100352,3136:2,56,1) -> Float(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:55] [V] [TRT] *************** Autotuning Reformat:Half(100352,3136:2,56,1) -> Float(200704,1,3584,64) ***************\n",
      "[04/10/2022-15:17:55] [V] [TRT] *************** Autotuning Reformat:Half(100352,3136:2,56,1) -> Half(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:55] [V] [TRT] *************** Autotuning Reformat:Float(200704,3136,56,1) -> Float(200704,1,3584,64) ***************\n",
      "[04/10/2022-15:17:55] [V] [TRT] *************** Autotuning Reformat:Float(200704,3136,56,1) -> Half(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:55] [V] [TRT] *************** Autotuning Reformat:Float(200704,3136,56,1) -> Half(100352,3136:2,56,1) ***************\n",
      "[04/10/2022-15:17:55] [V] [TRT] *************** Autotuning Reformat:Float(200704,1,3584,64) -> Float(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:55] [V] [TRT] *************** Autotuning Reformat:Float(200704,1,3584,64) -> Half(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:55] [V] [TRT] *************** Autotuning Reformat:Float(200704,1,3584,64) -> Half(100352,3136:2,56,1) ***************\n",
      "[04/10/2022-15:17:55] [V] [TRT] *************** Autotuning Reformat:Half(200704,3136,56,1) -> Float(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:55] [V] [TRT] *************** Autotuning Reformat:Half(200704,3136,56,1) -> Float(200704,1,3584,64) ***************\n",
      "[04/10/2022-15:17:55] [V] [TRT] *************** Autotuning Reformat:Half(200704,3136,56,1) -> Half(100352,3136:2,56,1) ***************\n",
      "[04/10/2022-15:17:55] [V] [TRT] *************** Autotuning Reformat:Half(100352,3136:2,56,1) -> Float(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:55] [V] [TRT] *************** Autotuning Reformat:Half(100352,3136:2,56,1) -> Float(200704,1,3584,64) ***************\n",
      "[04/10/2022-15:17:55] [V] [TRT] *************** Autotuning Reformat:Half(100352,3136:2,56,1) -> Half(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:17:55] [V] [TRT] *************** Autotuning format combination: Float(200704,3136,56,1) -> Float(100352,784,28,1) ***************\n",
      "[04/10/2022-15:17:55] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage2_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit1_relu2/Relu (CudaDepthwiseConvolution)\n",
      "[04/10/2022-15:17:55] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:17:55] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage2_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit1_relu2/Relu (FusedConvActConvolution)\n",
      "[04/10/2022-15:17:56] [V] [TRT] Tactic: 458751 Time: 0.924662\n",
      "[04/10/2022-15:17:56] [V] [TRT] Fastest Tactic: 458751 Time: 0.924662\n",
      "[04/10/2022-15:17:56] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage2_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit1_relu2/Relu (CudnnConvolution)\n",
      "[04/10/2022-15:17:56] [V] [TRT] Tactic: 0 Time: 1.54927\n",
      "[04/10/2022-15:17:56] [V] [TRT] Tactic: 1 Time: 1.54038\n",
      "[04/10/2022-15:17:56] [V] [TRT] Tactic: 2 Time: 1.35056\n",
      "[04/10/2022-15:17:56] [V] [TRT] Tactic: 5 Time: 26.706\n",
      "[04/10/2022-15:17:56] [V] [TRT] Fastest Tactic: 2 Time: 1.35056\n",
      "[04/10/2022-15:17:56] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage2_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit1_relu2/Relu (CaskConvolution)\n",
      "[04/10/2022-15:17:56] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758\n",
      "[04/10/2022-15:17:56] [V] [TRT] Tactic: 1062367460111450758 Time: 0.924407\n",
      "[04/10/2022-15:17:56] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v0 Tactic: 1754984623894446479\n",
      "[04/10/2022-15:17:56] [V] [TRT] Tactic: 1754984623894446479 Time: 1.02227\n",
      "[04/10/2022-15:17:56] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v0 Tactic: 3611739942397549984\n",
      "[04/10/2022-15:17:56] [V] [TRT] Tactic: 3611739942397549984 Time: 0.742214\n",
      "[04/10/2022-15:17:56] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379\n",
      "[04/10/2022-15:17:56] [V] [TRT] Tactic: 4337000649858996379 Time: 0.738906\n",
      "[04/10/2022-15:17:56] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441\n",
      "[04/10/2022-15:17:56] [V] [TRT] Tactic: 4501471010995462441 Time: 0.731211\n",
      "[04/10/2022-15:17:56] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826\n",
      "[04/10/2022-15:17:56] [V] [TRT] Tactic: 5137655947464784826 Time: 0.708555\n",
      "[04/10/2022-15:17:56] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929\n",
      "[04/10/2022-15:17:56] [V] [TRT] Tactic: 5288347012147084929 Time: 0.724134\n",
      "[04/10/2022-15:17:56] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056\n",
      "[04/10/2022-15:17:56] [V] [TRT] Tactic: 6645123197870846056 Time: 0.729583\n",
      "[04/10/2022-15:17:56] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478\n",
      "[04/10/2022-15:17:56] [V] [TRT] Tactic: 7144526460361122478 Time: 0.953027\n",
      "[04/10/2022-15:17:56] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713\n",
      "[04/10/2022-15:17:56] [V] [TRT] Tactic: -9137461792520977713 Time: 0.742591\n",
      "[04/10/2022-15:17:56] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730\n",
      "[04/10/2022-15:17:56] [V] [TRT] Tactic: -8262349710178828730 Time: 0.743691\n",
      "[04/10/2022-15:17:56] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v0 Tactic: -8133971918129952780\n",
      "[04/10/2022-15:17:56] [V] [TRT] Tactic: -8133971918129952780 Time: 0.824668\n",
      "[04/10/2022-15:17:56] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144\n",
      "[04/10/2022-15:17:56] [V] [TRT] Tactic: -6092040395344634144 Time: 0.953314\n",
      "[04/10/2022-15:17:56] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159\n",
      "[04/10/2022-15:17:56] [V] [TRT] Tactic: -4787320710726427159 Time: 1.0182\n",
      "[04/10/2022-15:17:56] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839\n",
      "[04/10/2022-15:17:56] [V] [TRT] Tactic: -3456450830548107839 Time: 0.846751\n",
      "[04/10/2022-15:17:57] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241\n",
      "[04/10/2022-15:17:57] [V] [TRT] Tactic: -1218658103698133241 Time: 0.824974\n",
      "[04/10/2022-15:17:57] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091\n",
      "[04/10/2022-15:17:57] [V] [TRT] Tactic: -836875257600482091 Time: 0.78291\n",
      "[04/10/2022-15:17:57] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746\n",
      "[04/10/2022-15:17:57] [V] [TRT] Tactic: -410470605513481746 Time: 0.712962\n",
      "[04/10/2022-15:17:57] [V] [TRT] Fastest Tactic: 5137655947464784826 Time: 0.708555\n",
      "[04/10/2022-15:17:57] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 5137655947464784826\n",
      "[04/10/2022-15:17:57] [V] [TRT] *************** Autotuning format combination: Float(200704,1,3584,64) -> Float(100352,1,3584,128) ***************\n",
      "[04/10/2022-15:17:57] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage2_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit1_relu2/Relu (CudnnConvolution)\n",
      "[04/10/2022-15:17:57] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:17:57] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage2_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit1_relu2/Relu (CaskConvolution)\n",
      "[04/10/2022-15:17:57] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824\n",
      "[04/10/2022-15:17:57] [V] [TRT] Tactic: -9153228964338181824 Time: 1.0566\n",
      "[04/10/2022-15:17:57] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025\n",
      "[04/10/2022-15:17:57] [V] [TRT] Tactic: -7394439838318485025 Time: 0.709251\n",
      "[04/10/2022-15:17:57] [V] [TRT] Fastest Tactic: -7394439838318485025 Time: 0.709251\n",
      "[04/10/2022-15:17:57] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7394439838318485025\n",
      "[04/10/2022-15:17:57] [V] [TRT] *************** Autotuning format combination: Half(200704,3136,56,1) -> Half(100352,784,28,1) ***************\n",
      "[04/10/2022-15:17:57] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage2_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit1_relu2/Relu (CudnnConvolution)\n",
      "[04/10/2022-15:17:57] [V] [TRT] Tactic: 0 Time: 1.56524\n",
      "[04/10/2022-15:17:57] [V] [TRT] Tactic: 1 Time: 1.3198\n",
      "[04/10/2022-15:17:57] [V] [TRT] Tactic: 2 Time: 1.26667\n",
      "[04/10/2022-15:17:57] [V] [TRT] Tactic: 5 Time: 26.1643\n",
      "[04/10/2022-15:17:57] [V] [TRT] Fastest Tactic: 2 Time: 1.26667\n",
      "[04/10/2022-15:17:57] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage2_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit1_relu2/Relu (CaskConvolution)\n",
      "[04/10/2022-15:17:57] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:17:57] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 2\n",
      "[04/10/2022-15:17:57] [V] [TRT] *************** Autotuning format combination: Half(100352,3136:2,56,1) -> Half(50176,784:2,28,1) ***************\n",
      "[04/10/2022-15:17:57] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage2_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit1_relu2/Relu (FusedConvActConvolution)\n",
      "[04/10/2022-15:17:57] [V] [TRT] Tactic: 458751 Time: 0.768503\n",
      "[04/10/2022-15:17:57] [V] [TRT] Fastest Tactic: 458751 Time: 0.768503\n",
      "[04/10/2022-15:17:57] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage2_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit1_relu2/Relu (CudnnConvolution)\n",
      "[04/10/2022-15:17:57] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:17:57] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage2_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit1_relu2/Relu (CaskConvolution)\n",
      "[04/10/2022-15:17:57] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit1_relu2/Relu Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998\n",
      "[04/10/2022-15:17:57] [V] [TRT] Tactic: 3564772625446233998 Time: 0.473926\n",
      "[04/10/2022-15:17:57] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit1_relu2/Relu Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_large_nn_v1 Tactic: 3650389455493082349\n",
      "[04/10/2022-15:17:57] [V] [TRT] Tactic: 3650389455493082349 Time: 0.491536\n",
      "[04/10/2022-15:17:57] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit1_relu2/Relu Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452\n",
      "[04/10/2022-15:17:57] [V] [TRT] Tactic: 5319956359050645452 Time: 0.433795\n",
      "[04/10/2022-15:17:57] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit1_relu2/Relu Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848\n",
      "[04/10/2022-15:17:57] [V] [TRT] Tactic: 7205456024582378848 Time: 0.372871\n",
      "[04/10/2022-15:17:57] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit1_relu2/Relu Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_large_nn_v1 Tactic: -6490690591794140522\n",
      "[04/10/2022-15:17:57] [V] [TRT] Tactic: -6490690591794140522 Time: 0.381849\n",
      "[04/10/2022-15:17:57] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit1_relu2/Relu Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_large_nn_v1 Tactic: -4686027666808657977\n",
      "[04/10/2022-15:17:57] [V] [TRT] Tactic: -4686027666808657977 Time: 0.371276\n",
      "[04/10/2022-15:17:57] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit1_relu2/Relu Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890\n",
      "[04/10/2022-15:17:57] [V] [TRT] Tactic: -4212163711445252890 Time: 0.353958\n",
      "[04/10/2022-15:17:57] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit1_relu2/Relu Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110\n",
      "[04/10/2022-15:17:57] [V] [TRT] Tactic: -3898373634979201110 Time: 0.367214\n",
      "[04/10/2022-15:17:57] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit1_relu2/Relu Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473\n",
      "[04/10/2022-15:17:57] [V] [TRT] Tactic: -2409163523992614473 Time: 0.363483\n",
      "[04/10/2022-15:17:57] [V] [TRT] Fastest Tactic: -4212163711445252890 Time: 0.353958\n",
      "[04/10/2022-15:17:57] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -4212163711445252890\n",
      "[04/10/2022-15:17:57] [V] [TRT] *************** Autotuning Reformat:Float(100352,784,28,1) -> Float(100352,1,3584,128) ***************\n",
      "[04/10/2022-15:17:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:17:57] [V] [TRT] Tactic: 1002 Time: 0.114395\n",
      "[04/10/2022-15:17:57] [V] [TRT] Tactic: 0 Time: 0.16903\n",
      "[04/10/2022-15:17:57] [V] [TRT] Fastest Tactic: 1002 Time: 0.114395\n",
      "[04/10/2022-15:17:57] [V] [TRT] *************** Autotuning Reformat:Float(100352,784,28,1) -> Half(100352,784,28,1) ***************\n",
      "[04/10/2022-15:17:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:17:57] [V] [TRT] Tactic: 1002 Time: 0.168509\n",
      "[04/10/2022-15:17:57] [V] [TRT] Tactic: 0 Time: 0.110716\n",
      "[04/10/2022-15:17:57] [V] [TRT] Fastest Tactic: 0 Time: 0.110716\n",
      "[04/10/2022-15:17:57] [V] [TRT] *************** Autotuning Reformat:Float(100352,784,28,1) -> Half(50176,784:2,28,1) ***************\n",
      "[04/10/2022-15:17:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:17:57] [V] [TRT] Tactic: 1002 Time: 0.153997\n",
      "[04/10/2022-15:17:57] [V] [TRT] Tactic: 0 Time: 0.088229\n",
      "[04/10/2022-15:17:57] [V] [TRT] Fastest Tactic: 0 Time: 0.088229\n",
      "[04/10/2022-15:17:57] [V] [TRT] *************** Autotuning Reformat:Float(100352,1,3584,128) -> Float(100352,784,28,1) ***************\n",
      "[04/10/2022-15:17:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:17:57] [V] [TRT] Tactic: 1002 Time: 0.138835\n",
      "[04/10/2022-15:17:57] [V] [TRT] Tactic: 0 Time: 0.163561\n",
      "[04/10/2022-15:17:57] [V] [TRT] Fastest Tactic: 1002 Time: 0.138835\n",
      "[04/10/2022-15:17:57] [V] [TRT] *************** Autotuning Reformat:Float(100352,1,3584,128) -> Half(100352,784,28,1) ***************\n",
      "[04/10/2022-15:17:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:17:57] [V] [TRT] Tactic: 1002 Time: 0.103411\n",
      "[04/10/2022-15:17:57] [V] [TRT] Tactic: 0 Time: 0.161882\n",
      "[04/10/2022-15:17:57] [V] [TRT] Fastest Tactic: 1002 Time: 0.103411\n",
      "[04/10/2022-15:17:57] [V] [TRT] *************** Autotuning Reformat:Float(100352,1,3584,128) -> Half(50176,784:2,28,1) ***************\n",
      "[04/10/2022-15:17:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:17:57] [V] [TRT] Tactic: 1002 Time: 0.135508\n",
      "[04/10/2022-15:17:58] [V] [TRT] Tactic: 0 Time: 0.183249\n",
      "[04/10/2022-15:17:58] [V] [TRT] Fastest Tactic: 1002 Time: 0.135508\n",
      "[04/10/2022-15:17:58] [V] [TRT] *************** Autotuning Reformat:Half(100352,784,28,1) -> Float(100352,784,28,1) ***************\n",
      "[04/10/2022-15:17:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:17:58] [V] [TRT] Tactic: 1002 Time: 0.170209\n",
      "[04/10/2022-15:17:58] [V] [TRT] Tactic: 0 Time: 0.0931251\n",
      "[04/10/2022-15:17:58] [V] [TRT] Fastest Tactic: 0 Time: 0.0931251\n",
      "[04/10/2022-15:17:58] [V] [TRT] *************** Autotuning Reformat:Half(100352,784,28,1) -> Float(100352,1,3584,128) ***************\n",
      "[04/10/2022-15:17:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:17:58] [V] [TRT] Tactic: 1002 Time: 0.0972461\n",
      "[04/10/2022-15:17:58] [V] [TRT] Tactic: 0 Time: 0.157415\n",
      "[04/10/2022-15:17:58] [V] [TRT] Fastest Tactic: 1002 Time: 0.0972461\n",
      "[04/10/2022-15:17:58] [V] [TRT] *************** Autotuning Reformat:Half(100352,784,28,1) -> Half(50176,784:2,28,1) ***************\n",
      "[04/10/2022-15:17:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:17:58] [V] [TRT] Tactic: 1002 Time: 0.105534\n",
      "[04/10/2022-15:17:58] [V] [TRT] Tactic: 0 Time: 0.0872786\n",
      "[04/10/2022-15:17:58] [V] [TRT] Fastest Tactic: 0 Time: 0.0872786\n",
      "[04/10/2022-15:17:58] [V] [TRT] *************** Autotuning Reformat:Half(50176,784:2,28,1) -> Float(100352,784,28,1) ***************\n",
      "[04/10/2022-15:17:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:17:58] [V] [TRT] Tactic: 1002 Time: 0.12875\n",
      "[04/10/2022-15:17:58] [V] [TRT] Tactic: 0 Time: 0.0759375\n",
      "[04/10/2022-15:17:58] [V] [TRT] Fastest Tactic: 0 Time: 0.0759375\n",
      "[04/10/2022-15:17:58] [V] [TRT] *************** Autotuning Reformat:Half(50176,784:2,28,1) -> Float(100352,1,3584,128) ***************\n",
      "[04/10/2022-15:17:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:17:58] [V] [TRT] Tactic: 1002 Time: 0.0985093\n",
      "[04/10/2022-15:17:58] [V] [TRT] Tactic: 0 Time: 0.181302\n",
      "[04/10/2022-15:17:58] [V] [TRT] Fastest Tactic: 1002 Time: 0.0985093\n",
      "[04/10/2022-15:17:58] [V] [TRT] *************** Autotuning Reformat:Half(50176,784:2,28,1) -> Half(100352,784,28,1) ***************\n",
      "[04/10/2022-15:17:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:17:58] [V] [TRT] Tactic: 1002 Time: 0.18597\n",
      "[04/10/2022-15:17:58] [V] [TRT] Tactic: 0 Time: 0.0746354\n",
      "[04/10/2022-15:17:58] [V] [TRT] Fastest Tactic: 0 Time: 0.0746354\n",
      "[04/10/2022-15:17:58] [V] [TRT] *************** Autotuning format combination: Float(100352,784,28,1) -> Float(100352,784,28,1) ***************\n",
      "[04/10/2022-15:17:58] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage2_unit1_conv2/Conv2D (CudaDepthwiseConvolution)\n",
      "[04/10/2022-15:17:58] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:17:58] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage2_unit1_conv2/Conv2D (FusedConvActConvolution)\n",
      "[04/10/2022-15:17:58] [V] [TRT] Tactic: 524287 Time: 1.41716\n",
      "[04/10/2022-15:17:58] [V] [TRT] Tactic: 720895 Time: 1.49781\n",
      "[04/10/2022-15:17:58] [V] [TRT] Tactic: 983039 Time: 1.3509\n",
      "[04/10/2022-15:17:58] [V] [TRT] Tactic: 1048575 Time: 1.64595\n",
      "[04/10/2022-15:17:58] [V] [TRT] Tactic: 1703935 Time: 1.64928\n",
      "[04/10/2022-15:17:58] [V] [TRT] Tactic: 1769471 Time: 1.60153\n",
      "[04/10/2022-15:17:58] [V] [TRT] Tactic: 1966079 Time: 1.44626\n",
      "[04/10/2022-15:17:58] [V] [TRT] Tactic: 2031615 Time: 1.54533\n",
      "[04/10/2022-15:17:58] [V] [TRT] Tactic: 2228223 Time: 1.73631\n",
      "[04/10/2022-15:17:59] [V] [TRT] Tactic: 2424831 Time: 2.00492\n",
      "[04/10/2022-15:17:59] [V] [TRT] Tactic: 2621439 Time: 2.06018\n",
      "[04/10/2022-15:17:59] [V] [TRT] Tactic: 2752511 Time: 1.45865\n",
      "[04/10/2022-15:17:59] [V] [TRT] Tactic: 2818047 Time: 1.97493\n",
      "[04/10/2022-15:17:59] [V] [TRT] Tactic: 2883583 Time: 1.4669\n",
      "[04/10/2022-15:17:59] [V] [TRT] Tactic: 3014655 Time: 1.55208\n",
      "[04/10/2022-15:17:59] [V] [TRT] Tactic: 3145727 Time: 1.43111\n",
      "[04/10/2022-15:17:59] [V] [TRT] Tactic: 3473407 Time: 1.521\n",
      "[04/10/2022-15:17:59] [V] [TRT] Tactic: 3604479 Time: 1.52651\n",
      "[04/10/2022-15:17:59] [V] [TRT] Tactic: 3735551 Time: 1.86542\n",
      "[04/10/2022-15:18:00] [V] [TRT] Tactic: 4390911 Time: 1.44158\n",
      "[04/10/2022-15:18:00] [V] [TRT] Tactic: 5046271 Time: 1.39071\n",
      "[04/10/2022-15:18:00] [V] [TRT] Tactic: 5963775 Time: 1.30592\n",
      "[04/10/2022-15:18:00] [V] [TRT] Tactic: 6160383 Time: 1.3802\n",
      "[04/10/2022-15:18:00] [V] [TRT] Tactic: 6488063 Time: 1.404\n",
      "[04/10/2022-15:18:00] [V] [TRT] Tactic: 6881279 Time: 1.49604\n",
      "[04/10/2022-15:18:00] [V] [TRT] Tactic: 7274495 Time: 2.06676\n",
      "[04/10/2022-15:18:00] [V] [TRT] Tactic: 7864319 Time: 1.8003\n",
      "[04/10/2022-15:18:00] [V] [TRT] Tactic: 7995391 Time: 1.52978\n",
      "[04/10/2022-15:18:00] [V] [TRT] Tactic: 8585215 Time: 1.43973\n",
      "[04/10/2022-15:18:00] [V] [TRT] Tactic: 8847359 Time: 1.57861\n",
      "[04/10/2022-15:18:01] [V] [TRT] Tactic: 8978431 Time: 1.32574\n",
      "[04/10/2022-15:18:01] [V] [TRT] Tactic: 9043967 Time: 1.4128\n",
      "[04/10/2022-15:18:01] [V] [TRT] Tactic: 9175039 Time: 1.52647\n",
      "[04/10/2022-15:18:01] [V] [TRT] Tactic: 9502719 Time: 1.45917\n",
      "[04/10/2022-15:18:01] [V] [TRT] Tactic: 9830399 Time: 1.43889\n",
      "[04/10/2022-15:18:01] [V] [TRT] Tactic: 9961471 Time: 1.71751\n",
      "[04/10/2022-15:18:01] [V] [TRT] Tactic: 10027007 Time: 1.4176\n",
      "[04/10/2022-15:18:01] [V] [TRT] Tactic: 10092543 Time: 1.44169\n",
      "[04/10/2022-15:18:01] [V] [TRT] Tactic: 10289151 Time: 1.4444\n",
      "[04/10/2022-15:18:01] [V] [TRT] Tactic: 10485759 Time: 1.44604\n",
      "[04/10/2022-15:18:01] [V] [TRT] Tactic: 10682367 Time: 2.04241\n",
      "[04/10/2022-15:18:02] [V] [TRT] Tactic: 10813439 Time: 1.52986\n",
      "[04/10/2022-15:18:02] [V] [TRT] Fastest Tactic: 5963775 Time: 1.30592\n",
      "[04/10/2022-15:18:02] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage2_unit1_conv2/Conv2D (CudnnConvolution)\n",
      "[04/10/2022-15:18:02] [V] [TRT] Tactic: 0 Time: 2.35826\n",
      "[04/10/2022-15:18:02] [V] [TRT] Tactic: 1 Time: 1.73259\n",
      "[04/10/2022-15:18:02] [V] [TRT] Tactic: 2 Time: 2.255\n",
      "[04/10/2022-15:18:02] [V] [TRT] Tactic: 4 Time: 22.8311\n",
      "[04/10/2022-15:18:03] [V] [TRT] Tactic: 5 Time: 22.3835\n",
      "[04/10/2022-15:18:03] [V] [TRT] Tactic: 6 Time: 1.09902\n",
      "[04/10/2022-15:18:03] [V] [TRT] Fastest Tactic: 6 Time: 1.09902\n",
      "[04/10/2022-15:18:03] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage2_unit1_conv2/Conv2D (CaskConvolution)\n",
      "[04/10/2022-15:18:03] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758\n",
      "[04/10/2022-15:18:03] [V] [TRT] Tactic: 1062367460111450758 Time: 1.74049\n",
      "[04/10/2022-15:18:03] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v0 Tactic: 1754984623894446479\n",
      "[04/10/2022-15:18:03] [V] [TRT] Tactic: 1754984623894446479 Time: 2.00668\n",
      "[04/10/2022-15:18:03] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v0 Tactic: 3611739942397549984\n",
      "[04/10/2022-15:18:03] [V] [TRT] Tactic: 3611739942397549984 Time: 1.43993\n",
      "[04/10/2022-15:18:03] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v1 Tactic: 3827454225649558724\n",
      "[04/10/2022-15:18:03] [V] [TRT] Tactic: 3827454225649558724 Time: 1.33223\n",
      "[04/10/2022-15:18:03] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379\n",
      "[04/10/2022-15:18:03] [V] [TRT] Tactic: 4337000649858996379 Time: 1.42419\n",
      "[04/10/2022-15:18:03] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441\n",
      "[04/10/2022-15:18:03] [V] [TRT] Tactic: 4501471010995462441 Time: 1.42243\n",
      "[04/10/2022-15:18:03] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826\n",
      "[04/10/2022-15:18:03] [V] [TRT] Tactic: 5137655947464784826 Time: 1.34865\n",
      "[04/10/2022-15:18:03] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929\n",
      "[04/10/2022-15:18:03] [V] [TRT] Tactic: 5288347012147084929 Time: 1.39798\n",
      "[04/10/2022-15:18:03] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 5921334924264294896\n",
      "[04/10/2022-15:18:03] [V] [TRT] Tactic: 5921334924264294896 Time: 1.00178\n",
      "[04/10/2022-15:18:03] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056\n",
      "[04/10/2022-15:18:03] [V] [TRT] Tactic: 6645123197870846056 Time: 1.41251\n",
      "[04/10/2022-15:18:03] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478\n",
      "[04/10/2022-15:18:03] [V] [TRT] Tactic: 7144526460361122478 Time: 1.76734\n",
      "[04/10/2022-15:18:03] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: 7852627285308570038\n",
      "[04/10/2022-15:18:03] [V] [TRT] Tactic: 7852627285308570038 Time: 1.3404\n",
      "[04/10/2022-15:18:03] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713\n",
      "[04/10/2022-15:18:03] [V] [TRT] Tactic: -9137461792520977713 Time: 1.43242\n",
      "[04/10/2022-15:18:03] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v0 Tactic: -8776506421218919509\n",
      "[04/10/2022-15:18:03] [V] [TRT] Tactic: -8776506421218919509 Time: 1.30542\n",
      "[04/10/2022-15:18:03] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730\n",
      "[04/10/2022-15:18:03] [V] [TRT] Tactic: -8262349710178828730 Time: 1.44966\n",
      "[04/10/2022-15:18:03] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v0 Tactic: -8133971918129952780\n",
      "[04/10/2022-15:18:03] [V] [TRT] Tactic: -8133971918129952780 Time: 1.59484\n",
      "[04/10/2022-15:18:03] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144\n",
      "[04/10/2022-15:18:03] [V] [TRT] Tactic: -6092040395344634144 Time: 1.81571\n",
      "[04/10/2022-15:18:03] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159\n",
      "[04/10/2022-15:18:03] [V] [TRT] Tactic: -4787320710726427159 Time: 1.9993\n",
      "[04/10/2022-15:18:03] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839\n",
      "[04/10/2022-15:18:03] [V] [TRT] Tactic: -3456450830548107839 Time: 1.53648\n",
      "[04/10/2022-15:18:03] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v0 Tactic: -2318106587342035239\n",
      "[04/10/2022-15:18:03] [V] [TRT] Tactic: -2318106587342035239 Time: 1.34148\n",
      "[04/10/2022-15:18:03] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_mobile_relu_tile148t_nt_v0 Tactic: -1343271414618805657\n",
      "[04/10/2022-15:18:04] [V] [TRT] Tactic: -1343271414618805657 Time: 0.908509\n",
      "[04/10/2022-15:18:04] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241\n",
      "[04/10/2022-15:18:04] [V] [TRT] Tactic: -1218658103698133241 Time: 1.56487\n",
      "[04/10/2022-15:18:04] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091\n",
      "[04/10/2022-15:18:04] [V] [TRT] Tactic: -836875257600482091 Time: 1.49512\n",
      "[04/10/2022-15:18:04] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746\n",
      "[04/10/2022-15:18:04] [V] [TRT] Tactic: -410470605513481746 Time: 1.35339\n",
      "[04/10/2022-15:18:04] [V] [TRT] Fastest Tactic: -1343271414618805657 Time: 0.908509\n",
      "[04/10/2022-15:18:04] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -1343271414618805657\n",
      "[04/10/2022-15:18:04] [V] [TRT] *************** Autotuning format combination: Float(100352,1,3584,128) -> Float(100352,1,3584,128) ***************\n",
      "[04/10/2022-15:18:04] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage2_unit1_conv2/Conv2D (CudnnConvolution)\n",
      "[04/10/2022-15:18:04] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:18:04] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage2_unit1_conv2/Conv2D (CaskConvolution)\n",
      "[04/10/2022-15:18:04] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824\n",
      "[04/10/2022-15:18:04] [V] [TRT] Tactic: -9153228964338181824 Time: 1.69107\n",
      "[04/10/2022-15:18:04] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025\n",
      "[04/10/2022-15:18:04] [V] [TRT] Tactic: -7394439838318485025 Time: 1.31595\n",
      "[04/10/2022-15:18:04] [V] [TRT] Fastest Tactic: -7394439838318485025 Time: 1.31595\n",
      "[04/10/2022-15:18:04] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7394439838318485025\n",
      "[04/10/2022-15:18:04] [V] [TRT] *************** Autotuning format combination: Half(100352,784,28,1) -> Half(100352,784,28,1) ***************\n",
      "[04/10/2022-15:18:04] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage2_unit1_conv2/Conv2D (CudnnConvolution)\n",
      "[04/10/2022-15:18:04] [V] [TRT] Tactic: 0 Time: 2.89374\n",
      "[04/10/2022-15:18:04] [V] [TRT] Tactic: 1 Time: 2.58729\n",
      "[04/10/2022-15:18:04] [V] [TRT] Tactic: 2 Time: 2.16137\n",
      "[04/10/2022-15:18:04] [V] [TRT] Tactic: 4 Time: 22.4339\n",
      "[04/10/2022-15:18:05] [V] [TRT] Tactic: 5 Time: 21.6193\n",
      "[04/10/2022-15:18:05] [V] [TRT] Tactic: 6 Time: 2.13908\n",
      "[04/10/2022-15:18:05] [V] [TRT] Fastest Tactic: 6 Time: 2.13908\n",
      "[04/10/2022-15:18:05] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage2_unit1_conv2/Conv2D (CaskConvolution)\n",
      "[04/10/2022-15:18:05] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:18:05] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 6\n",
      "[04/10/2022-15:18:05] [V] [TRT] *************** Autotuning format combination: Half(50176,784:2,28,1) -> Half(50176,784:2,28,1) ***************\n",
      "[04/10/2022-15:18:05] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage2_unit1_conv2/Conv2D (FusedConvActConvolution)\n",
      "[04/10/2022-15:18:05] [V] [TRT] Tactic: 524287 Time: 0.73209\n",
      "[04/10/2022-15:18:05] [V] [TRT] Tactic: 720895 Time: 0.85084\n",
      "[04/10/2022-15:18:05] [V] [TRT] Tactic: 983039 Time: 0.73737\n",
      "[04/10/2022-15:18:05] [V] [TRT] Tactic: 1048575 Time: 0.913144\n",
      "[04/10/2022-15:18:05] [V] [TRT] Tactic: 1703935 Time: 0.936738\n",
      "[04/10/2022-15:18:05] [V] [TRT] Tactic: 1769471 Time: 5.40158\n",
      "[04/10/2022-15:18:05] [V] [TRT] Tactic: 1966079 Time: 0.835677\n",
      "[04/10/2022-15:18:05] [V] [TRT] Tactic: 2031615 Time: 0.789473\n",
      "[04/10/2022-15:18:06] [V] [TRT] Tactic: 2228223 Time: 0.955332\n",
      "[04/10/2022-15:18:06] [V] [TRT] Tactic: 2424831 Time: 1.48764\n",
      "[04/10/2022-15:18:06] [V] [TRT] Tactic: 2621439 Time: 1.0912\n",
      "[04/10/2022-15:18:06] [V] [TRT] Tactic: 2752511 Time: 0.805833\n",
      "[04/10/2022-15:18:06] [V] [TRT] Tactic: 2818047 Time: 1.07436\n",
      "[04/10/2022-15:18:06] [V] [TRT] Tactic: 2883583 Time: 0.88694\n",
      "[04/10/2022-15:18:06] [V] [TRT] Tactic: 3014655 Time: 0.871875\n",
      "[04/10/2022-15:18:06] [V] [TRT] Tactic: 3145727 Time: 0.835039\n",
      "[04/10/2022-15:18:06] [V] [TRT] Tactic: 3473407 Time: 0.871803\n",
      "[04/10/2022-15:18:06] [V] [TRT] Tactic: 3604479 Time: 0.858802\n",
      "[04/10/2022-15:18:06] [V] [TRT] Tactic: 3735551 Time: 0.819271\n",
      "[04/10/2022-15:18:06] [V] [TRT] Tactic: 4390911 Time: 0.792213\n",
      "[04/10/2022-15:18:06] [V] [TRT] Tactic: 5046271 Time: 0.7497\n",
      "[04/10/2022-15:18:06] [V] [TRT] Tactic: 5963775 Time: 0.687031\n",
      "[04/10/2022-15:18:06] [V] [TRT] Tactic: 6160383 Time: 0.772624\n",
      "[04/10/2022-15:18:06] [V] [TRT] Tactic: 6488063 Time: 0.779922\n",
      "[04/10/2022-15:18:07] [V] [TRT] Tactic: 6881279 Time: 0.743945\n",
      "[04/10/2022-15:18:07] [V] [TRT] Tactic: 7274495 Time: 1.14182\n",
      "[04/10/2022-15:18:07] [V] [TRT] Tactic: 7864319 Time: 0.9747\n",
      "[04/10/2022-15:18:07] [V] [TRT] Tactic: 7995391 Time: 0.853424\n",
      "[04/10/2022-15:18:07] [V] [TRT] Tactic: 8585215 Time: 0.789714\n",
      "[04/10/2022-15:18:07] [V] [TRT] Tactic: 8847359 Time: 0.865033\n",
      "[04/10/2022-15:18:07] [V] [TRT] Tactic: 8978431 Time: 0.735202\n",
      "[04/10/2022-15:18:07] [V] [TRT] Tactic: 9043967 Time: 0.772819\n",
      "[04/10/2022-15:18:07] [V] [TRT] Tactic: 9175039 Time: 0.859284\n",
      "[04/10/2022-15:18:07] [V] [TRT] Tactic: 9502719 Time: 0.789375\n",
      "[04/10/2022-15:18:07] [V] [TRT] Tactic: 9830399 Time: 0.75099\n",
      "[04/10/2022-15:18:07] [V] [TRT] Tactic: 9961471 Time: 0.958607\n",
      "[04/10/2022-15:18:07] [V] [TRT] Tactic: 10027007 Time: 0.775814\n",
      "[04/10/2022-15:18:07] [V] [TRT] Tactic: 10092543 Time: 0.793294\n",
      "[04/10/2022-15:18:07] [V] [TRT] Tactic: 10289151 Time: 0.836471\n",
      "[04/10/2022-15:18:07] [V] [TRT] Tactic: 10485759 Time: 0.783359\n",
      "[04/10/2022-15:18:07] [V] [TRT] Tactic: 10682367 Time: 1.06268\n",
      "[04/10/2022-15:18:08] [V] [TRT] Tactic: 10813439 Time: 0.913437\n",
      "[04/10/2022-15:18:08] [V] [TRT] Fastest Tactic: 5963775 Time: 0.687031\n",
      "[04/10/2022-15:18:08] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage2_unit1_conv2/Conv2D (CudnnConvolution)\n",
      "[04/10/2022-15:18:08] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:18:08] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage2_unit1_conv2/Conv2D (CaskConvolution)\n",
      "[04/10/2022-15:18:08] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_conv2/Conv2D Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998\n",
      "[04/10/2022-15:18:08] [V] [TRT] Tactic: 3564772625446233998 Time: 0.902813\n",
      "[04/10/2022-15:18:08] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_conv2/Conv2D Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_large_nn_v1 Tactic: 3650389455493082349\n",
      "[04/10/2022-15:18:08] [V] [TRT] Tactic: 3650389455493082349 Time: 0.925358\n",
      "[04/10/2022-15:18:08] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_conv2/Conv2D Set Tactic Name: maxwell_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 4772821744921268633\n",
      "[04/10/2022-15:18:08] [V] [TRT] Tactic: 4772821744921268633 Time: 0.534056\n",
      "[04/10/2022-15:18:08] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_conv2/Conv2D Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452\n",
      "[04/10/2022-15:18:08] [V] [TRT] Tactic: 5319956359050645452 Time: 0.788815\n",
      "[04/10/2022-15:18:08] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_conv2/Conv2D Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848\n",
      "[04/10/2022-15:18:08] [V] [TRT] Tactic: 7205456024582378848 Time: 0.711888\n",
      "[04/10/2022-15:18:08] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_conv2/Conv2D Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_large_nn_v1 Tactic: -6490690591794140522\n",
      "[04/10/2022-15:18:08] [V] [TRT] Tactic: -6490690591794140522 Time: 0.722448\n",
      "[04/10/2022-15:18:08] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_conv2/Conv2D Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_large_nn_v1 Tactic: -4686027666808657977\n",
      "[04/10/2022-15:18:08] [V] [TRT] Tactic: -4686027666808657977 Time: 0.726628\n",
      "[04/10/2022-15:18:08] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_conv2/Conv2D Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890\n",
      "[04/10/2022-15:18:08] [V] [TRT] Tactic: -4212163711445252890 Time: 0.686419\n",
      "[04/10/2022-15:18:08] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_conv2/Conv2D Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110\n",
      "[04/10/2022-15:18:08] [V] [TRT] Tactic: -3898373634979201110 Time: 0.713952\n",
      "[04/10/2022-15:18:08] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_conv2/Conv2D Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473\n",
      "[04/10/2022-15:18:08] [V] [TRT] Tactic: -2409163523992614473 Time: 0.687604\n",
      "[04/10/2022-15:18:08] [V] [TRT] Fastest Tactic: 4772821744921268633 Time: 0.534056\n",
      "[04/10/2022-15:18:08] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 4772821744921268633\n",
      "[04/10/2022-15:18:08] [V] [TRT] *************** Autotuning Reformat:Float(200704,3136,56,1) -> Float(200704,1,3584,64) ***************\n",
      "[04/10/2022-15:18:08] [V] [TRT] *************** Autotuning Reformat:Float(200704,3136,56,1) -> Half(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:18:08] [V] [TRT] *************** Autotuning Reformat:Float(200704,3136,56,1) -> Half(100352,3136:2,56,1) ***************\n",
      "[04/10/2022-15:18:08] [V] [TRT] *************** Autotuning Reformat:Float(200704,1,3584,64) -> Float(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:18:08] [V] [TRT] *************** Autotuning Reformat:Float(200704,1,3584,64) -> Half(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:18:08] [V] [TRT] *************** Autotuning Reformat:Float(200704,1,3584,64) -> Half(100352,3136:2,56,1) ***************\n",
      "[04/10/2022-15:18:08] [V] [TRT] *************** Autotuning Reformat:Half(200704,3136,56,1) -> Float(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:18:08] [V] [TRT] *************** Autotuning Reformat:Half(200704,3136,56,1) -> Float(200704,1,3584,64) ***************\n",
      "[04/10/2022-15:18:08] [V] [TRT] *************** Autotuning Reformat:Half(200704,3136,56,1) -> Half(100352,3136:2,56,1) ***************\n",
      "[04/10/2022-15:18:08] [V] [TRT] *************** Autotuning Reformat:Half(100352,3136:2,56,1) -> Float(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:18:08] [V] [TRT] *************** Autotuning Reformat:Half(100352,3136:2,56,1) -> Float(200704,1,3584,64) ***************\n",
      "[04/10/2022-15:18:08] [V] [TRT] *************** Autotuning Reformat:Half(100352,3136:2,56,1) -> Half(200704,3136,56,1) ***************\n",
      "[04/10/2022-15:18:08] [V] [TRT] *************** Autotuning Reformat:Float(100352,784,28,1) -> Float(100352,1,3584,128) ***************\n",
      "[04/10/2022-15:18:08] [V] [TRT] *************** Autotuning Reformat:Float(100352,784,28,1) -> Half(100352,784,28,1) ***************\n",
      "[04/10/2022-15:18:08] [V] [TRT] *************** Autotuning Reformat:Float(100352,784,28,1) -> Half(50176,784:2,28,1) ***************\n",
      "[04/10/2022-15:18:08] [V] [TRT] *************** Autotuning Reformat:Float(100352,1,3584,128) -> Float(100352,784,28,1) ***************\n",
      "[04/10/2022-15:18:08] [V] [TRT] *************** Autotuning Reformat:Float(100352,1,3584,128) -> Half(100352,784,28,1) ***************\n",
      "[04/10/2022-15:18:08] [V] [TRT] *************** Autotuning Reformat:Float(100352,1,3584,128) -> Half(50176,784:2,28,1) ***************\n",
      "[04/10/2022-15:18:08] [V] [TRT] *************** Autotuning Reformat:Half(100352,784,28,1) -> Float(100352,784,28,1) ***************\n",
      "[04/10/2022-15:18:08] [V] [TRT] *************** Autotuning Reformat:Half(100352,784,28,1) -> Float(100352,1,3584,128) ***************\n",
      "[04/10/2022-15:18:08] [V] [TRT] *************** Autotuning Reformat:Half(100352,784,28,1) -> Half(50176,784:2,28,1) ***************\n",
      "[04/10/2022-15:18:08] [V] [TRT] *************** Autotuning Reformat:Half(50176,784:2,28,1) -> Float(100352,784,28,1) ***************\n",
      "[04/10/2022-15:18:08] [V] [TRT] *************** Autotuning Reformat:Half(50176,784:2,28,1) -> Float(100352,1,3584,128) ***************\n",
      "[04/10/2022-15:18:08] [V] [TRT] *************** Autotuning Reformat:Half(50176,784:2,28,1) -> Half(100352,784,28,1) ***************\n",
      "[04/10/2022-15:18:08] [V] [TRT] *************** Autotuning format combination: Float(200704,3136,56,1), Float(100352,784,28,1) -> Float(100352,784,28,1) ***************\n",
      "[04/10/2022-15:18:08] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage2_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_2/add (CudaDepthwiseConvolution)\n",
      "[04/10/2022-15:18:08] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:18:08] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage2_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_2/add (FusedConvActConvolution)\n",
      "[04/10/2022-15:18:08] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:18:08] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage2_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_2/add (CudnnConvolution)\n",
      "[04/10/2022-15:18:08] [V] [TRT] Tactic: 0 Time: 0.29071\n",
      "[04/10/2022-15:18:08] [V] [TRT] Tactic: 1 Time: 0.283672\n",
      "[04/10/2022-15:18:08] [V] [TRT] Tactic: 2 Time: 0.314616\n",
      "[04/10/2022-15:18:08] [V] [TRT] Fastest Tactic: 1 Time: 0.283672\n",
      "[04/10/2022-15:18:08] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage2_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_2/add (CaskConvolution)\n",
      "[04/10/2022-15:18:08] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_2/add Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758\n",
      "[04/10/2022-15:18:08] [V] [TRT] Tactic: 1062367460111450758 Time: 0.200827\n",
      "[04/10/2022-15:18:08] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_2/add Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347\n",
      "[04/10/2022-15:18:08] [V] [TRT] Tactic: 1698681053543049347 Time: 0.185065\n",
      "[04/10/2022-15:18:08] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_2/add Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441\n",
      "[04/10/2022-15:18:08] [V] [TRT] Tactic: 4501471010995462441 Time: 0.142474\n",
      "[04/10/2022-15:18:08] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_2/add Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826\n",
      "[04/10/2022-15:18:08] [V] [TRT] Tactic: 5137655947464784826 Time: 0.144674\n",
      "[04/10/2022-15:18:08] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_2/add Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929\n",
      "[04/10/2022-15:18:08] [V] [TRT] Tactic: 5288347012147084929 Time: 0.145631\n",
      "[04/10/2022-15:18:08] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_2/add Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011\n",
      "[04/10/2022-15:18:08] [V] [TRT] Tactic: 5326823351883942011 Time: 0.140723\n",
      "[04/10/2022-15:18:08] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_2/add Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314\n",
      "[04/10/2022-15:18:08] [V] [TRT] Tactic: 5500448035057547314 Time: 0.159088\n",
      "[04/10/2022-15:18:08] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_2/add Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056\n",
      "[04/10/2022-15:18:08] [V] [TRT] Tactic: 6645123197870846056 Time: 0.147135\n",
      "[04/10/2022-15:18:08] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_2/add Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478\n",
      "[04/10/2022-15:18:08] [V] [TRT] Tactic: 7144526460361122478 Time: 0.205618\n",
      "[04/10/2022-15:18:08] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_2/add Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730\n",
      "[04/10/2022-15:18:08] [V] [TRT] Tactic: -8262349710178828730 Time: 0.149329\n",
      "[04/10/2022-15:18:08] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_2/add Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580\n",
      "[04/10/2022-15:18:08] [V] [TRT] Tactic: -6576203419454146580 Time: 0.192962\n",
      "[04/10/2022-15:18:08] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_2/add Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159\n",
      "[04/10/2022-15:18:08] [V] [TRT] Tactic: -4787320710726427159 Time: 0.209752\n",
      "[04/10/2022-15:18:08] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_2/add Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839\n",
      "[04/10/2022-15:18:08] [V] [TRT] Tactic: -3456450830548107839 Time: 0.198399\n",
      "[04/10/2022-15:18:08] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_2/add Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241\n",
      "[04/10/2022-15:18:08] [V] [TRT] Tactic: -1218658103698133241 Time: 0.162767\n",
      "[04/10/2022-15:18:08] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_2/add Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091\n",
      "[04/10/2022-15:18:08] [V] [TRT] Tactic: -836875257600482091 Time: 0.162969\n",
      "[04/10/2022-15:18:08] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_2/add Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746\n",
      "[04/10/2022-15:18:08] [V] [TRT] Tactic: -410470605513481746 Time: 0.141491\n",
      "[04/10/2022-15:18:08] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_2/add Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884\n",
      "[04/10/2022-15:18:08] [V] [TRT] Tactic: -377491875521947884 Time: 0.146621\n",
      "[04/10/2022-15:18:08] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_2/add Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163\n",
      "[04/10/2022-15:18:08] [V] [TRT] Tactic: -37215280111360163 Time: 0.143542\n",
      "[04/10/2022-15:18:08] [V] [TRT] Fastest Tactic: 5326823351883942011 Time: 0.140723\n",
      "[04/10/2022-15:18:08] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 5326823351883942011\n",
      "[04/10/2022-15:18:08] [V] [TRT] *************** Autotuning format combination: Float(200704,1,3584,64), Float(100352,1,3584,128) -> Float(100352,1,3584,128) ***************\n",
      "[04/10/2022-15:18:08] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage2_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_2/add (CudnnConvolution)\n",
      "[04/10/2022-15:18:08] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:18:08] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage2_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_2/add (CaskConvolution)\n",
      "[04/10/2022-15:18:08] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_2/add Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788\n",
      "[04/10/2022-15:18:08] [V] [TRT] Tactic: 3886731678879822788 Time: 0.168548\n",
      "[04/10/2022-15:18:08] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_2/add Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200\n",
      "[04/10/2022-15:18:08] [V] [TRT] Tactic: 6629944304117643200 Time: 0.403913\n",
      "[04/10/2022-15:18:08] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_2/add Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824\n",
      "[04/10/2022-15:18:08] [V] [TRT] Tactic: -9153228964338181824 Time: 0.406491\n",
      "[04/10/2022-15:18:08] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_2/add Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025\n",
      "[04/10/2022-15:18:08] [V] [TRT] Tactic: -7394439838318485025 Time: 0.170163\n",
      "[04/10/2022-15:18:08] [V] [TRT] Fastest Tactic: 3886731678879822788 Time: 0.168548\n",
      "[04/10/2022-15:18:08] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 3886731678879822788\n",
      "[04/10/2022-15:18:08] [V] [TRT] *************** Autotuning format combination: Half(200704,3136,56,1), Half(100352,784,28,1) -> Half(100352,784,28,1) ***************\n",
      "[04/10/2022-15:18:08] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage2_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_2/add (CudnnConvolution)\n",
      "[04/10/2022-15:18:08] [V] [TRT] Tactic: 0 Time: 0.256458\n",
      "[04/10/2022-15:18:08] [V] [TRT] Tactic: 1 Time: 0.252663\n",
      "[04/10/2022-15:18:08] [V] [TRT] Tactic: 2 Time: 0.266335\n",
      "[04/10/2022-15:18:08] [V] [TRT] Fastest Tactic: 1 Time: 0.252663\n",
      "[04/10/2022-15:18:08] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage2_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_2/add (CaskConvolution)\n",
      "[04/10/2022-15:18:08] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:18:08] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 1\n",
      "[04/10/2022-15:18:08] [V] [TRT] *************** Autotuning format combination: Half(100352,3136:2,56,1), Half(50176,784:2,28,1) -> Half(50176,784:2,28,1) ***************\n",
      "[04/10/2022-15:18:08] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage2_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_2/add (FusedConvActConvolution)\n",
      "[04/10/2022-15:18:08] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:18:08] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage2_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_2/add (CudnnConvolution)\n",
      "[04/10/2022-15:18:08] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:18:08] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage2_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_2/add (CaskConvolution)\n",
      "[04/10/2022-15:18:08] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_2/add Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_interior_nn_v1 Tactic: 3066127711859985668\n",
      "[04/10/2022-15:18:08] [V] [TRT] Tactic: 3066127711859985668 Time: 0.109485\n",
      "[04/10/2022-15:18:08] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_2/add Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998\n",
      "[04/10/2022-15:18:08] [V] [TRT] Tactic: 3564772625446233998 Time: 0.113639\n",
      "[04/10/2022-15:18:08] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_2/add Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452\n",
      "[04/10/2022-15:18:08] [V] [TRT] Tactic: 5319956359050645452 Time: 0.11151\n",
      "[04/10/2022-15:18:08] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_2/add Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848\n",
      "[04/10/2022-15:18:08] [V] [TRT] Tactic: 7205456024582378848 Time: 0.0851109\n",
      "[04/10/2022-15:18:08] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_2/add Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 8163473458334948789\n",
      "[04/10/2022-15:18:08] [V] [TRT] Tactic: 8163473458334948789 Time: 0.0825131\n",
      "[04/10/2022-15:18:08] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_2/add Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890\n",
      "[04/10/2022-15:18:08] [V] [TRT] Tactic: -4212163711445252890 Time: 0.0808919\n",
      "[04/10/2022-15:18:08] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_2/add Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110\n",
      "[04/10/2022-15:18:08] [V] [TRT] Tactic: -3898373634979201110 Time: 0.082552\n",
      "[04/10/2022-15:18:08] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_2/add Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473\n",
      "[04/10/2022-15:18:08] [V] [TRT] Tactic: -2409163523992614473 Time: 0.0843684\n",
      "[04/10/2022-15:18:08] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_2/add Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322\n",
      "[04/10/2022-15:18:08] [V] [TRT] Tactic: -1716393687483585322 Time: 0.0790041\n",
      "[04/10/2022-15:18:08] [V] [TRT] Fastest Tactic: -1716393687483585322 Time: 0.0790041\n",
      "[04/10/2022-15:18:08] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -1716393687483585322\n",
      "[04/10/2022-15:18:08] [V] [TRT] *************** Autotuning Reformat:Float(100352,784,28,1) -> Float(100352,1,3584,128) ***************\n",
      "[04/10/2022-15:18:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:18:08] [V] [TRT] Tactic: 1002 Time: 0.115436\n",
      "[04/10/2022-15:18:08] [V] [TRT] Tactic: 0 Time: 0.169414\n",
      "[04/10/2022-15:18:08] [V] [TRT] Fastest Tactic: 1002 Time: 0.115436\n",
      "[04/10/2022-15:18:08] [V] [TRT] *************** Autotuning Reformat:Float(100352,784,28,1) -> Half(100352,784,28,1) ***************\n",
      "[04/10/2022-15:18:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:18:08] [V] [TRT] Tactic: 1002 Time: 0.167988\n",
      "[04/10/2022-15:18:08] [V] [TRT] Tactic: 0 Time: 0.110521\n",
      "[04/10/2022-15:18:08] [V] [TRT] Fastest Tactic: 0 Time: 0.110521\n",
      "[04/10/2022-15:18:08] [V] [TRT] *************** Autotuning Reformat:Float(100352,784,28,1) -> Half(50176,784:2,28,1) ***************\n",
      "[04/10/2022-15:18:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:18:08] [V] [TRT] Tactic: 1002 Time: 0.153978\n",
      "[04/10/2022-15:18:08] [V] [TRT] Tactic: 0 Time: 0.0883009\n",
      "[04/10/2022-15:18:08] [V] [TRT] Fastest Tactic: 0 Time: 0.0883009\n",
      "[04/10/2022-15:18:08] [V] [TRT] *************** Autotuning Reformat:Float(100352,1,3584,128) -> Float(100352,784,28,1) ***************\n",
      "[04/10/2022-15:18:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:18:08] [V] [TRT] Tactic: 1002 Time: 0.13806\n",
      "[04/10/2022-15:18:08] [V] [TRT] Tactic: 0 Time: 0.164095\n",
      "[04/10/2022-15:18:08] [V] [TRT] Fastest Tactic: 1002 Time: 0.13806\n",
      "[04/10/2022-15:18:08] [V] [TRT] *************** Autotuning Reformat:Float(100352,1,3584,128) -> Half(100352,784,28,1) ***************\n",
      "[04/10/2022-15:18:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:18:08] [V] [TRT] Tactic: 1002 Time: 0.103347\n",
      "[04/10/2022-15:18:08] [V] [TRT] Tactic: 0 Time: 0.161758\n",
      "[04/10/2022-15:18:08] [V] [TRT] Fastest Tactic: 1002 Time: 0.103347\n",
      "[04/10/2022-15:18:08] [V] [TRT] *************** Autotuning Reformat:Float(100352,1,3584,128) -> Half(50176,784:2,28,1) ***************\n",
      "[04/10/2022-15:18:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:18:08] [V] [TRT] Tactic: 1002 Time: 0.135325\n",
      "[04/10/2022-15:18:08] [V] [TRT] Tactic: 0 Time: 0.183203\n",
      "[04/10/2022-15:18:08] [V] [TRT] Fastest Tactic: 1002 Time: 0.135325\n",
      "[04/10/2022-15:18:08] [V] [TRT] *************** Autotuning Reformat:Half(100352,784,28,1) -> Float(100352,784,28,1) ***************\n",
      "[04/10/2022-15:18:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:18:08] [V] [TRT] Tactic: 1002 Time: 0.170195\n",
      "[04/10/2022-15:18:08] [V] [TRT] Tactic: 0 Time: 0.0930075\n",
      "[04/10/2022-15:18:08] [V] [TRT] Fastest Tactic: 0 Time: 0.0930075\n",
      "[04/10/2022-15:18:08] [V] [TRT] *************** Autotuning Reformat:Half(100352,784,28,1) -> Float(100352,1,3584,128) ***************\n",
      "[04/10/2022-15:18:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:18:08] [V] [TRT] Tactic: 1002 Time: 0.0969856\n",
      "[04/10/2022-15:18:08] [V] [TRT] Tactic: 0 Time: 0.157493\n",
      "[04/10/2022-15:18:08] [V] [TRT] Fastest Tactic: 1002 Time: 0.0969856\n",
      "[04/10/2022-15:18:08] [V] [TRT] *************** Autotuning Reformat:Half(100352,784,28,1) -> Half(50176,784:2,28,1) ***************\n",
      "[04/10/2022-15:18:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:18:08] [V] [TRT] Tactic: 1002 Time: 0.104434\n",
      "[04/10/2022-15:18:08] [V] [TRT] Tactic: 0 Time: 0.0872855\n",
      "[04/10/2022-15:18:08] [V] [TRT] Fastest Tactic: 0 Time: 0.0872855\n",
      "[04/10/2022-15:18:08] [V] [TRT] *************** Autotuning Reformat:Half(50176,784:2,28,1) -> Float(100352,784,28,1) ***************\n",
      "[04/10/2022-15:18:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:18:08] [V] [TRT] Tactic: 1002 Time: 0.128789\n",
      "[04/10/2022-15:18:08] [V] [TRT] Tactic: 0 Time: 0.0767185\n",
      "[04/10/2022-15:18:08] [V] [TRT] Fastest Tactic: 0 Time: 0.0767185\n",
      "[04/10/2022-15:18:08] [V] [TRT] *************** Autotuning Reformat:Half(50176,784:2,28,1) -> Float(100352,1,3584,128) ***************\n",
      "[04/10/2022-15:18:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:18:08] [V] [TRT] Tactic: 1002 Time: 0.0979299\n",
      "[04/10/2022-15:18:08] [V] [TRT] Tactic: 0 Time: 0.182064\n",
      "[04/10/2022-15:18:08] [V] [TRT] Fastest Tactic: 1002 Time: 0.0979299\n",
      "[04/10/2022-15:18:08] [V] [TRT] *************** Autotuning Reformat:Half(50176,784:2,28,1) -> Half(100352,784,28,1) ***************\n",
      "[04/10/2022-15:18:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:18:08] [V] [TRT] Tactic: 1002 Time: 0.185983\n",
      "[04/10/2022-15:18:08] [V] [TRT] Tactic: 0 Time: 0.0750717\n",
      "[04/10/2022-15:18:08] [V] [TRT] Fastest Tactic: 0 Time: 0.0750717\n",
      "[04/10/2022-15:18:08] [V] [TRT] *************** Autotuning Reformat:Float(100352,784,28,1) -> Float(100352,1,3584,128) ***************\n",
      "[04/10/2022-15:18:08] [V] [TRT] *************** Autotuning Reformat:Float(100352,784,28,1) -> Half(100352,784,28,1) ***************\n",
      "[04/10/2022-15:18:08] [V] [TRT] *************** Autotuning Reformat:Float(100352,784,28,1) -> Half(50176,784:2,28,1) ***************\n",
      "[04/10/2022-15:18:08] [V] [TRT] *************** Autotuning Reformat:Float(100352,1,3584,128) -> Float(100352,784,28,1) ***************\n",
      "[04/10/2022-15:18:08] [V] [TRT] *************** Autotuning Reformat:Float(100352,1,3584,128) -> Half(100352,784,28,1) ***************\n",
      "[04/10/2022-15:18:08] [V] [TRT] *************** Autotuning Reformat:Float(100352,1,3584,128) -> Half(50176,784:2,28,1) ***************\n",
      "[04/10/2022-15:18:08] [V] [TRT] *************** Autotuning Reformat:Half(100352,784,28,1) -> Float(100352,784,28,1) ***************\n",
      "[04/10/2022-15:18:08] [V] [TRT] *************** Autotuning Reformat:Half(100352,784,28,1) -> Float(100352,1,3584,128) ***************\n",
      "[04/10/2022-15:18:08] [V] [TRT] *************** Autotuning Reformat:Half(100352,784,28,1) -> Half(50176,784:2,28,1) ***************\n",
      "[04/10/2022-15:18:08] [V] [TRT] *************** Autotuning Reformat:Half(50176,784:2,28,1) -> Float(100352,784,28,1) ***************\n",
      "[04/10/2022-15:18:08] [V] [TRT] *************** Autotuning Reformat:Half(50176,784:2,28,1) -> Float(100352,1,3584,128) ***************\n",
      "[04/10/2022-15:18:08] [V] [TRT] *************** Autotuning Reformat:Half(50176,784:2,28,1) -> Half(100352,784,28,1) ***************\n",
      "[04/10/2022-15:18:08] [V] [TRT] *************** Autotuning format combination: Float(100352,784,28,1) -> Float(100352,784,28,1) ***************\n",
      "[04/10/2022-15:18:08] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage2_unit2_bn1/FusedBatchNormV3 + StatefulPartitionedCall/model_1/stage2_unit2_relu1/Relu (Scale)\n",
      "[04/10/2022-15:18:08] [V] [TRT] Tactic: 0 Time: 0.0713542\n",
      "[04/10/2022-15:18:08] [V] [TRT] Fastest Tactic: 0 Time: 0.0713542\n",
      "[04/10/2022-15:18:08] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Scale Tactic: 0\n",
      "[04/10/2022-15:18:08] [V] [TRT] *************** Autotuning format combination: Float(100352,1,3584,128) -> Float(100352,1,3584,128) ***************\n",
      "[04/10/2022-15:18:08] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage2_unit2_bn1/FusedBatchNormV3 + StatefulPartitionedCall/model_1/stage2_unit2_relu1/Relu (Scale)\n",
      "[04/10/2022-15:18:08] [V] [TRT] Scale has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:18:08] [V] [TRT] *************** Autotuning format combination: Half(100352,784,28,1) -> Half(100352,784,28,1) ***************\n",
      "[04/10/2022-15:18:08] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage2_unit2_bn1/FusedBatchNormV3 + StatefulPartitionedCall/model_1/stage2_unit2_relu1/Relu (Scale)\n",
      "[04/10/2022-15:18:08] [V] [TRT] Tactic: 0 Time: 0.0678647\n",
      "[04/10/2022-15:18:08] [V] [TRT] Fastest Tactic: 0 Time: 0.0678647\n",
      "[04/10/2022-15:18:08] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Scale Tactic: 0\n",
      "[04/10/2022-15:18:08] [V] [TRT] *************** Autotuning format combination: Half(50176,784:2,28,1) -> Half(50176,784:2,28,1) ***************\n",
      "[04/10/2022-15:18:08] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage2_unit2_bn1/FusedBatchNormV3 + StatefulPartitionedCall/model_1/stage2_unit2_relu1/Relu (Scale)\n",
      "[04/10/2022-15:18:08] [V] [TRT] Tactic: 0 Time: 0.0828839\n",
      "[04/10/2022-15:18:08] [V] [TRT] Fastest Tactic: 0 Time: 0.0828839\n",
      "[04/10/2022-15:18:08] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Scale Tactic: 0\n",
      "[04/10/2022-15:18:08] [V] [TRT] *************** Autotuning Reformat:Float(100352,784,28,1) -> Float(100352,1,3584,128) ***************\n",
      "[04/10/2022-15:18:08] [V] [TRT] *************** Autotuning Reformat:Float(100352,784,28,1) -> Half(100352,784,28,1) ***************\n",
      "[04/10/2022-15:18:08] [V] [TRT] *************** Autotuning Reformat:Float(100352,784,28,1) -> Half(50176,784:2,28,1) ***************\n",
      "[04/10/2022-15:18:08] [V] [TRT] *************** Autotuning Reformat:Float(100352,1,3584,128) -> Float(100352,784,28,1) ***************\n",
      "[04/10/2022-15:18:08] [V] [TRT] *************** Autotuning Reformat:Float(100352,1,3584,128) -> Half(100352,784,28,1) ***************\n",
      "[04/10/2022-15:18:08] [V] [TRT] *************** Autotuning Reformat:Float(100352,1,3584,128) -> Half(50176,784:2,28,1) ***************\n",
      "[04/10/2022-15:18:08] [V] [TRT] *************** Autotuning Reformat:Half(100352,784,28,1) -> Float(100352,784,28,1) ***************\n",
      "[04/10/2022-15:18:08] [V] [TRT] *************** Autotuning Reformat:Half(100352,784,28,1) -> Float(100352,1,3584,128) ***************\n",
      "[04/10/2022-15:18:08] [V] [TRT] *************** Autotuning Reformat:Half(100352,784,28,1) -> Half(50176,784:2,28,1) ***************\n",
      "[04/10/2022-15:18:08] [V] [TRT] *************** Autotuning Reformat:Half(50176,784:2,28,1) -> Float(100352,784,28,1) ***************\n",
      "[04/10/2022-15:18:08] [V] [TRT] *************** Autotuning Reformat:Half(50176,784:2,28,1) -> Float(100352,1,3584,128) ***************\n",
      "[04/10/2022-15:18:08] [V] [TRT] *************** Autotuning Reformat:Half(50176,784:2,28,1) -> Half(100352,784,28,1) ***************\n",
      "[04/10/2022-15:18:08] [V] [TRT] *************** Autotuning format combination: Float(100352,784,28,1) -> Float(100352,784,28,1) ***************\n",
      "[04/10/2022-15:18:08] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage2_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit2_relu2/Relu (CudaDepthwiseConvolution)\n",
      "[04/10/2022-15:18:08] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:18:08] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage2_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit2_relu2/Relu (FusedConvActConvolution)\n",
      "[04/10/2022-15:18:08] [V] [TRT] Tactic: 524287 Time: 1.41574\n",
      "[04/10/2022-15:18:09] [V] [TRT] Tactic: 720895 Time: 1.48315\n",
      "[04/10/2022-15:18:09] [V] [TRT] Tactic: 983039 Time: 1.35178\n",
      "[04/10/2022-15:18:09] [V] [TRT] Tactic: 1048575 Time: 1.6473\n",
      "[04/10/2022-15:18:09] [V] [TRT] Tactic: 1703935 Time: 1.64917\n",
      "[04/10/2022-15:18:09] [V] [TRT] Tactic: 1769471 Time: 1.60428\n",
      "[04/10/2022-15:18:09] [V] [TRT] Tactic: 1966079 Time: 1.43558\n",
      "[04/10/2022-15:18:09] [V] [TRT] Tactic: 2031615 Time: 1.50523\n",
      "[04/10/2022-15:18:09] [V] [TRT] Tactic: 2228223 Time: 1.72829\n",
      "[04/10/2022-15:18:09] [V] [TRT] Tactic: 2424831 Time: 2.00181\n",
      "[04/10/2022-15:18:09] [V] [TRT] Tactic: 2621439 Time: 2.0598\n",
      "[04/10/2022-15:18:10] [V] [TRT] Tactic: 2752511 Time: 1.43428\n",
      "[04/10/2022-15:18:10] [V] [TRT] Tactic: 2818047 Time: 1.96911\n",
      "[04/10/2022-15:18:10] [V] [TRT] Tactic: 2883583 Time: 1.47251\n",
      "[04/10/2022-15:18:10] [V] [TRT] Tactic: 3014655 Time: 1.55587\n",
      "[04/10/2022-15:18:10] [V] [TRT] Tactic: 3145727 Time: 1.4346\n",
      "[04/10/2022-15:18:10] [V] [TRT] Tactic: 3473407 Time: 1.43603\n",
      "[04/10/2022-15:18:10] [V] [TRT] Tactic: 3604479 Time: 1.52796\n",
      "[04/10/2022-15:18:10] [V] [TRT] Tactic: 3735551 Time: 1.62868\n",
      "[04/10/2022-15:18:10] [V] [TRT] Tactic: 4390911 Time: 1.43436\n",
      "[04/10/2022-15:18:10] [V] [TRT] Tactic: 5046271 Time: 1.39616\n",
      "[04/10/2022-15:18:10] [V] [TRT] Tactic: 5963775 Time: 1.27945\n",
      "[04/10/2022-15:18:11] [V] [TRT] Tactic: 6160383 Time: 1.38211\n",
      "[04/10/2022-15:18:11] [V] [TRT] Tactic: 6488063 Time: 1.40671\n",
      "[04/10/2022-15:18:11] [V] [TRT] Tactic: 6881279 Time: 1.43314\n",
      "[04/10/2022-15:18:11] [V] [TRT] Tactic: 7274495 Time: 2.07105\n",
      "[04/10/2022-15:18:11] [V] [TRT] Tactic: 7864319 Time: 1.80053\n",
      "[04/10/2022-15:18:11] [V] [TRT] Tactic: 7995391 Time: 1.5212\n",
      "[04/10/2022-15:18:11] [V] [TRT] Tactic: 8585215 Time: 1.44428\n",
      "[04/10/2022-15:18:11] [V] [TRT] Tactic: 8847359 Time: 1.5809\n",
      "[04/10/2022-15:18:11] [V] [TRT] Tactic: 8978431 Time: 1.29868\n",
      "[04/10/2022-15:18:11] [V] [TRT] Tactic: 9043967 Time: 1.41399\n",
      "[04/10/2022-15:18:11] [V] [TRT] Tactic: 9175039 Time: 1.52882\n",
      "[04/10/2022-15:18:12] [V] [TRT] Tactic: 9502719 Time: 1.45735\n",
      "[04/10/2022-15:18:12] [V] [TRT] Tactic: 9830399 Time: 1.3558\n",
      "[04/10/2022-15:18:12] [V] [TRT] Tactic: 9961471 Time: 1.73161\n",
      "[04/10/2022-15:18:12] [V] [TRT] Tactic: 10027007 Time: 1.4221\n",
      "[04/10/2022-15:18:12] [V] [TRT] Tactic: 10092543 Time: 1.43402\n",
      "[04/10/2022-15:18:12] [V] [TRT] Tactic: 10289151 Time: 1.43647\n",
      "[04/10/2022-15:18:12] [V] [TRT] Tactic: 10485759 Time: 1.44697\n",
      "[04/10/2022-15:18:12] [V] [TRT] Tactic: 10682367 Time: 2.04098\n",
      "[04/10/2022-15:18:12] [V] [TRT] Tactic: 10813439 Time: 1.53085\n",
      "[04/10/2022-15:18:12] [V] [TRT] Fastest Tactic: 5963775 Time: 1.27945\n",
      "[04/10/2022-15:18:12] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage2_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit2_relu2/Relu (CudnnConvolution)\n",
      "[04/10/2022-15:18:12] [V] [TRT] Tactic: 0 Time: 2.48779\n",
      "[04/10/2022-15:18:12] [V] [TRT] Tactic: 1 Time: 1.78714\n",
      "[04/10/2022-15:18:12] [V] [TRT] Tactic: 2 Time: 2.36104\n",
      "[04/10/2022-15:18:13] [V] [TRT] Tactic: 4 Time: 23.0402\n",
      "[04/10/2022-15:18:13] [V] [TRT] Tactic: 5 Time: 23.0361\n",
      "[04/10/2022-15:18:13] [V] [TRT] Tactic: 6 Time: 1.22484\n",
      "[04/10/2022-15:18:13] [V] [TRT] Fastest Tactic: 6 Time: 1.22484\n",
      "[04/10/2022-15:18:13] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage2_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit2_relu2/Relu (CaskConvolution)\n",
      "[04/10/2022-15:18:13] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit2_relu2/Relu Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758\n",
      "[04/10/2022-15:18:13] [V] [TRT] Tactic: 1062367460111450758 Time: 1.73083\n",
      "[04/10/2022-15:18:13] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit2_relu2/Relu Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v0 Tactic: 1754984623894446479\n",
      "[04/10/2022-15:18:13] [V] [TRT] Tactic: 1754984623894446479 Time: 2.00427\n",
      "[04/10/2022-15:18:13] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit2_relu2/Relu Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v0 Tactic: 3611739942397549984\n",
      "[04/10/2022-15:18:14] [V] [TRT] Tactic: 3611739942397549984 Time: 1.44292\n",
      "[04/10/2022-15:18:14] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit2_relu2/Relu Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v1 Tactic: 3827454225649558724\n",
      "[04/10/2022-15:18:14] [V] [TRT] Tactic: 3827454225649558724 Time: 1.33201\n",
      "[04/10/2022-15:18:14] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit2_relu2/Relu Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379\n",
      "[04/10/2022-15:18:14] [V] [TRT] Tactic: 4337000649858996379 Time: 1.4247\n",
      "[04/10/2022-15:18:14] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit2_relu2/Relu Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441\n",
      "[04/10/2022-15:18:14] [V] [TRT] Tactic: 4501471010995462441 Time: 1.42182\n",
      "[04/10/2022-15:18:14] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit2_relu2/Relu Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826\n",
      "[04/10/2022-15:18:14] [V] [TRT] Tactic: 5137655947464784826 Time: 1.34827\n",
      "[04/10/2022-15:18:14] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit2_relu2/Relu Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929\n",
      "[04/10/2022-15:18:14] [V] [TRT] Tactic: 5288347012147084929 Time: 1.40423\n",
      "[04/10/2022-15:18:14] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit2_relu2/Relu Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 5921334924264294896\n",
      "[04/10/2022-15:18:14] [V] [TRT] Tactic: 5921334924264294896 Time: 1.00616\n",
      "[04/10/2022-15:18:14] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit2_relu2/Relu Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056\n",
      "[04/10/2022-15:18:14] [V] [TRT] Tactic: 6645123197870846056 Time: 1.4016\n",
      "[04/10/2022-15:18:14] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit2_relu2/Relu Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478\n",
      "[04/10/2022-15:18:14] [V] [TRT] Tactic: 7144526460361122478 Time: 1.77428\n",
      "[04/10/2022-15:18:14] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit2_relu2/Relu Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: 7852627285308570038\n",
      "[04/10/2022-15:18:14] [V] [TRT] Tactic: 7852627285308570038 Time: 1.33567\n",
      "[04/10/2022-15:18:14] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit2_relu2/Relu Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713\n",
      "[04/10/2022-15:18:14] [V] [TRT] Tactic: -9137461792520977713 Time: 1.43126\n",
      "[04/10/2022-15:18:14] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit2_relu2/Relu Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v0 Tactic: -8776506421218919509\n",
      "[04/10/2022-15:18:14] [V] [TRT] Tactic: -8776506421218919509 Time: 1.30581\n",
      "[04/10/2022-15:18:14] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit2_relu2/Relu Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730\n",
      "[04/10/2022-15:18:14] [V] [TRT] Tactic: -8262349710178828730 Time: 1.4533\n",
      "[04/10/2022-15:18:14] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit2_relu2/Relu Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v0 Tactic: -8133971918129952780\n",
      "[04/10/2022-15:18:14] [V] [TRT] Tactic: -8133971918129952780 Time: 1.56889\n",
      "[04/10/2022-15:18:14] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit2_relu2/Relu Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144\n",
      "[04/10/2022-15:18:14] [V] [TRT] Tactic: -6092040395344634144 Time: 1.80673\n",
      "[04/10/2022-15:18:14] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit2_relu2/Relu Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159\n",
      "[04/10/2022-15:18:14] [V] [TRT] Tactic: -4787320710726427159 Time: 2.00361\n",
      "[04/10/2022-15:18:14] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit2_relu2/Relu Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839\n",
      "[04/10/2022-15:18:14] [V] [TRT] Tactic: -3456450830548107839 Time: 1.57304\n",
      "[04/10/2022-15:18:14] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit2_relu2/Relu Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v0 Tactic: -2318106587342035239\n",
      "[04/10/2022-15:18:14] [V] [TRT] Tactic: -2318106587342035239 Time: 1.33766\n",
      "[04/10/2022-15:18:14] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit2_relu2/Relu Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_mobile_relu_tile148t_nt_v0 Tactic: -1343271414618805657\n",
      "[04/10/2022-15:18:14] [V] [TRT] Tactic: -1343271414618805657 Time: 0.917663\n",
      "[04/10/2022-15:18:14] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit2_relu2/Relu Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241\n",
      "[04/10/2022-15:18:14] [V] [TRT] Tactic: -1218658103698133241 Time: 1.56628\n",
      "[04/10/2022-15:18:14] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit2_relu2/Relu Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091\n",
      "[04/10/2022-15:18:14] [V] [TRT] Tactic: -836875257600482091 Time: 1.48992\n",
      "[04/10/2022-15:18:14] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit2_relu2/Relu Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746\n",
      "[04/10/2022-15:18:14] [V] [TRT] Tactic: -410470605513481746 Time: 1.3826\n",
      "[04/10/2022-15:18:14] [V] [TRT] Fastest Tactic: -1343271414618805657 Time: 0.917663\n",
      "[04/10/2022-15:18:14] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -1343271414618805657\n",
      "[04/10/2022-15:18:14] [V] [TRT] *************** Autotuning format combination: Float(100352,1,3584,128) -> Float(100352,1,3584,128) ***************\n",
      "[04/10/2022-15:18:14] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage2_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit2_relu2/Relu (CudnnConvolution)\n",
      "[04/10/2022-15:18:14] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:18:14] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage2_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit2_relu2/Relu (CaskConvolution)\n",
      "[04/10/2022-15:18:14] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit2_relu2/Relu Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824\n",
      "[04/10/2022-15:18:14] [V] [TRT] Tactic: -9153228964338181824 Time: 1.698\n",
      "[04/10/2022-15:18:14] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit2_relu2/Relu Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025\n",
      "[04/10/2022-15:18:14] [V] [TRT] Tactic: -7394439838318485025 Time: 1.31769\n",
      "[04/10/2022-15:18:14] [V] [TRT] Fastest Tactic: -7394439838318485025 Time: 1.31769\n",
      "[04/10/2022-15:18:14] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7394439838318485025\n",
      "[04/10/2022-15:18:14] [V] [TRT] *************** Autotuning format combination: Half(100352,784,28,1) -> Half(100352,784,28,1) ***************\n",
      "[04/10/2022-15:18:14] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage2_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit2_relu2/Relu (CudnnConvolution)\n",
      "[04/10/2022-15:18:14] [V] [TRT] Tactic: 0 Time: 2.94754\n",
      "[04/10/2022-15:18:15] [V] [TRT] Tactic: 1 Time: 2.68226\n",
      "[04/10/2022-15:18:15] [V] [TRT] Tactic: 2 Time: 2.26635\n",
      "[04/10/2022-15:18:15] [V] [TRT] Tactic: 4 Time: 22.4741\n",
      "[04/10/2022-15:18:15] [V] [TRT] Tactic: 5 Time: 21.9166\n",
      "[04/10/2022-15:18:16] [V] [TRT] Tactic: 6 Time: 2.10518\n",
      "[04/10/2022-15:18:16] [V] [TRT] Fastest Tactic: 6 Time: 2.10518\n",
      "[04/10/2022-15:18:16] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage2_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit2_relu2/Relu (CaskConvolution)\n",
      "[04/10/2022-15:18:16] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:18:16] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 6\n",
      "[04/10/2022-15:18:16] [V] [TRT] *************** Autotuning format combination: Half(50176,784:2,28,1) -> Half(50176,784:2,28,1) ***************\n",
      "[04/10/2022-15:18:16] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage2_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit2_relu2/Relu (FusedConvActConvolution)\n",
      "[04/10/2022-15:18:16] [V] [TRT] Tactic: 524287 Time: 0.731719\n",
      "[04/10/2022-15:18:16] [V] [TRT] Tactic: 720895 Time: 0.85112\n",
      "[04/10/2022-15:18:16] [V] [TRT] Tactic: 983039 Time: 0.738171\n",
      "[04/10/2022-15:18:16] [V] [TRT] Tactic: 1048575 Time: 0.912787\n",
      "[04/10/2022-15:18:16] [V] [TRT] Tactic: 1703935 Time: 0.937539\n",
      "[04/10/2022-15:18:16] [V] [TRT] Tactic: 1769471 Time: 5.4405\n",
      "[04/10/2022-15:18:16] [V] [TRT] Tactic: 1966079 Time: 0.834882\n",
      "[04/10/2022-15:18:16] [V] [TRT] Tactic: 2031615 Time: 0.786016\n",
      "[04/10/2022-15:18:16] [V] [TRT] Tactic: 2228223 Time: 0.953177\n",
      "[04/10/2022-15:18:16] [V] [TRT] Tactic: 2424831 Time: 1.49536\n",
      "[04/10/2022-15:18:16] [V] [TRT] Tactic: 2621439 Time: 1.09204\n",
      "[04/10/2022-15:18:17] [V] [TRT] Tactic: 2752511 Time: 0.804408\n",
      "[04/10/2022-15:18:17] [V] [TRT] Tactic: 2818047 Time: 1.07668\n",
      "[04/10/2022-15:18:17] [V] [TRT] Tactic: 2883583 Time: 0.887337\n",
      "[04/10/2022-15:18:17] [V] [TRT] Tactic: 3014655 Time: 0.872481\n",
      "[04/10/2022-15:18:17] [V] [TRT] Tactic: 3145727 Time: 0.835606\n",
      "[04/10/2022-15:18:17] [V] [TRT] Tactic: 3473407 Time: 0.872116\n",
      "[04/10/2022-15:18:17] [V] [TRT] Tactic: 3604479 Time: 0.858587\n",
      "[04/10/2022-15:18:17] [V] [TRT] Tactic: 3735551 Time: 0.815482\n",
      "[04/10/2022-15:18:17] [V] [TRT] Tactic: 4390911 Time: 0.789811\n",
      "[04/10/2022-15:18:17] [V] [TRT] Tactic: 5046271 Time: 0.749551\n",
      "[04/10/2022-15:18:17] [V] [TRT] Tactic: 5963775 Time: 0.688835\n",
      "[04/10/2022-15:18:17] [V] [TRT] Tactic: 6160383 Time: 0.773952\n",
      "[04/10/2022-15:18:17] [V] [TRT] Tactic: 6488063 Time: 0.780918\n",
      "[04/10/2022-15:18:17] [V] [TRT] Tactic: 6881279 Time: 0.745006\n",
      "[04/10/2022-15:18:17] [V] [TRT] Tactic: 7274495 Time: 1.14799\n",
      "[04/10/2022-15:18:17] [V] [TRT] Tactic: 7864319 Time: 0.974994\n",
      "[04/10/2022-15:18:17] [V] [TRT] Tactic: 7995391 Time: 0.857832\n",
      "[04/10/2022-15:18:17] [V] [TRT] Tactic: 8585215 Time: 0.78862\n",
      "[04/10/2022-15:18:18] [V] [TRT] Tactic: 8847359 Time: 0.864759\n",
      "[04/10/2022-15:18:18] [V] [TRT] Tactic: 8978431 Time: 0.736367\n",
      "[04/10/2022-15:18:18] [V] [TRT] Tactic: 9043967 Time: 0.771322\n",
      "[04/10/2022-15:18:18] [V] [TRT] Tactic: 9175039 Time: 0.858424\n",
      "[04/10/2022-15:18:18] [V] [TRT] Tactic: 9502719 Time: 0.78638\n",
      "[04/10/2022-15:18:18] [V] [TRT] Tactic: 9830399 Time: 0.751817\n",
      "[04/10/2022-15:18:18] [V] [TRT] Tactic: 9961471 Time: 0.962064\n",
      "[04/10/2022-15:18:18] [V] [TRT] Tactic: 10027007 Time: 0.776732\n",
      "[04/10/2022-15:18:18] [V] [TRT] Tactic: 10092543 Time: 0.796146\n",
      "[04/10/2022-15:18:18] [V] [TRT] Tactic: 10289151 Time: 0.835065\n",
      "[04/10/2022-15:18:18] [V] [TRT] Tactic: 10485759 Time: 0.784199\n",
      "[04/10/2022-15:18:18] [V] [TRT] Tactic: 10682367 Time: 1.06403\n",
      "[04/10/2022-15:18:18] [V] [TRT] Tactic: 10813439 Time: 0.913626\n",
      "[04/10/2022-15:18:18] [V] [TRT] Fastest Tactic: 5963775 Time: 0.688835\n",
      "[04/10/2022-15:18:18] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage2_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit2_relu2/Relu (CudnnConvolution)\n",
      "[04/10/2022-15:18:18] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:18:18] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage2_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit2_relu2/Relu (CaskConvolution)\n",
      "[04/10/2022-15:18:18] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit2_relu2/Relu Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998\n",
      "[04/10/2022-15:18:18] [V] [TRT] Tactic: 3564772625446233998 Time: 0.904538\n",
      "[04/10/2022-15:18:18] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit2_relu2/Relu Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_large_nn_v1 Tactic: 3650389455493082349\n",
      "[04/10/2022-15:18:18] [V] [TRT] Tactic: 3650389455493082349 Time: 0.924186\n",
      "[04/10/2022-15:18:18] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit2_relu2/Relu Set Tactic Name: maxwell_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 4772821744921268633\n",
      "[04/10/2022-15:18:18] [V] [TRT] Tactic: 4772821744921268633 Time: 0.535013\n",
      "[04/10/2022-15:18:18] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit2_relu2/Relu Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452\n",
      "[04/10/2022-15:18:18] [V] [TRT] Tactic: 5319956359050645452 Time: 0.785221\n",
      "[04/10/2022-15:18:18] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit2_relu2/Relu Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848\n",
      "[04/10/2022-15:18:18] [V] [TRT] Tactic: 7205456024582378848 Time: 0.709303\n",
      "[04/10/2022-15:18:18] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit2_relu2/Relu Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_large_nn_v1 Tactic: -6490690591794140522\n",
      "[04/10/2022-15:18:18] [V] [TRT] Tactic: -6490690591794140522 Time: 0.726966\n",
      "[04/10/2022-15:18:18] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit2_relu2/Relu Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_large_nn_v1 Tactic: -4686027666808657977\n",
      "[04/10/2022-15:18:18] [V] [TRT] Tactic: -4686027666808657977 Time: 0.720326\n",
      "[04/10/2022-15:18:18] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit2_relu2/Relu Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890\n",
      "[04/10/2022-15:18:18] [V] [TRT] Tactic: -4212163711445252890 Time: 0.684818\n",
      "[04/10/2022-15:18:18] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit2_relu2/Relu Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110\n",
      "[04/10/2022-15:18:18] [V] [TRT] Tactic: -3898373634979201110 Time: 0.710442\n",
      "[04/10/2022-15:18:18] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage2_unit2_relu2/Relu Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473\n",
      "[04/10/2022-15:18:18] [V] [TRT] Tactic: -2409163523992614473 Time: 0.690501\n",
      "[04/10/2022-15:18:18] [V] [TRT] Fastest Tactic: 4772821744921268633 Time: 0.535013\n",
      "[04/10/2022-15:18:18] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 4772821744921268633\n",
      "[04/10/2022-15:18:18] [V] [TRT] *************** Autotuning Reformat:Float(100352,784,28,1) -> Float(100352,1,3584,128) ***************\n",
      "[04/10/2022-15:18:18] [V] [TRT] *************** Autotuning Reformat:Float(100352,784,28,1) -> Half(100352,784,28,1) ***************\n",
      "[04/10/2022-15:18:18] [V] [TRT] *************** Autotuning Reformat:Float(100352,784,28,1) -> Half(50176,784:2,28,1) ***************\n",
      "[04/10/2022-15:18:18] [V] [TRT] *************** Autotuning Reformat:Float(100352,1,3584,128) -> Float(100352,784,28,1) ***************\n",
      "[04/10/2022-15:18:18] [V] [TRT] *************** Autotuning Reformat:Float(100352,1,3584,128) -> Half(100352,784,28,1) ***************\n",
      "[04/10/2022-15:18:18] [V] [TRT] *************** Autotuning Reformat:Float(100352,1,3584,128) -> Half(50176,784:2,28,1) ***************\n",
      "[04/10/2022-15:18:18] [V] [TRT] *************** Autotuning Reformat:Half(100352,784,28,1) -> Float(100352,784,28,1) ***************\n",
      "[04/10/2022-15:18:18] [V] [TRT] *************** Autotuning Reformat:Half(100352,784,28,1) -> Float(100352,1,3584,128) ***************\n",
      "[04/10/2022-15:18:18] [V] [TRT] *************** Autotuning Reformat:Half(100352,784,28,1) -> Half(50176,784:2,28,1) ***************\n",
      "[04/10/2022-15:18:18] [V] [TRT] *************** Autotuning Reformat:Half(50176,784:2,28,1) -> Float(100352,784,28,1) ***************\n",
      "[04/10/2022-15:18:18] [V] [TRT] *************** Autotuning Reformat:Half(50176,784:2,28,1) -> Float(100352,1,3584,128) ***************\n",
      "[04/10/2022-15:18:18] [V] [TRT] *************** Autotuning Reformat:Half(50176,784:2,28,1) -> Half(100352,784,28,1) ***************\n",
      "[04/10/2022-15:18:18] [V] [TRT] *************** Autotuning Reformat:Float(100352,784,28,1) -> Float(100352,1,3584,128) ***************\n",
      "[04/10/2022-15:18:18] [V] [TRT] *************** Autotuning Reformat:Float(100352,784,28,1) -> Half(100352,784,28,1) ***************\n",
      "[04/10/2022-15:18:18] [V] [TRT] *************** Autotuning Reformat:Float(100352,784,28,1) -> Half(50176,784:2,28,1) ***************\n",
      "[04/10/2022-15:18:18] [V] [TRT] *************** Autotuning Reformat:Float(100352,1,3584,128) -> Float(100352,784,28,1) ***************\n",
      "[04/10/2022-15:18:18] [V] [TRT] *************** Autotuning Reformat:Float(100352,1,3584,128) -> Half(100352,784,28,1) ***************\n",
      "[04/10/2022-15:18:18] [V] [TRT] *************** Autotuning Reformat:Float(100352,1,3584,128) -> Half(50176,784:2,28,1) ***************\n",
      "[04/10/2022-15:18:18] [V] [TRT] *************** Autotuning Reformat:Half(100352,784,28,1) -> Float(100352,784,28,1) ***************\n",
      "[04/10/2022-15:18:18] [V] [TRT] *************** Autotuning Reformat:Half(100352,784,28,1) -> Float(100352,1,3584,128) ***************\n",
      "[04/10/2022-15:18:18] [V] [TRT] *************** Autotuning Reformat:Half(100352,784,28,1) -> Half(50176,784:2,28,1) ***************\n",
      "[04/10/2022-15:18:18] [V] [TRT] *************** Autotuning Reformat:Half(50176,784:2,28,1) -> Float(100352,784,28,1) ***************\n",
      "[04/10/2022-15:18:18] [V] [TRT] *************** Autotuning Reformat:Half(50176,784:2,28,1) -> Float(100352,1,3584,128) ***************\n",
      "[04/10/2022-15:18:18] [V] [TRT] *************** Autotuning Reformat:Half(50176,784:2,28,1) -> Half(100352,784,28,1) ***************\n",
      "[04/10/2022-15:18:18] [V] [TRT] *************** Autotuning format combination: Float(100352,784,28,1), Float(100352,784,28,1) -> Float(100352,784,28,1) ***************\n",
      "[04/10/2022-15:18:18] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage2_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_3/add (CudaDepthwiseConvolution)\n",
      "[04/10/2022-15:18:18] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:18:18] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage2_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_3/add (FusedConvActConvolution)\n",
      "[04/10/2022-15:18:18] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:18:18] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage2_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_3/add (CudnnConvolution)\n",
      "[04/10/2022-15:18:19] [V] [TRT] Tactic: 0 Time: 2.42618\n",
      "[04/10/2022-15:18:19] [V] [TRT] Tactic: 1 Time: 1.51508\n",
      "[04/10/2022-15:18:19] [V] [TRT] Tactic: 2 Time: 2.32988\n",
      "[04/10/2022-15:18:19] [V] [TRT] Tactic: 4 Time: 23.5193\n",
      "[04/10/2022-15:18:20] [V] [TRT] Tactic: 5 Time: 22.7248\n",
      "[04/10/2022-15:18:20] [V] [TRT] Tactic: 6 Time: 1.19671\n",
      "[04/10/2022-15:18:20] [V] [TRT] Fastest Tactic: 6 Time: 1.19671\n",
      "[04/10/2022-15:18:20] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage2_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_3/add (CaskConvolution)\n",
      "[04/10/2022-15:18:20] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_3/add Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758\n",
      "[04/10/2022-15:18:20] [V] [TRT] Tactic: 1062367460111450758 Time: 1.75167\n",
      "[04/10/2022-15:18:20] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_3/add Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v0 Tactic: 1754984623894446479\n",
      "[04/10/2022-15:18:20] [V] [TRT] Tactic: 1754984623894446479 Time: 2.02259\n",
      "[04/10/2022-15:18:20] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_3/add Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v0 Tactic: 3611739942397549984\n",
      "[04/10/2022-15:18:20] [V] [TRT] Tactic: 3611739942397549984 Time: 1.45163\n",
      "[04/10/2022-15:18:20] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_3/add Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v1 Tactic: 3827454225649558724\n",
      "[04/10/2022-15:18:20] [V] [TRT] Tactic: 3827454225649558724 Time: 1.37585\n",
      "[04/10/2022-15:18:20] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_3/add Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379\n",
      "[04/10/2022-15:18:20] [V] [TRT] Tactic: 4337000649858996379 Time: 1.4228\n",
      "[04/10/2022-15:18:20] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_3/add Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441\n",
      "[04/10/2022-15:18:20] [V] [TRT] Tactic: 4501471010995462441 Time: 1.43931\n",
      "[04/10/2022-15:18:20] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_3/add Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826\n",
      "[04/10/2022-15:18:20] [V] [TRT] Tactic: 5137655947464784826 Time: 1.35221\n",
      "[04/10/2022-15:18:20] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_3/add Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929\n",
      "[04/10/2022-15:18:20] [V] [TRT] Tactic: 5288347012147084929 Time: 1.41886\n",
      "[04/10/2022-15:18:20] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_3/add Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 5921334924264294896\n",
      "[04/10/2022-15:18:20] [V] [TRT] Tactic: 5921334924264294896 Time: 1.03751\n",
      "[04/10/2022-15:18:20] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_3/add Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056\n",
      "[04/10/2022-15:18:20] [V] [TRT] Tactic: 6645123197870846056 Time: 1.40791\n",
      "[04/10/2022-15:18:20] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_3/add Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478\n",
      "[04/10/2022-15:18:20] [V] [TRT] Tactic: 7144526460361122478 Time: 1.77609\n",
      "[04/10/2022-15:18:20] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_3/add Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: 7852627285308570038\n",
      "[04/10/2022-15:18:20] [V] [TRT] Tactic: 7852627285308570038 Time: 1.37652\n",
      "[04/10/2022-15:18:20] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_3/add Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713\n",
      "[04/10/2022-15:18:20] [V] [TRT] Tactic: -9137461792520977713 Time: 1.44374\n",
      "[04/10/2022-15:18:20] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_3/add Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v0 Tactic: -8776506421218919509\n",
      "[04/10/2022-15:18:20] [V] [TRT] Tactic: -8776506421218919509 Time: 1.35076\n",
      "[04/10/2022-15:18:20] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_3/add Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730\n",
      "[04/10/2022-15:18:20] [V] [TRT] Tactic: -8262349710178828730 Time: 1.46554\n",
      "[04/10/2022-15:18:20] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_3/add Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v0 Tactic: -8133971918129952780\n",
      "[04/10/2022-15:18:20] [V] [TRT] Tactic: -8133971918129952780 Time: 1.58204\n",
      "[04/10/2022-15:18:20] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_3/add Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144\n",
      "[04/10/2022-15:18:20] [V] [TRT] Tactic: -6092040395344634144 Time: 1.82556\n",
      "[04/10/2022-15:18:20] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_3/add Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159\n",
      "[04/10/2022-15:18:20] [V] [TRT] Tactic: -4787320710726427159 Time: 2.00962\n",
      "[04/10/2022-15:18:20] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_3/add Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839\n",
      "[04/10/2022-15:18:20] [V] [TRT] Tactic: -3456450830548107839 Time: 1.54993\n",
      "[04/10/2022-15:18:20] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_3/add Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v0 Tactic: -2318106587342035239\n",
      "[04/10/2022-15:18:20] [V] [TRT] Tactic: -2318106587342035239 Time: 1.38222\n",
      "[04/10/2022-15:18:20] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_3/add Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_mobile_relu_tile148t_nt_v0 Tactic: -1343271414618805657\n",
      "[04/10/2022-15:18:20] [V] [TRT] Tactic: -1343271414618805657 Time: 0.932324\n",
      "[04/10/2022-15:18:20] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_3/add Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241\n",
      "[04/10/2022-15:18:20] [V] [TRT] Tactic: -1218658103698133241 Time: 1.58917\n",
      "[04/10/2022-15:18:20] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_3/add Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091\n",
      "[04/10/2022-15:18:21] [V] [TRT] Tactic: -836875257600482091 Time: 1.51424\n",
      "[04/10/2022-15:18:21] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_3/add Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746\n",
      "[04/10/2022-15:18:21] [V] [TRT] Tactic: -410470605513481746 Time: 1.39189\n",
      "[04/10/2022-15:18:21] [V] [TRT] Fastest Tactic: -1343271414618805657 Time: 0.932324\n",
      "[04/10/2022-15:18:21] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -1343271414618805657\n",
      "[04/10/2022-15:18:21] [V] [TRT] *************** Autotuning format combination: Float(100352,1,3584,128), Float(100352,1,3584,128) -> Float(100352,1,3584,128) ***************\n",
      "[04/10/2022-15:18:21] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage2_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_3/add (CudnnConvolution)\n",
      "[04/10/2022-15:18:21] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:18:21] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage2_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_3/add (CaskConvolution)\n",
      "[04/10/2022-15:18:21] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_3/add Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824\n",
      "[04/10/2022-15:18:21] [V] [TRT] Tactic: -9153228964338181824 Time: 1.79062\n",
      "[04/10/2022-15:18:21] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_3/add Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025\n",
      "[04/10/2022-15:18:21] [V] [TRT] Tactic: -7394439838318485025 Time: 1.33205\n",
      "[04/10/2022-15:18:21] [V] [TRT] Fastest Tactic: -7394439838318485025 Time: 1.33205\n",
      "[04/10/2022-15:18:21] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7394439838318485025\n",
      "[04/10/2022-15:18:21] [V] [TRT] *************** Autotuning format combination: Half(100352,784,28,1), Half(100352,784,28,1) -> Half(100352,784,28,1) ***************\n",
      "[04/10/2022-15:18:21] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage2_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_3/add (CudnnConvolution)\n",
      "[04/10/2022-15:18:21] [V] [TRT] Tactic: 0 Time: 2.90758\n",
      "[04/10/2022-15:18:21] [V] [TRT] Tactic: 1 Time: 2.66868\n",
      "[04/10/2022-15:18:21] [V] [TRT] Tactic: 2 Time: 2.20978\n",
      "[04/10/2022-15:18:21] [V] [TRT] Tactic: 4 Time: 22.7043\n",
      "[04/10/2022-15:18:22] [V] [TRT] Tactic: 5 Time: 21.9342\n",
      "[04/10/2022-15:18:22] [V] [TRT] Tactic: 6 Time: 2.11734\n",
      "[04/10/2022-15:18:22] [V] [TRT] Fastest Tactic: 6 Time: 2.11734\n",
      "[04/10/2022-15:18:22] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage2_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_3/add (CaskConvolution)\n",
      "[04/10/2022-15:18:22] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:18:22] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 6\n",
      "[04/10/2022-15:18:22] [V] [TRT] *************** Autotuning format combination: Half(50176,784:2,28,1), Half(50176,784:2,28,1) -> Half(50176,784:2,28,1) ***************\n",
      "[04/10/2022-15:18:22] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage2_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_3/add (FusedConvActConvolution)\n",
      "[04/10/2022-15:18:22] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:18:22] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage2_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_3/add (CudnnConvolution)\n",
      "[04/10/2022-15:18:22] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:18:22] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage2_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_3/add (CaskConvolution)\n",
      "[04/10/2022-15:18:22] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_3/add Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998\n",
      "[04/10/2022-15:18:22] [V] [TRT] Tactic: 3564772625446233998 Time: 0.911758\n",
      "[04/10/2022-15:18:22] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_3/add Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_large_nn_v1 Tactic: 3650389455493082349\n",
      "[04/10/2022-15:18:22] [V] [TRT] Tactic: 3650389455493082349 Time: 0.945631\n",
      "[04/10/2022-15:18:22] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_3/add Set Tactic Name: maxwell_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 4772821744921268633\n",
      "[04/10/2022-15:18:22] [V] [TRT] Tactic: 4772821744921268633 Time: 0.546523\n",
      "[04/10/2022-15:18:22] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_3/add Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452\n",
      "[04/10/2022-15:18:22] [V] [TRT] Tactic: 5319956359050645452 Time: 0.79377\n",
      "[04/10/2022-15:18:22] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_3/add Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848\n",
      "[04/10/2022-15:18:22] [V] [TRT] Tactic: 7205456024582378848 Time: 0.713861\n",
      "[04/10/2022-15:18:22] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_3/add Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_large_nn_v1 Tactic: -6490690591794140522\n",
      "[04/10/2022-15:18:22] [V] [TRT] Tactic: -6490690591794140522 Time: 0.732311\n",
      "[04/10/2022-15:18:22] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_3/add Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_large_nn_v1 Tactic: -4686027666808657977\n",
      "[04/10/2022-15:18:22] [V] [TRT] Tactic: -4686027666808657977 Time: 0.72985\n",
      "[04/10/2022-15:18:22] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_3/add Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890\n",
      "[04/10/2022-15:18:22] [V] [TRT] Tactic: -4212163711445252890 Time: 0.691927\n",
      "[04/10/2022-15:18:22] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_3/add Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110\n",
      "[04/10/2022-15:18:22] [V] [TRT] Tactic: -3898373634979201110 Time: 0.718496\n",
      "[04/10/2022-15:18:22] [V] [TRT] StatefulPartitionedCall/model_1/stage2_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_3/add Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473\n",
      "[04/10/2022-15:18:22] [V] [TRT] Tactic: -2409163523992614473 Time: 0.692721\n",
      "[04/10/2022-15:18:22] [V] [TRT] Fastest Tactic: 4772821744921268633 Time: 0.546523\n",
      "[04/10/2022-15:18:22] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 4772821744921268633\n",
      "[04/10/2022-15:18:22] [V] [TRT] *************** Autotuning Reformat:Float(100352,784,28,1) -> Float(100352,1,3584,128) ***************\n",
      "[04/10/2022-15:18:22] [V] [TRT] *************** Autotuning Reformat:Float(100352,784,28,1) -> Half(100352,784,28,1) ***************\n",
      "[04/10/2022-15:18:22] [V] [TRT] *************** Autotuning Reformat:Float(100352,784,28,1) -> Half(50176,784:2,28,1) ***************\n",
      "[04/10/2022-15:18:22] [V] [TRT] *************** Autotuning Reformat:Float(100352,1,3584,128) -> Float(100352,784,28,1) ***************\n",
      "[04/10/2022-15:18:22] [V] [TRT] *************** Autotuning Reformat:Float(100352,1,3584,128) -> Half(100352,784,28,1) ***************\n",
      "[04/10/2022-15:18:22] [V] [TRT] *************** Autotuning Reformat:Float(100352,1,3584,128) -> Half(50176,784:2,28,1) ***************\n",
      "[04/10/2022-15:18:22] [V] [TRT] *************** Autotuning Reformat:Half(100352,784,28,1) -> Float(100352,784,28,1) ***************\n",
      "[04/10/2022-15:18:22] [V] [TRT] *************** Autotuning Reformat:Half(100352,784,28,1) -> Float(100352,1,3584,128) ***************\n",
      "[04/10/2022-15:18:22] [V] [TRT] *************** Autotuning Reformat:Half(100352,784,28,1) -> Half(50176,784:2,28,1) ***************\n",
      "[04/10/2022-15:18:22] [V] [TRT] *************** Autotuning Reformat:Half(50176,784:2,28,1) -> Float(100352,784,28,1) ***************\n",
      "[04/10/2022-15:18:22] [V] [TRT] *************** Autotuning Reformat:Half(50176,784:2,28,1) -> Float(100352,1,3584,128) ***************\n",
      "[04/10/2022-15:18:22] [V] [TRT] *************** Autotuning Reformat:Half(50176,784:2,28,1) -> Half(100352,784,28,1) ***************\n",
      "[04/10/2022-15:18:22] [V] [TRT] *************** Autotuning format combination: Float(100352,784,28,1) -> Float(100352,784,28,1) ***************\n",
      "[04/10/2022-15:18:22] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage3_unit1_bn1/FusedBatchNormV3 + StatefulPartitionedCall/model_1/stage3_unit1_relu1/Relu (Scale)\n",
      "[04/10/2022-15:18:22] [V] [TRT] Tactic: 0 Time: 0.0713281\n",
      "[04/10/2022-15:18:22] [V] [TRT] Fastest Tactic: 0 Time: 0.0713281\n",
      "[04/10/2022-15:18:22] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Scale Tactic: 0\n",
      "[04/10/2022-15:18:22] [V] [TRT] *************** Autotuning format combination: Float(100352,1,3584,128) -> Float(100352,1,3584,128) ***************\n",
      "[04/10/2022-15:18:22] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage3_unit1_bn1/FusedBatchNormV3 + StatefulPartitionedCall/model_1/stage3_unit1_relu1/Relu (Scale)\n",
      "[04/10/2022-15:18:22] [V] [TRT] Scale has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:18:22] [V] [TRT] *************** Autotuning format combination: Half(100352,784,28,1) -> Half(100352,784,28,1) ***************\n",
      "[04/10/2022-15:18:22] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage3_unit1_bn1/FusedBatchNormV3 + StatefulPartitionedCall/model_1/stage3_unit1_relu1/Relu (Scale)\n",
      "[04/10/2022-15:18:22] [V] [TRT] Tactic: 0 Time: 0.0683141\n",
      "[04/10/2022-15:18:22] [V] [TRT] Fastest Tactic: 0 Time: 0.0683141\n",
      "[04/10/2022-15:18:22] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Scale Tactic: 0\n",
      "[04/10/2022-15:18:22] [V] [TRT] *************** Autotuning format combination: Half(50176,784:2,28,1) -> Half(50176,784:2,28,1) ***************\n",
      "[04/10/2022-15:18:22] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage3_unit1_bn1/FusedBatchNormV3 + StatefulPartitionedCall/model_1/stage3_unit1_relu1/Relu (Scale)\n",
      "[04/10/2022-15:18:22] [V] [TRT] Tactic: 0 Time: 0.0829296\n",
      "[04/10/2022-15:18:22] [V] [TRT] Fastest Tactic: 0 Time: 0.0829296\n",
      "[04/10/2022-15:18:22] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Scale Tactic: 0\n",
      "[04/10/2022-15:18:22] [V] [TRT] *************** Autotuning Reformat:Float(100352,784,28,1) -> Float(100352,1,3584,128) ***************\n",
      "[04/10/2022-15:18:22] [V] [TRT] *************** Autotuning Reformat:Float(100352,784,28,1) -> Half(100352,784,28,1) ***************\n",
      "[04/10/2022-15:18:22] [V] [TRT] *************** Autotuning Reformat:Float(100352,784,28,1) -> Half(50176,784:2,28,1) ***************\n",
      "[04/10/2022-15:18:22] [V] [TRT] *************** Autotuning Reformat:Float(100352,1,3584,128) -> Float(100352,784,28,1) ***************\n",
      "[04/10/2022-15:18:22] [V] [TRT] *************** Autotuning Reformat:Float(100352,1,3584,128) -> Half(100352,784,28,1) ***************\n",
      "[04/10/2022-15:18:22] [V] [TRT] *************** Autotuning Reformat:Float(100352,1,3584,128) -> Half(50176,784:2,28,1) ***************\n",
      "[04/10/2022-15:18:22] [V] [TRT] *************** Autotuning Reformat:Half(100352,784,28,1) -> Float(100352,784,28,1) ***************\n",
      "[04/10/2022-15:18:22] [V] [TRT] *************** Autotuning Reformat:Half(100352,784,28,1) -> Float(100352,1,3584,128) ***************\n",
      "[04/10/2022-15:18:22] [V] [TRT] *************** Autotuning Reformat:Half(100352,784,28,1) -> Half(50176,784:2,28,1) ***************\n",
      "[04/10/2022-15:18:22] [V] [TRT] *************** Autotuning Reformat:Half(50176,784:2,28,1) -> Float(100352,784,28,1) ***************\n",
      "[04/10/2022-15:18:22] [V] [TRT] *************** Autotuning Reformat:Half(50176,784:2,28,1) -> Float(100352,1,3584,128) ***************\n",
      "[04/10/2022-15:18:22] [V] [TRT] *************** Autotuning Reformat:Half(50176,784:2,28,1) -> Half(100352,784,28,1) ***************\n",
      "[04/10/2022-15:18:22] [V] [TRT] *************** Autotuning Reformat:Float(100352,784,28,1) -> Float(100352,1,3584,128) ***************\n",
      "[04/10/2022-15:18:22] [V] [TRT] *************** Autotuning Reformat:Float(100352,784,28,1) -> Half(100352,784,28,1) ***************\n",
      "[04/10/2022-15:18:22] [V] [TRT] *************** Autotuning Reformat:Float(100352,784,28,1) -> Half(50176,784:2,28,1) ***************\n",
      "[04/10/2022-15:18:22] [V] [TRT] *************** Autotuning Reformat:Float(100352,1,3584,128) -> Float(100352,784,28,1) ***************\n",
      "[04/10/2022-15:18:22] [V] [TRT] *************** Autotuning Reformat:Float(100352,1,3584,128) -> Half(100352,784,28,1) ***************\n",
      "[04/10/2022-15:18:22] [V] [TRT] *************** Autotuning Reformat:Float(100352,1,3584,128) -> Half(50176,784:2,28,1) ***************\n",
      "[04/10/2022-15:18:22] [V] [TRT] *************** Autotuning Reformat:Half(100352,784,28,1) -> Float(100352,784,28,1) ***************\n",
      "[04/10/2022-15:18:22] [V] [TRT] *************** Autotuning Reformat:Half(100352,784,28,1) -> Float(100352,1,3584,128) ***************\n",
      "[04/10/2022-15:18:22] [V] [TRT] *************** Autotuning Reformat:Half(100352,784,28,1) -> Half(50176,784:2,28,1) ***************\n",
      "[04/10/2022-15:18:22] [V] [TRT] *************** Autotuning Reformat:Half(50176,784:2,28,1) -> Float(100352,784,28,1) ***************\n",
      "[04/10/2022-15:18:22] [V] [TRT] *************** Autotuning Reformat:Half(50176,784:2,28,1) -> Float(100352,1,3584,128) ***************\n",
      "[04/10/2022-15:18:22] [V] [TRT] *************** Autotuning Reformat:Half(50176,784:2,28,1) -> Half(100352,784,28,1) ***************\n",
      "[04/10/2022-15:18:22] [V] [TRT] *************** Autotuning format combination: Float(100352,784,28,1) -> Float(50176,196,14,1) ***************\n",
      "[04/10/2022-15:18:22] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage3_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit1_relu2/Relu (CudaDepthwiseConvolution)\n",
      "[04/10/2022-15:18:22] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:18:22] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage3_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit1_relu2/Relu (FusedConvActConvolution)\n",
      "[04/10/2022-15:18:22] [V] [TRT] Tactic: 458751 Time: 1.08161\n",
      "[04/10/2022-15:18:22] [V] [TRT] Fastest Tactic: 458751 Time: 1.08161\n",
      "[04/10/2022-15:18:22] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage3_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit1_relu2/Relu (CudnnConvolution)\n",
      "[04/10/2022-15:18:22] [V] [TRT] Tactic: 0 Time: 1.67919\n",
      "[04/10/2022-15:18:22] [V] [TRT] Tactic: 1 Time: 1.72796\n",
      "[04/10/2022-15:18:22] [V] [TRT] Tactic: 2 Time: 1.40734\n",
      "[04/10/2022-15:18:23] [V] [TRT] Tactic: 5 Time: 45.4237\n",
      "[04/10/2022-15:18:23] [V] [TRT] Fastest Tactic: 2 Time: 1.40734\n",
      "[04/10/2022-15:18:23] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage3_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit1_relu2/Relu (CaskConvolution)\n",
      "[04/10/2022-15:18:23] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758\n",
      "[04/10/2022-15:18:23] [V] [TRT] Tactic: 1062367460111450758 Time: 1.02005\n",
      "[04/10/2022-15:18:23] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v0 Tactic: 1754984623894446479\n",
      "[04/10/2022-15:18:23] [V] [TRT] Tactic: 1754984623894446479 Time: 1.27388\n",
      "[04/10/2022-15:18:23] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v0 Tactic: 3611739942397549984\n",
      "[04/10/2022-15:18:23] [V] [TRT] Tactic: 3611739942397549984 Time: 0.787558\n",
      "[04/10/2022-15:18:23] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379\n",
      "[04/10/2022-15:18:23] [V] [TRT] Tactic: 4337000649858996379 Time: 0.800306\n",
      "[04/10/2022-15:18:23] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441\n",
      "[04/10/2022-15:18:23] [V] [TRT] Tactic: 4501471010995462441 Time: 0.786426\n",
      "[04/10/2022-15:18:23] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826\n",
      "[04/10/2022-15:18:23] [V] [TRT] Tactic: 5137655947464784826 Time: 0.776204\n",
      "[04/10/2022-15:18:23] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929\n",
      "[04/10/2022-15:18:23] [V] [TRT] Tactic: 5288347012147084929 Time: 0.77692\n",
      "[04/10/2022-15:18:23] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056\n",
      "[04/10/2022-15:18:23] [V] [TRT] Tactic: 6645123197870846056 Time: 0.788756\n",
      "[04/10/2022-15:18:23] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478\n",
      "[04/10/2022-15:18:23] [V] [TRT] Tactic: 7144526460361122478 Time: 1.16742\n",
      "[04/10/2022-15:18:23] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713\n",
      "[04/10/2022-15:18:23] [V] [TRT] Tactic: -9137461792520977713 Time: 0.79138\n",
      "[04/10/2022-15:18:23] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730\n",
      "[04/10/2022-15:18:23] [V] [TRT] Tactic: -8262349710178828730 Time: 0.792396\n",
      "[04/10/2022-15:18:23] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v0 Tactic: -8133971918129952780\n",
      "[04/10/2022-15:18:23] [V] [TRT] Tactic: -8133971918129952780 Time: 0.868874\n",
      "[04/10/2022-15:18:23] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144\n",
      "[04/10/2022-15:18:23] [V] [TRT] Tactic: -6092040395344634144 Time: 1.05178\n",
      "[04/10/2022-15:18:23] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159\n",
      "[04/10/2022-15:18:23] [V] [TRT] Tactic: -4787320710726427159 Time: 1.26652\n",
      "[04/10/2022-15:18:23] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839\n",
      "[04/10/2022-15:18:24] [V] [TRT] Tactic: -3456450830548107839 Time: 0.923412\n",
      "[04/10/2022-15:18:24] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241\n",
      "[04/10/2022-15:18:24] [V] [TRT] Tactic: -1218658103698133241 Time: 0.860729\n",
      "[04/10/2022-15:18:24] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091\n",
      "[04/10/2022-15:18:24] [V] [TRT] Tactic: -836875257600482091 Time: 0.835378\n",
      "[04/10/2022-15:18:24] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746\n",
      "[04/10/2022-15:18:24] [V] [TRT] Tactic: -410470605513481746 Time: 0.765345\n",
      "[04/10/2022-15:18:24] [V] [TRT] Fastest Tactic: -410470605513481746 Time: 0.765345\n",
      "[04/10/2022-15:18:24] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -410470605513481746\n",
      "[04/10/2022-15:18:24] [V] [TRT] *************** Autotuning format combination: Float(100352,1,3584,128) -> Float(50176,1,3584,256) ***************\n",
      "[04/10/2022-15:18:24] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage3_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit1_relu2/Relu (CudnnConvolution)\n",
      "[04/10/2022-15:18:24] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:18:24] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage3_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit1_relu2/Relu (CaskConvolution)\n",
      "[04/10/2022-15:18:24] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824\n",
      "[04/10/2022-15:18:24] [V] [TRT] Tactic: -9153228964338181824 Time: 1.08269\n",
      "[04/10/2022-15:18:24] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025\n",
      "[04/10/2022-15:18:24] [V] [TRT] Tactic: -7394439838318485025 Time: 0.762461\n",
      "[04/10/2022-15:18:24] [V] [TRT] Fastest Tactic: -7394439838318485025 Time: 0.762461\n",
      "[04/10/2022-15:18:24] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7394439838318485025\n",
      "[04/10/2022-15:18:24] [V] [TRT] *************** Autotuning format combination: Half(100352,784,28,1) -> Half(50176,196,14,1) ***************\n",
      "[04/10/2022-15:18:24] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage3_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit1_relu2/Relu (CudnnConvolution)\n",
      "[04/10/2022-15:18:24] [V] [TRT] Tactic: 0 Time: 1.74674\n",
      "[04/10/2022-15:18:24] [V] [TRT] Tactic: 1 Time: 1.74576\n",
      "[04/10/2022-15:18:24] [V] [TRT] Tactic: 2 Time: 1.38385\n",
      "[04/10/2022-15:18:25] [V] [TRT] Tactic: 5 Time: 44.3612\n",
      "[04/10/2022-15:18:25] [V] [TRT] Fastest Tactic: 2 Time: 1.38385\n",
      "[04/10/2022-15:18:25] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage3_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit1_relu2/Relu (CaskConvolution)\n",
      "[04/10/2022-15:18:25] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:18:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 2\n",
      "[04/10/2022-15:18:25] [V] [TRT] *************** Autotuning format combination: Half(50176,784:2,28,1) -> Half(25088,196:2,14,1) ***************\n",
      "[04/10/2022-15:18:25] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage3_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit1_relu2/Relu (FusedConvActConvolution)\n",
      "[04/10/2022-15:18:25] [V] [TRT] Tactic: 458751 Time: 0.837357\n",
      "[04/10/2022-15:18:25] [V] [TRT] Fastest Tactic: 458751 Time: 0.837357\n",
      "[04/10/2022-15:18:25] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage3_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit1_relu2/Relu (CudnnConvolution)\n",
      "[04/10/2022-15:18:25] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:18:25] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage3_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit1_relu2/Relu (CaskConvolution)\n",
      "[04/10/2022-15:18:25] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit1_relu2/Relu Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998\n",
      "[04/10/2022-15:18:25] [V] [TRT] Tactic: 3564772625446233998 Time: 0.511283\n",
      "[04/10/2022-15:18:25] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit1_relu2/Relu Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_large_nn_v1 Tactic: 3650389455493082349\n",
      "[04/10/2022-15:18:25] [V] [TRT] Tactic: 3650389455493082349 Time: 0.535267\n",
      "[04/10/2022-15:18:25] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit1_relu2/Relu Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452\n",
      "[04/10/2022-15:18:25] [V] [TRT] Tactic: 5319956359050645452 Time: 0.46235\n",
      "[04/10/2022-15:18:25] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit1_relu2/Relu Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848\n",
      "[04/10/2022-15:18:25] [V] [TRT] Tactic: 7205456024582378848 Time: 0.420215\n",
      "[04/10/2022-15:18:25] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit1_relu2/Relu Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_large_nn_v1 Tactic: -6490690591794140522\n",
      "[04/10/2022-15:18:25] [V] [TRT] Tactic: -6490690591794140522 Time: 0.423203\n",
      "[04/10/2022-15:18:25] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit1_relu2/Relu Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_large_nn_v1 Tactic: -4686027666808657977\n",
      "[04/10/2022-15:18:25] [V] [TRT] Tactic: -4686027666808657977 Time: 0.40556\n",
      "[04/10/2022-15:18:25] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit1_relu2/Relu Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890\n",
      "[04/10/2022-15:18:25] [V] [TRT] Tactic: -4212163711445252890 Time: 0.391191\n",
      "[04/10/2022-15:18:25] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit1_relu2/Relu Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110\n",
      "[04/10/2022-15:18:25] [V] [TRT] Tactic: -3898373634979201110 Time: 0.401165\n",
      "[04/10/2022-15:18:25] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit1_relu2/Relu Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473\n",
      "[04/10/2022-15:18:25] [V] [TRT] Tactic: -2409163523992614473 Time: 0.404811\n",
      "[04/10/2022-15:18:25] [V] [TRT] Fastest Tactic: -4212163711445252890 Time: 0.391191\n",
      "[04/10/2022-15:18:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -4212163711445252890\n",
      "[04/10/2022-15:18:25] [V] [TRT] *************** Autotuning Reformat:Float(50176,196,14,1) -> Float(50176,1,3584,256) ***************\n",
      "[04/10/2022-15:18:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:18:25] [V] [TRT] Tactic: 1002 Time: 0.0736395\n",
      "[04/10/2022-15:18:25] [V] [TRT] Tactic: 0 Time: 0.0827541\n",
      "[04/10/2022-15:18:25] [V] [TRT] Fastest Tactic: 1002 Time: 0.0736395\n",
      "[04/10/2022-15:18:25] [V] [TRT] *************** Autotuning Reformat:Float(50176,196,14,1) -> Half(50176,196,14,1) ***************\n",
      "[04/10/2022-15:18:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:18:25] [V] [TRT] Tactic: 1002 Time: 1.35408\n",
      "[04/10/2022-15:18:25] [V] [TRT] Tactic: 0 Time: 0.0589974\n",
      "[04/10/2022-15:18:25] [V] [TRT] Fastest Tactic: 0 Time: 0.0589974\n",
      "[04/10/2022-15:18:25] [V] [TRT] *************** Autotuning Reformat:Float(50176,196,14,1) -> Half(25088,196:2,14,1) ***************\n",
      "[04/10/2022-15:18:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:18:25] [V] [TRT] Tactic: 1002 Time: 0.0866146\n",
      "[04/10/2022-15:18:25] [V] [TRT] Tactic: 0 Time: 0.0465105\n",
      "[04/10/2022-15:18:25] [V] [TRT] Fastest Tactic: 0 Time: 0.0465105\n",
      "[04/10/2022-15:18:25] [V] [TRT] *************** Autotuning Reformat:Float(50176,1,3584,256) -> Float(50176,196,14,1) ***************\n",
      "[04/10/2022-15:18:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:18:25] [V] [TRT] Tactic: 1002 Time: 0.0941669\n",
      "[04/10/2022-15:18:25] [V] [TRT] Tactic: 0 Time: 0.0772655\n",
      "[04/10/2022-15:18:25] [V] [TRT] Fastest Tactic: 0 Time: 0.0772655\n",
      "[04/10/2022-15:18:25] [V] [TRT] *************** Autotuning Reformat:Float(50176,1,3584,256) -> Half(50176,196,14,1) ***************\n",
      "[04/10/2022-15:18:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:18:25] [V] [TRT] Tactic: 1002 Time: 0.0631836\n",
      "[04/10/2022-15:18:25] [V] [TRT] Tactic: 0 Time: 0.0765559\n",
      "[04/10/2022-15:18:25] [V] [TRT] Fastest Tactic: 1002 Time: 0.0631836\n",
      "[04/10/2022-15:18:25] [V] [TRT] *************** Autotuning Reformat:Float(50176,1,3584,256) -> Half(25088,196:2,14,1) ***************\n",
      "[04/10/2022-15:18:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:18:25] [V] [TRT] Tactic: 1002 Time: 0.0756251\n",
      "[04/10/2022-15:18:25] [V] [TRT] Tactic: 0 Time: 0.0894464\n",
      "[04/10/2022-15:18:25] [V] [TRT] Fastest Tactic: 1002 Time: 0.0756251\n",
      "[04/10/2022-15:18:25] [V] [TRT] *************** Autotuning Reformat:Half(50176,196,14,1) -> Float(50176,196,14,1) ***************\n",
      "[04/10/2022-15:18:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:18:25] [V] [TRT] Tactic: 1002 Time: 1.39237\n",
      "[04/10/2022-15:18:25] [V] [TRT] Tactic: 0 Time: 0.0493818\n",
      "[04/10/2022-15:18:25] [V] [TRT] Fastest Tactic: 0 Time: 0.0493818\n",
      "[04/10/2022-15:18:25] [V] [TRT] *************** Autotuning Reformat:Half(50176,196,14,1) -> Float(50176,1,3584,256) ***************\n",
      "[04/10/2022-15:18:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:18:25] [V] [TRT] Tactic: 1002 Time: 0.0575\n",
      "[04/10/2022-15:18:25] [V] [TRT] Tactic: 0 Time: 0.0822721\n",
      "[04/10/2022-15:18:25] [V] [TRT] Fastest Tactic: 1002 Time: 0.0575\n",
      "[04/10/2022-15:18:25] [V] [TRT] *************** Autotuning Reformat:Half(50176,196,14,1) -> Half(25088,196:2,14,1) ***************\n",
      "[04/10/2022-15:18:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:18:25] [V] [TRT] Tactic: 1002 Time: 0.0623308\n",
      "[04/10/2022-15:18:25] [V] [TRT] Tactic: 0 Time: 0.0456186\n",
      "[04/10/2022-15:18:25] [V] [TRT] Fastest Tactic: 0 Time: 0.0456186\n",
      "[04/10/2022-15:18:25] [V] [TRT] *************** Autotuning Reformat:Half(25088,196:2,14,1) -> Float(50176,196,14,1) ***************\n",
      "[04/10/2022-15:18:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:18:25] [V] [TRT] Tactic: 1002 Time: 0.0825586\n",
      "[04/10/2022-15:18:25] [V] [TRT] Tactic: 0 Time: 0.0409179\n",
      "[04/10/2022-15:18:25] [V] [TRT] Fastest Tactic: 0 Time: 0.0409179\n",
      "[04/10/2022-15:18:25] [V] [TRT] *************** Autotuning Reformat:Half(25088,196:2,14,1) -> Float(50176,1,3584,256) ***************\n",
      "[04/10/2022-15:18:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:18:25] [V] [TRT] Tactic: 1002 Time: 0.0582356\n",
      "[04/10/2022-15:18:25] [V] [TRT] Tactic: 0 Time: 0.0943099\n",
      "[04/10/2022-15:18:25] [V] [TRT] Fastest Tactic: 1002 Time: 0.0582356\n",
      "[04/10/2022-15:18:25] [V] [TRT] *************** Autotuning Reformat:Half(25088,196:2,14,1) -> Half(50176,196,14,1) ***************\n",
      "[04/10/2022-15:18:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:18:25] [V] [TRT] Tactic: 1002 Time: 0.110091\n",
      "[04/10/2022-15:18:25] [V] [TRT] Tactic: 0 Time: 0.0387304\n",
      "[04/10/2022-15:18:25] [V] [TRT] Fastest Tactic: 0 Time: 0.0387304\n",
      "[04/10/2022-15:18:25] [V] [TRT] *************** Autotuning format combination: Float(50176,196,14,1) -> Float(50176,196,14,1) ***************\n",
      "[04/10/2022-15:18:25] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage3_unit1_conv2/Conv2D (CudaDepthwiseConvolution)\n",
      "[04/10/2022-15:18:25] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:18:25] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage3_unit1_conv2/Conv2D (FusedConvActConvolution)\n",
      "[04/10/2022-15:18:25] [V] [TRT] Tactic: 524287 Time: 1.58184\n",
      "[04/10/2022-15:18:25] [V] [TRT] Tactic: 720895 Time: 1.70061\n",
      "[04/10/2022-15:18:25] [V] [TRT] Tactic: 983039 Time: 1.45838\n",
      "[04/10/2022-15:18:25] [V] [TRT] Tactic: 1048575 Time: 1.59714\n",
      "[04/10/2022-15:18:26] [V] [TRT] Tactic: 1703935 Time: 1.60672\n",
      "[04/10/2022-15:18:26] [V] [TRT] Tactic: 1769471 Time: 1.45738\n",
      "[04/10/2022-15:18:26] [V] [TRT] Tactic: 1966079 Time: 1.56023\n",
      "[04/10/2022-15:18:26] [V] [TRT] Tactic: 2031615 Time: 1.60471\n",
      "[04/10/2022-15:18:26] [V] [TRT] Tactic: 2228223 Time: 2.0363\n",
      "[04/10/2022-15:18:26] [V] [TRT] Tactic: 2424831 Time: 2.19258\n",
      "[04/10/2022-15:18:26] [V] [TRT] Tactic: 2621439 Time: 1.8744\n",
      "[04/10/2022-15:18:26] [V] [TRT] Tactic: 2752511 Time: 1.3803\n",
      "[04/10/2022-15:18:26] [V] [TRT] Tactic: 2818047 Time: 1.85949\n",
      "[04/10/2022-15:18:27] [V] [TRT] Tactic: 2883583 Time: 1.5218\n",
      "[04/10/2022-15:18:27] [V] [TRT] Tactic: 3014655 Time: 1.47524\n",
      "[04/10/2022-15:18:27] [V] [TRT] Tactic: 3145727 Time: 1.37335\n",
      "[04/10/2022-15:18:27] [V] [TRT] Tactic: 3473407 Time: 1.59021\n",
      "[04/10/2022-15:18:27] [V] [TRT] Tactic: 3604479 Time: 1.45706\n",
      "[04/10/2022-15:18:27] [V] [TRT] Tactic: 3735551 Time: 1.92174\n",
      "[04/10/2022-15:18:27] [V] [TRT] Tactic: 4390911 Time: 1.41056\n",
      "[04/10/2022-15:18:27] [V] [TRT] Tactic: 5046271 Time: 1.57169\n",
      "[04/10/2022-15:18:27] [V] [TRT] Tactic: 5963775 Time: 1.38968\n",
      "[04/10/2022-15:18:27] [V] [TRT] Tactic: 6160383 Time: 1.54398\n",
      "[04/10/2022-15:18:27] [V] [TRT] Tactic: 6488063 Time: 1.34025\n",
      "[04/10/2022-15:18:28] [V] [TRT] Tactic: 6881279 Time: 1.37367\n",
      "[04/10/2022-15:18:28] [V] [TRT] Tactic: 7274495 Time: 1.85144\n",
      "[04/10/2022-15:18:28] [V] [TRT] Tactic: 7864319 Time: 1.96456\n",
      "[04/10/2022-15:18:28] [V] [TRT] Tactic: 7995391 Time: 1.66993\n",
      "[04/10/2022-15:18:28] [V] [TRT] Tactic: 8585215 Time: 1.40624\n",
      "[04/10/2022-15:18:28] [V] [TRT] Tactic: 8847359 Time: 1.44174\n",
      "[04/10/2022-15:18:28] [V] [TRT] Tactic: 8978431 Time: 1.40785\n",
      "[04/10/2022-15:18:28] [V] [TRT] Tactic: 9043967 Time: 1.3543\n",
      "[04/10/2022-15:18:28] [V] [TRT] Tactic: 9175039 Time: 1.46558\n",
      "[04/10/2022-15:18:28] [V] [TRT] Tactic: 9502719 Time: 1.44037\n",
      "[04/10/2022-15:18:29] [V] [TRT] Tactic: 9830399 Time: 1.45301\n",
      "[04/10/2022-15:18:29] [V] [TRT] Tactic: 9961471 Time: 1.59719\n",
      "[04/10/2022-15:18:29] [V] [TRT] Tactic: 10027007 Time: 1.42169\n",
      "[04/10/2022-15:18:29] [V] [TRT] Tactic: 10092543 Time: 1.42249\n",
      "[04/10/2022-15:18:29] [V] [TRT] Tactic: 10289151 Time: 1.56488\n",
      "[04/10/2022-15:18:29] [V] [TRT] Tactic: 10485759 Time: 1.41839\n",
      "[04/10/2022-15:18:29] [V] [TRT] Tactic: 10682367 Time: 1.91294\n",
      "[04/10/2022-15:18:29] [V] [TRT] Tactic: 10813439 Time: 1.67867\n",
      "[04/10/2022-15:18:29] [V] [TRT] Fastest Tactic: 6488063 Time: 1.34025\n",
      "[04/10/2022-15:18:29] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage3_unit1_conv2/Conv2D (CudnnConvolution)\n",
      "[04/10/2022-15:18:29] [V] [TRT] Tactic: 0 Time: 2.93285\n",
      "[04/10/2022-15:18:29] [V] [TRT] Tactic: 1 Time: 1.65186\n",
      "[04/10/2022-15:18:29] [V] [TRT] Tactic: 2 Time: 2.46165\n",
      "[04/10/2022-15:18:30] [V] [TRT] Tactic: 4 Time: 17.3118\n",
      "[04/10/2022-15:18:30] [V] [TRT] Tactic: 5 skipped. Scratch requested: 287440896, available: 268435456\n",
      "[04/10/2022-15:18:30] [V] [TRT] Tactic: 6 Time: 1.40176\n",
      "[04/10/2022-15:18:30] [I] [TRT] Some tactics do not have sufficient workspace memory to run. Increasing workspace size may increase performance, please check verbose output.\n",
      "[04/10/2022-15:18:30] [V] [TRT] Fastest Tactic: 6 Time: 1.40176\n",
      "[04/10/2022-15:18:30] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage3_unit1_conv2/Conv2D (CaskConvolution)\n",
      "[04/10/2022-15:18:30] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758\n",
      "[04/10/2022-15:18:30] [V] [TRT] Tactic: 1062367460111450758 Time: 2.03169\n",
      "[04/10/2022-15:18:30] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v0 Tactic: 1754984623894446479\n",
      "[04/10/2022-15:18:30] [V] [TRT] Tactic: 1754984623894446479 Time: 2.60079\n",
      "[04/10/2022-15:18:30] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v0 Tactic: 3611739942397549984\n",
      "[04/10/2022-15:18:30] [V] [TRT] Tactic: 3611739942397549984 Time: 1.56115\n",
      "[04/10/2022-15:18:30] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v1 Tactic: 3827454225649558724\n",
      "[04/10/2022-15:18:30] [V] [TRT] Tactic: 3827454225649558724 Time: 1.17214\n",
      "[04/10/2022-15:18:30] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379\n",
      "[04/10/2022-15:18:30] [V] [TRT] Tactic: 4337000649858996379 Time: 1.5957\n",
      "[04/10/2022-15:18:30] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441\n",
      "[04/10/2022-15:18:30] [V] [TRT] Tactic: 4501471010995462441 Time: 1.56605\n",
      "[04/10/2022-15:18:30] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826\n",
      "[04/10/2022-15:18:30] [V] [TRT] Tactic: 5137655947464784826 Time: 1.51218\n",
      "[04/10/2022-15:18:30] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929\n",
      "[04/10/2022-15:18:30] [V] [TRT] Tactic: 5288347012147084929 Time: 1.52457\n",
      "[04/10/2022-15:18:30] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 5921334924264294896\n",
      "[04/10/2022-15:18:30] [V] [TRT] Tactic: 5921334924264294896 Time: 0.912656\n",
      "[04/10/2022-15:18:30] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056\n",
      "[04/10/2022-15:18:30] [V] [TRT] Tactic: 6645123197870846056 Time: 1.571\n",
      "[04/10/2022-15:18:30] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478\n",
      "[04/10/2022-15:18:30] [V] [TRT] Tactic: 7144526460361122478 Time: 2.23711\n",
      "[04/10/2022-15:18:30] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: 7852627285308570038\n",
      "[04/10/2022-15:18:30] [V] [TRT] Tactic: 7852627285308570038 Time: 1.14639\n",
      "[04/10/2022-15:18:30] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713\n",
      "[04/10/2022-15:18:30] [V] [TRT] Tactic: -9137461792520977713 Time: 1.57409\n",
      "[04/10/2022-15:18:30] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v0 Tactic: -8776506421218919509\n",
      "[04/10/2022-15:18:31] [V] [TRT] Tactic: -8776506421218919509 Time: 1.11365\n",
      "[04/10/2022-15:18:31] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730\n",
      "[04/10/2022-15:18:31] [V] [TRT] Tactic: -8262349710178828730 Time: 1.57025\n",
      "[04/10/2022-15:18:31] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v0 Tactic: -8133971918129952780\n",
      "[04/10/2022-15:18:31] [V] [TRT] Tactic: -8133971918129952780 Time: 1.71518\n",
      "[04/10/2022-15:18:31] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144\n",
      "[04/10/2022-15:18:31] [V] [TRT] Tactic: -6092040395344634144 Time: 2.12655\n",
      "[04/10/2022-15:18:31] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159\n",
      "[04/10/2022-15:18:31] [V] [TRT] Tactic: -4787320710726427159 Time: 2.58438\n",
      "[04/10/2022-15:18:31] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839\n",
      "[04/10/2022-15:18:31] [V] [TRT] Tactic: -3456450830548107839 Time: 1.78161\n",
      "[04/10/2022-15:18:31] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v0 Tactic: -2318106587342035239\n",
      "[04/10/2022-15:18:31] [V] [TRT] Tactic: -2318106587342035239 Time: 1.10955\n",
      "[04/10/2022-15:18:31] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_mobile_relu_tile148t_nt_v0 Tactic: -1343271414618805657\n",
      "[04/10/2022-15:18:31] [V] [TRT] Tactic: -1343271414618805657 Time: 0.835742\n",
      "[04/10/2022-15:18:31] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241\n",
      "[04/10/2022-15:18:31] [V] [TRT] Tactic: -1218658103698133241 Time: 1.70952\n",
      "[04/10/2022-15:18:31] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091\n",
      "[04/10/2022-15:18:31] [V] [TRT] Tactic: -836875257600482091 Time: 1.63653\n",
      "[04/10/2022-15:18:31] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746\n",
      "[04/10/2022-15:18:31] [V] [TRT] Tactic: -410470605513481746 Time: 1.50964\n",
      "[04/10/2022-15:18:31] [V] [TRT] Fastest Tactic: -1343271414618805657 Time: 0.835742\n",
      "[04/10/2022-15:18:31] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -1343271414618805657\n",
      "[04/10/2022-15:18:31] [V] [TRT] *************** Autotuning format combination: Float(50176,1,3584,256) -> Float(50176,1,3584,256) ***************\n",
      "[04/10/2022-15:18:31] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage3_unit1_conv2/Conv2D (CudnnConvolution)\n",
      "[04/10/2022-15:18:31] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:18:31] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage3_unit1_conv2/Conv2D (CaskConvolution)\n",
      "[04/10/2022-15:18:31] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824\n",
      "[04/10/2022-15:18:31] [V] [TRT] Tactic: -9153228964338181824 Time: 1.83128\n",
      "[04/10/2022-15:18:31] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025\n",
      "[04/10/2022-15:18:31] [V] [TRT] Tactic: -7394439838318485025 Time: 1.49191\n",
      "[04/10/2022-15:18:31] [V] [TRT] Fastest Tactic: -7394439838318485025 Time: 1.49191\n",
      "[04/10/2022-15:18:31] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7394439838318485025\n",
      "[04/10/2022-15:18:31] [V] [TRT] *************** Autotuning format combination: Half(50176,196,14,1) -> Half(50176,196,14,1) ***************\n",
      "[04/10/2022-15:18:31] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage3_unit1_conv2/Conv2D (CudnnConvolution)\n",
      "[04/10/2022-15:18:31] [V] [TRT] Tactic: 0 Time: 2.87499\n",
      "[04/10/2022-15:18:31] [V] [TRT] Tactic: 1 Time: 1.92921\n",
      "[04/10/2022-15:18:31] [V] [TRT] Tactic: 2 Time: 2.39186\n",
      "[04/10/2022-15:18:32] [V] [TRT] Tactic: 4 Time: 15.5527\n",
      "[04/10/2022-15:18:32] [V] [TRT] Tactic: 5 skipped. Scratch requested: 287440896, available: 268435456\n",
      "[04/10/2022-15:18:32] [V] [TRT] Tactic: 6 Time: 2.57764\n",
      "[04/10/2022-15:18:32] [V] [TRT] Fastest Tactic: 1 Time: 1.92921\n",
      "[04/10/2022-15:18:32] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage3_unit1_conv2/Conv2D (CaskConvolution)\n",
      "[04/10/2022-15:18:32] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:18:32] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 1\n",
      "[04/10/2022-15:18:32] [V] [TRT] *************** Autotuning format combination: Half(25088,196:2,14,1) -> Half(25088,196:2,14,1) ***************\n",
      "[04/10/2022-15:18:32] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage3_unit1_conv2/Conv2D (FusedConvActConvolution)\n",
      "[04/10/2022-15:18:32] [V] [TRT] Tactic: 524287 Time: 0.855098\n",
      "[04/10/2022-15:18:32] [V] [TRT] Tactic: 720895 Time: 0.961146\n",
      "[04/10/2022-15:18:32] [V] [TRT] Tactic: 983039 Time: 0.810384\n",
      "[04/10/2022-15:18:32] [V] [TRT] Tactic: 1048575 Time: 0.8886\n",
      "[04/10/2022-15:18:32] [V] [TRT] Tactic: 1703935 Time: 0.901335\n",
      "[04/10/2022-15:18:32] [V] [TRT] Tactic: 1769471 Time: 5.25803\n",
      "[04/10/2022-15:18:32] [V] [TRT] Tactic: 1966079 Time: 0.938548\n",
      "[04/10/2022-15:18:32] [V] [TRT] Tactic: 2031615 Time: 0.833626\n",
      "[04/10/2022-15:18:32] [V] [TRT] Tactic: 2228223 Time: 1.10063\n",
      "[04/10/2022-15:18:33] [V] [TRT] Tactic: 2424831 Time: 1.6419\n",
      "[04/10/2022-15:18:33] [V] [TRT] Tactic: 2621439 Time: 0.999981\n",
      "[04/10/2022-15:18:33] [V] [TRT] Tactic: 2752511 Time: 0.732715\n",
      "[04/10/2022-15:18:33] [V] [TRT] Tactic: 2818047 Time: 1.02895\n",
      "[04/10/2022-15:18:33] [V] [TRT] Tactic: 2883583 Time: 0.89334\n",
      "[04/10/2022-15:18:33] [V] [TRT] Tactic: 3014655 Time: 0.830117\n",
      "[04/10/2022-15:18:33] [V] [TRT] Tactic: 3145727 Time: 0.771276\n",
      "[04/10/2022-15:18:33] [V] [TRT] Tactic: 3473407 Time: 0.926732\n",
      "[04/10/2022-15:18:33] [V] [TRT] Tactic: 3604479 Time: 0.819694\n",
      "[04/10/2022-15:18:33] [V] [TRT] Tactic: 3735551 Time: 0.938431\n",
      "[04/10/2022-15:18:33] [V] [TRT] Tactic: 4390911 Time: 0.76666\n",
      "[04/10/2022-15:18:33] [V] [TRT] Tactic: 5046271 Time: 0.838073\n",
      "[04/10/2022-15:18:33] [V] [TRT] Tactic: 5963775 Time: 0.785436\n",
      "[04/10/2022-15:18:33] [V] [TRT] Tactic: 6160383 Time: 0.896152\n",
      "[04/10/2022-15:18:33] [V] [TRT] Tactic: 6488063 Time: 0.748757\n",
      "[04/10/2022-15:18:33] [V] [TRT] Tactic: 6881279 Time: 0.770384\n",
      "[04/10/2022-15:18:34] [V] [TRT] Tactic: 7274495 Time: 1.05943\n",
      "[04/10/2022-15:18:34] [V] [TRT] Tactic: 7864319 Time: 1.07048\n",
      "[04/10/2022-15:18:34] [V] [TRT] Tactic: 7995391 Time: 0.968118\n",
      "[04/10/2022-15:18:34] [V] [TRT] Tactic: 8585215 Time: 0.804707\n",
      "[04/10/2022-15:18:34] [V] [TRT] Tactic: 8847359 Time: 0.776295\n",
      "[04/10/2022-15:18:34] [V] [TRT] Tactic: 8978431 Time: 0.829961\n",
      "[04/10/2022-15:18:34] [V] [TRT] Tactic: 9043967 Time: 0.726784\n",
      "[04/10/2022-15:18:34] [V] [TRT] Tactic: 9175039 Time: 0.820703\n",
      "[04/10/2022-15:18:34] [V] [TRT] Tactic: 9502719 Time: 0.737187\n",
      "[04/10/2022-15:18:34] [V] [TRT] Tactic: 9830399 Time: 0.782617\n",
      "[04/10/2022-15:18:34] [V] [TRT] Tactic: 9961471 Time: 0.890925\n",
      "[04/10/2022-15:18:34] [V] [TRT] Tactic: 10027007 Time: 0.759889\n",
      "[04/10/2022-15:18:34] [V] [TRT] Tactic: 10092543 Time: 0.767494\n",
      "[04/10/2022-15:18:34] [V] [TRT] Tactic: 10289151 Time: 0.940332\n",
      "[04/10/2022-15:18:34] [V] [TRT] Tactic: 10485759 Time: 0.752324\n",
      "[04/10/2022-15:18:34] [V] [TRT] Tactic: 10682367 Time: 0.982637\n",
      "[04/10/2022-15:18:35] [V] [TRT] Tactic: 10813439 Time: 0.98099\n",
      "[04/10/2022-15:18:35] [V] [TRT] Fastest Tactic: 9043967 Time: 0.726784\n",
      "[04/10/2022-15:18:35] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage3_unit1_conv2/Conv2D (CudnnConvolution)\n",
      "[04/10/2022-15:18:35] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:18:35] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage3_unit1_conv2/Conv2D (CaskConvolution)\n",
      "[04/10/2022-15:18:35] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_conv2/Conv2D Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998\n",
      "[04/10/2022-15:18:35] [V] [TRT] Tactic: 3564772625446233998 Time: 1.03606\n",
      "[04/10/2022-15:18:35] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_conv2/Conv2D Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_large_nn_v1 Tactic: 3650389455493082349\n",
      "[04/10/2022-15:18:35] [V] [TRT] Tactic: 3650389455493082349 Time: 1.07912\n",
      "[04/10/2022-15:18:35] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_conv2/Conv2D Set Tactic Name: maxwell_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 4772821744921268633\n",
      "[04/10/2022-15:18:35] [V] [TRT] Tactic: 4772821744921268633 Time: 0.483379\n",
      "[04/10/2022-15:18:35] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_conv2/Conv2D Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452\n",
      "[04/10/2022-15:18:35] [V] [TRT] Tactic: 5319956359050645452 Time: 0.903548\n",
      "[04/10/2022-15:18:35] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_conv2/Conv2D Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848\n",
      "[04/10/2022-15:18:35] [V] [TRT] Tactic: 7205456024582378848 Time: 0.800176\n",
      "[04/10/2022-15:18:35] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_conv2/Conv2D Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_large_nn_v1 Tactic: -6490690591794140522\n",
      "[04/10/2022-15:18:35] [V] [TRT] Tactic: -6490690591794140522 Time: 0.812695\n",
      "[04/10/2022-15:18:35] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_conv2/Conv2D Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_large_nn_v1 Tactic: -4686027666808657977\n",
      "[04/10/2022-15:18:35] [V] [TRT] Tactic: -4686027666808657977 Time: 0.79683\n",
      "[04/10/2022-15:18:35] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_conv2/Conv2D Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890\n",
      "[04/10/2022-15:18:35] [V] [TRT] Tactic: -4212163711445252890 Time: 0.757851\n",
      "[04/10/2022-15:18:35] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_conv2/Conv2D Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110\n",
      "[04/10/2022-15:18:35] [V] [TRT] Tactic: -3898373634979201110 Time: 0.79319\n",
      "[04/10/2022-15:18:35] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_conv2/Conv2D Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473\n",
      "[04/10/2022-15:18:35] [V] [TRT] Tactic: -2409163523992614473 Time: 0.766856\n",
      "[04/10/2022-15:18:35] [V] [TRT] Fastest Tactic: 4772821744921268633 Time: 0.483379\n",
      "[04/10/2022-15:18:35] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 4772821744921268633\n",
      "[04/10/2022-15:18:35] [V] [TRT] *************** Autotuning Reformat:Float(100352,784,28,1) -> Float(100352,1,3584,128) ***************\n",
      "[04/10/2022-15:18:35] [V] [TRT] *************** Autotuning Reformat:Float(100352,784,28,1) -> Half(100352,784,28,1) ***************\n",
      "[04/10/2022-15:18:35] [V] [TRT] *************** Autotuning Reformat:Float(100352,784,28,1) -> Half(50176,784:2,28,1) ***************\n",
      "[04/10/2022-15:18:35] [V] [TRT] *************** Autotuning Reformat:Float(100352,1,3584,128) -> Float(100352,784,28,1) ***************\n",
      "[04/10/2022-15:18:35] [V] [TRT] *************** Autotuning Reformat:Float(100352,1,3584,128) -> Half(100352,784,28,1) ***************\n",
      "[04/10/2022-15:18:35] [V] [TRT] *************** Autotuning Reformat:Float(100352,1,3584,128) -> Half(50176,784:2,28,1) ***************\n",
      "[04/10/2022-15:18:35] [V] [TRT] *************** Autotuning Reformat:Half(100352,784,28,1) -> Float(100352,784,28,1) ***************\n",
      "[04/10/2022-15:18:35] [V] [TRT] *************** Autotuning Reformat:Half(100352,784,28,1) -> Float(100352,1,3584,128) ***************\n",
      "[04/10/2022-15:18:35] [V] [TRT] *************** Autotuning Reformat:Half(100352,784,28,1) -> Half(50176,784:2,28,1) ***************\n",
      "[04/10/2022-15:18:35] [V] [TRT] *************** Autotuning Reformat:Half(50176,784:2,28,1) -> Float(100352,784,28,1) ***************\n",
      "[04/10/2022-15:18:35] [V] [TRT] *************** Autotuning Reformat:Half(50176,784:2,28,1) -> Float(100352,1,3584,128) ***************\n",
      "[04/10/2022-15:18:35] [V] [TRT] *************** Autotuning Reformat:Half(50176,784:2,28,1) -> Half(100352,784,28,1) ***************\n",
      "[04/10/2022-15:18:35] [V] [TRT] *************** Autotuning Reformat:Float(50176,196,14,1) -> Float(50176,1,3584,256) ***************\n",
      "[04/10/2022-15:18:35] [V] [TRT] *************** Autotuning Reformat:Float(50176,196,14,1) -> Half(50176,196,14,1) ***************\n",
      "[04/10/2022-15:18:35] [V] [TRT] *************** Autotuning Reformat:Float(50176,196,14,1) -> Half(25088,196:2,14,1) ***************\n",
      "[04/10/2022-15:18:35] [V] [TRT] *************** Autotuning Reformat:Float(50176,1,3584,256) -> Float(50176,196,14,1) ***************\n",
      "[04/10/2022-15:18:35] [V] [TRT] *************** Autotuning Reformat:Float(50176,1,3584,256) -> Half(50176,196,14,1) ***************\n",
      "[04/10/2022-15:18:35] [V] [TRT] *************** Autotuning Reformat:Float(50176,1,3584,256) -> Half(25088,196:2,14,1) ***************\n",
      "[04/10/2022-15:18:35] [V] [TRT] *************** Autotuning Reformat:Half(50176,196,14,1) -> Float(50176,196,14,1) ***************\n",
      "[04/10/2022-15:18:35] [V] [TRT] *************** Autotuning Reformat:Half(50176,196,14,1) -> Float(50176,1,3584,256) ***************\n",
      "[04/10/2022-15:18:35] [V] [TRT] *************** Autotuning Reformat:Half(50176,196,14,1) -> Half(25088,196:2,14,1) ***************\n",
      "[04/10/2022-15:18:35] [V] [TRT] *************** Autotuning Reformat:Half(25088,196:2,14,1) -> Float(50176,196,14,1) ***************\n",
      "[04/10/2022-15:18:35] [V] [TRT] *************** Autotuning Reformat:Half(25088,196:2,14,1) -> Float(50176,1,3584,256) ***************\n",
      "[04/10/2022-15:18:35] [V] [TRT] *************** Autotuning Reformat:Half(25088,196:2,14,1) -> Half(50176,196,14,1) ***************\n",
      "[04/10/2022-15:18:35] [V] [TRT] *************** Autotuning format combination: Float(100352,784,28,1), Float(50176,196,14,1) -> Float(50176,196,14,1) ***************\n",
      "[04/10/2022-15:18:35] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage3_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_4/add (CudaDepthwiseConvolution)\n",
      "[04/10/2022-15:18:35] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:18:35] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage3_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_4/add (FusedConvActConvolution)\n",
      "[04/10/2022-15:18:35] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:18:35] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage3_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_4/add (CudnnConvolution)\n",
      "[04/10/2022-15:18:35] [V] [TRT] Tactic: 0 Time: 0.277116\n",
      "[04/10/2022-15:18:35] [V] [TRT] Tactic: 1 Time: 0.260137\n",
      "[04/10/2022-15:18:35] [V] [TRT] Tactic: 2 Time: 0.33388\n",
      "[04/10/2022-15:18:35] [V] [TRT] Fastest Tactic: 1 Time: 0.260137\n",
      "[04/10/2022-15:18:35] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage3_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_4/add (CaskConvolution)\n",
      "[04/10/2022-15:18:35] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_4/add Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758\n",
      "[04/10/2022-15:18:35] [V] [TRT] Tactic: 1062367460111450758 Time: 0.168151\n",
      "[04/10/2022-15:18:35] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_4/add Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347\n",
      "[04/10/2022-15:18:35] [V] [TRT] Tactic: 1698681053543049347 Time: 0.159486\n",
      "[04/10/2022-15:18:35] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_4/add Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441\n",
      "[04/10/2022-15:18:35] [V] [TRT] Tactic: 4501471010995462441 Time: 0.128268\n",
      "[04/10/2022-15:18:35] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_4/add Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826\n",
      "[04/10/2022-15:18:35] [V] [TRT] Tactic: 5137655947464784826 Time: 0.137682\n",
      "[04/10/2022-15:18:35] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_4/add Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929\n",
      "[04/10/2022-15:18:35] [V] [TRT] Tactic: 5288347012147084929 Time: 0.131608\n",
      "[04/10/2022-15:18:35] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_4/add Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011\n",
      "[04/10/2022-15:18:35] [V] [TRT] Tactic: 5326823351883942011 Time: 0.125176\n",
      "[04/10/2022-15:18:35] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_4/add Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314\n",
      "[04/10/2022-15:18:35] [V] [TRT] Tactic: 5500448035057547314 Time: 0.138464\n",
      "[04/10/2022-15:18:35] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_4/add Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056\n",
      "[04/10/2022-15:18:35] [V] [TRT] Tactic: 6645123197870846056 Time: 0.136784\n",
      "[04/10/2022-15:18:35] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_4/add Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478\n",
      "[04/10/2022-15:18:35] [V] [TRT] Tactic: 7144526460361122478 Time: 0.192259\n",
      "[04/10/2022-15:18:35] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_4/add Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730\n",
      "[04/10/2022-15:18:35] [V] [TRT] Tactic: -8262349710178828730 Time: 0.133887\n",
      "[04/10/2022-15:18:35] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_4/add Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580\n",
      "[04/10/2022-15:18:35] [V] [TRT] Tactic: -6576203419454146580 Time: 0.158867\n",
      "[04/10/2022-15:18:35] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_4/add Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159\n",
      "[04/10/2022-15:18:35] [V] [TRT] Tactic: -4787320710726427159 Time: 0.20112\n",
      "[04/10/2022-15:18:35] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_4/add Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839\n",
      "[04/10/2022-15:18:35] [V] [TRT] Tactic: -3456450830548107839 Time: 0.165137\n",
      "[04/10/2022-15:18:35] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_4/add Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241\n",
      "[04/10/2022-15:18:35] [V] [TRT] Tactic: -1218658103698133241 Time: 0.144499\n",
      "[04/10/2022-15:18:35] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_4/add Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091\n",
      "[04/10/2022-15:18:35] [V] [TRT] Tactic: -836875257600482091 Time: 0.141224\n",
      "[04/10/2022-15:18:35] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_4/add Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746\n",
      "[04/10/2022-15:18:35] [V] [TRT] Tactic: -410470605513481746 Time: 0.126315\n",
      "[04/10/2022-15:18:35] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_4/add Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884\n",
      "[04/10/2022-15:18:35] [V] [TRT] Tactic: -377491875521947884 Time: 0.128105\n",
      "[04/10/2022-15:18:35] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_4/add Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163\n",
      "[04/10/2022-15:18:35] [V] [TRT] Tactic: -37215280111360163 Time: 0.132877\n",
      "[04/10/2022-15:18:35] [V] [TRT] Fastest Tactic: 5326823351883942011 Time: 0.125176\n",
      "[04/10/2022-15:18:35] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 5326823351883942011\n",
      "[04/10/2022-15:18:35] [V] [TRT] *************** Autotuning format combination: Float(100352,1,3584,128), Float(50176,1,3584,256) -> Float(50176,1,3584,256) ***************\n",
      "[04/10/2022-15:18:35] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage3_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_4/add (CudnnConvolution)\n",
      "[04/10/2022-15:18:35] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:18:35] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage3_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_4/add (CaskConvolution)\n",
      "[04/10/2022-15:18:35] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_4/add Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788\n",
      "[04/10/2022-15:18:35] [V] [TRT] Tactic: 3886731678879822788 Time: 0.13543\n",
      "[04/10/2022-15:18:35] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_4/add Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200\n",
      "[04/10/2022-15:18:35] [V] [TRT] Tactic: 6629944304117643200 Time: 0.265007\n",
      "[04/10/2022-15:18:35] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_4/add Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824\n",
      "[04/10/2022-15:18:35] [V] [TRT] Tactic: -9153228964338181824 Time: 0.267604\n",
      "[04/10/2022-15:18:35] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_4/add Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025\n",
      "[04/10/2022-15:18:35] [V] [TRT] Tactic: -7394439838318485025 Time: 0.137851\n",
      "[04/10/2022-15:18:35] [V] [TRT] Fastest Tactic: 3886731678879822788 Time: 0.13543\n",
      "[04/10/2022-15:18:35] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 3886731678879822788\n",
      "[04/10/2022-15:18:35] [V] [TRT] *************** Autotuning format combination: Half(100352,784,28,1), Half(50176,196,14,1) -> Half(50176,196,14,1) ***************\n",
      "[04/10/2022-15:18:35] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage3_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_4/add (CudnnConvolution)\n",
      "[04/10/2022-15:18:35] [V] [TRT] Tactic: 0 Time: 0.263939\n",
      "[04/10/2022-15:18:35] [V] [TRT] Tactic: 1 Time: 0.245638\n",
      "[04/10/2022-15:18:35] [V] [TRT] Tactic: 2 Time: 0.325339\n",
      "[04/10/2022-15:18:35] [V] [TRT] Fastest Tactic: 1 Time: 0.245638\n",
      "[04/10/2022-15:18:35] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage3_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_4/add (CaskConvolution)\n",
      "[04/10/2022-15:18:35] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:18:35] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 1\n",
      "[04/10/2022-15:18:35] [V] [TRT] *************** Autotuning format combination: Half(50176,784:2,28,1), Half(25088,196:2,14,1) -> Half(25088,196:2,14,1) ***************\n",
      "[04/10/2022-15:18:35] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage3_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_4/add (FusedConvActConvolution)\n",
      "[04/10/2022-15:18:35] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:18:35] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage3_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_4/add (CudnnConvolution)\n",
      "[04/10/2022-15:18:35] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:18:35] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage3_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_4/add (CaskConvolution)\n",
      "[04/10/2022-15:18:35] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_4/add Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_interior_nn_v1 Tactic: 3066127711859985668\n",
      "[04/10/2022-15:18:35] [V] [TRT] Tactic: 3066127711859985668 Time: 0.0835937\n",
      "[04/10/2022-15:18:35] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_4/add Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998\n",
      "[04/10/2022-15:18:35] [V] [TRT] Tactic: 3564772625446233998 Time: 0.0897005\n",
      "[04/10/2022-15:18:35] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_4/add Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452\n",
      "[04/10/2022-15:18:35] [V] [TRT] Tactic: 5319956359050645452 Time: 0.0853384\n",
      "[04/10/2022-15:18:35] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_4/add Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848\n",
      "[04/10/2022-15:18:35] [V] [TRT] Tactic: 7205456024582378848 Time: 0.0746809\n",
      "[04/10/2022-15:18:35] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_4/add Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 8163473458334948789\n",
      "[04/10/2022-15:18:35] [V] [TRT] Tactic: 8163473458334948789 Time: 0.0728187\n",
      "[04/10/2022-15:18:35] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_4/add Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890\n",
      "[04/10/2022-15:18:35] [V] [TRT] Tactic: -4212163711445252890 Time: 0.0703971\n",
      "[04/10/2022-15:18:35] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_4/add Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110\n",
      "[04/10/2022-15:18:35] [V] [TRT] Tactic: -3898373634979201110 Time: 0.0713149\n",
      "[04/10/2022-15:18:35] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_4/add Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473\n",
      "[04/10/2022-15:18:35] [V] [TRT] Tactic: -2409163523992614473 Time: 0.0729296\n",
      "[04/10/2022-15:18:35] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit1_sc/Conv2D + StatefulPartitionedCall/model_1/add_4/add Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322\n",
      "[04/10/2022-15:18:35] [V] [TRT] Tactic: -1716393687483585322 Time: 0.0697006\n",
      "[04/10/2022-15:18:35] [V] [TRT] Fastest Tactic: -1716393687483585322 Time: 0.0697006\n",
      "[04/10/2022-15:18:35] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -1716393687483585322\n",
      "[04/10/2022-15:18:35] [V] [TRT] *************** Autotuning Reformat:Float(50176,196,14,1) -> Float(50176,1,3584,256) ***************\n",
      "[04/10/2022-15:18:35] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:18:35] [V] [TRT] Tactic: 1002 Time: 0.0748372\n",
      "[04/10/2022-15:18:35] [V] [TRT] Tactic: 0 Time: 0.0826626\n",
      "[04/10/2022-15:18:35] [V] [TRT] Fastest Tactic: 1002 Time: 0.0748372\n",
      "[04/10/2022-15:18:35] [V] [TRT] *************** Autotuning Reformat:Float(50176,196,14,1) -> Half(50176,196,14,1) ***************\n",
      "[04/10/2022-15:18:35] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:18:35] [V] [TRT] Tactic: 1002 Time: 1.36052\n",
      "[04/10/2022-15:18:35] [V] [TRT] Tactic: 0 Time: 0.0595377\n",
      "[04/10/2022-15:18:35] [V] [TRT] Fastest Tactic: 0 Time: 0.0595377\n",
      "[04/10/2022-15:18:35] [V] [TRT] *************** Autotuning Reformat:Float(50176,196,14,1) -> Half(25088,196:2,14,1) ***************\n",
      "[04/10/2022-15:18:35] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:18:35] [V] [TRT] Tactic: 1002 Time: 0.0876759\n",
      "[04/10/2022-15:18:35] [V] [TRT] Tactic: 0 Time: 0.0468425\n",
      "[04/10/2022-15:18:35] [V] [TRT] Fastest Tactic: 0 Time: 0.0468425\n",
      "[04/10/2022-15:18:35] [V] [TRT] *************** Autotuning Reformat:Float(50176,1,3584,256) -> Float(50176,196,14,1) ***************\n",
      "[04/10/2022-15:18:35] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:18:35] [V] [TRT] Tactic: 1002 Time: 0.0935611\n",
      "[04/10/2022-15:18:35] [V] [TRT] Tactic: 0 Time: 0.0784897\n",
      "[04/10/2022-15:18:35] [V] [TRT] Fastest Tactic: 0 Time: 0.0784897\n",
      "[04/10/2022-15:18:35] [V] [TRT] *************** Autotuning Reformat:Float(50176,1,3584,256) -> Half(50176,196,14,1) ***************\n",
      "[04/10/2022-15:18:35] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:18:35] [V] [TRT] Tactic: 1002 Time: 0.0637175\n",
      "[04/10/2022-15:18:35] [V] [TRT] Tactic: 0 Time: 0.0772524\n",
      "[04/10/2022-15:18:35] [V] [TRT] Fastest Tactic: 1002 Time: 0.0637175\n",
      "[04/10/2022-15:18:35] [V] [TRT] *************** Autotuning Reformat:Float(50176,1,3584,256) -> Half(25088,196:2,14,1) ***************\n",
      "[04/10/2022-15:18:35] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:18:35] [V] [TRT] Tactic: 1002 Time: 0.0756966\n",
      "[04/10/2022-15:18:35] [V] [TRT] Tactic: 0 Time: 0.0905729\n",
      "[04/10/2022-15:18:35] [V] [TRT] Fastest Tactic: 1002 Time: 0.0756966\n",
      "[04/10/2022-15:18:35] [V] [TRT] *************** Autotuning Reformat:Half(50176,196,14,1) -> Float(50176,196,14,1) ***************\n",
      "[04/10/2022-15:18:35] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:18:35] [V] [TRT] Tactic: 1002 Time: 1.40008\n",
      "[04/10/2022-15:18:35] [V] [TRT] Tactic: 0 Time: 0.0502149\n",
      "[04/10/2022-15:18:35] [V] [TRT] Fastest Tactic: 0 Time: 0.0502149\n",
      "[04/10/2022-15:18:35] [V] [TRT] *************** Autotuning Reformat:Half(50176,196,14,1) -> Float(50176,1,3584,256) ***************\n",
      "[04/10/2022-15:18:35] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:18:35] [V] [TRT] Tactic: 1002 Time: 0.0578971\n",
      "[04/10/2022-15:18:35] [V] [TRT] Tactic: 0 Time: 0.0827992\n",
      "[04/10/2022-15:18:35] [V] [TRT] Fastest Tactic: 1002 Time: 0.0578971\n",
      "[04/10/2022-15:18:35] [V] [TRT] *************** Autotuning Reformat:Half(50176,196,14,1) -> Half(25088,196:2,14,1) ***************\n",
      "[04/10/2022-15:18:35] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:18:35] [V] [TRT] Tactic: 1002 Time: 0.0624676\n",
      "[04/10/2022-15:18:35] [V] [TRT] Tactic: 0 Time: 0.0460026\n",
      "[04/10/2022-15:18:35] [V] [TRT] Fastest Tactic: 0 Time: 0.0460026\n",
      "[04/10/2022-15:18:35] [V] [TRT] *************** Autotuning Reformat:Half(25088,196:2,14,1) -> Float(50176,196,14,1) ***************\n",
      "[04/10/2022-15:18:35] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:18:35] [V] [TRT] Tactic: 1002 Time: 0.0828713\n",
      "[04/10/2022-15:18:35] [V] [TRT] Tactic: 0 Time: 0.0415039\n",
      "[04/10/2022-15:18:35] [V] [TRT] Fastest Tactic: 0 Time: 0.0415039\n",
      "[04/10/2022-15:18:35] [V] [TRT] *************** Autotuning Reformat:Half(25088,196:2,14,1) -> Float(50176,1,3584,256) ***************\n",
      "[04/10/2022-15:18:35] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:18:35] [V] [TRT] Tactic: 1002 Time: 0.0583854\n",
      "[04/10/2022-15:18:35] [V] [TRT] Tactic: 0 Time: 0.0954686\n",
      "[04/10/2022-15:18:35] [V] [TRT] Fastest Tactic: 1002 Time: 0.0583854\n",
      "[04/10/2022-15:18:35] [V] [TRT] *************** Autotuning Reformat:Half(25088,196:2,14,1) -> Half(50176,196,14,1) ***************\n",
      "[04/10/2022-15:18:35] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:18:35] [V] [TRT] Tactic: 1002 Time: 0.110827\n",
      "[04/10/2022-15:18:35] [V] [TRT] Tactic: 0 Time: 0.0391014\n",
      "[04/10/2022-15:18:35] [V] [TRT] Fastest Tactic: 0 Time: 0.0391014\n",
      "[04/10/2022-15:18:35] [V] [TRT] *************** Autotuning Reformat:Float(50176,196,14,1) -> Float(50176,1,3584,256) ***************\n",
      "[04/10/2022-15:18:35] [V] [TRT] *************** Autotuning Reformat:Float(50176,196,14,1) -> Half(50176,196,14,1) ***************\n",
      "[04/10/2022-15:18:35] [V] [TRT] *************** Autotuning Reformat:Float(50176,196,14,1) -> Half(25088,196:2,14,1) ***************\n",
      "[04/10/2022-15:18:35] [V] [TRT] *************** Autotuning Reformat:Float(50176,1,3584,256) -> Float(50176,196,14,1) ***************\n",
      "[04/10/2022-15:18:35] [V] [TRT] *************** Autotuning Reformat:Float(50176,1,3584,256) -> Half(50176,196,14,1) ***************\n",
      "[04/10/2022-15:18:35] [V] [TRT] *************** Autotuning Reformat:Float(50176,1,3584,256) -> Half(25088,196:2,14,1) ***************\n",
      "[04/10/2022-15:18:35] [V] [TRT] *************** Autotuning Reformat:Half(50176,196,14,1) -> Float(50176,196,14,1) ***************\n",
      "[04/10/2022-15:18:35] [V] [TRT] *************** Autotuning Reformat:Half(50176,196,14,1) -> Float(50176,1,3584,256) ***************\n",
      "[04/10/2022-15:18:35] [V] [TRT] *************** Autotuning Reformat:Half(50176,196,14,1) -> Half(25088,196:2,14,1) ***************\n",
      "[04/10/2022-15:18:35] [V] [TRT] *************** Autotuning Reformat:Half(25088,196:2,14,1) -> Float(50176,196,14,1) ***************\n",
      "[04/10/2022-15:18:35] [V] [TRT] *************** Autotuning Reformat:Half(25088,196:2,14,1) -> Float(50176,1,3584,256) ***************\n",
      "[04/10/2022-15:18:35] [V] [TRT] *************** Autotuning Reformat:Half(25088,196:2,14,1) -> Half(50176,196,14,1) ***************\n",
      "[04/10/2022-15:18:35] [V] [TRT] *************** Autotuning format combination: Float(50176,196,14,1) -> Float(50176,196,14,1) ***************\n",
      "[04/10/2022-15:18:35] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage3_unit2_bn1/FusedBatchNormV3 + StatefulPartitionedCall/model_1/stage3_unit2_relu1/Relu (Scale)\n",
      "[04/10/2022-15:18:35] [V] [TRT] Tactic: 0 Time: 0.0388866\n",
      "[04/10/2022-15:18:35] [V] [TRT] Fastest Tactic: 0 Time: 0.0388866\n",
      "[04/10/2022-15:18:35] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Scale Tactic: 0\n",
      "[04/10/2022-15:18:35] [V] [TRT] *************** Autotuning format combination: Float(50176,1,3584,256) -> Float(50176,1,3584,256) ***************\n",
      "[04/10/2022-15:18:35] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage3_unit2_bn1/FusedBatchNormV3 + StatefulPartitionedCall/model_1/stage3_unit2_relu1/Relu (Scale)\n",
      "[04/10/2022-15:18:35] [V] [TRT] Scale has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:18:35] [V] [TRT] *************** Autotuning format combination: Half(50176,196,14,1) -> Half(50176,196,14,1) ***************\n",
      "[04/10/2022-15:18:35] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage3_unit2_bn1/FusedBatchNormV3 + StatefulPartitionedCall/model_1/stage3_unit2_relu1/Relu (Scale)\n",
      "[04/10/2022-15:18:35] [V] [TRT] Tactic: 0 Time: 0.0341929\n",
      "[04/10/2022-15:18:35] [V] [TRT] Fastest Tactic: 0 Time: 0.0341929\n",
      "[04/10/2022-15:18:35] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Scale Tactic: 0\n",
      "[04/10/2022-15:18:35] [V] [TRT] *************** Autotuning format combination: Half(25088,196:2,14,1) -> Half(25088,196:2,14,1) ***************\n",
      "[04/10/2022-15:18:35] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage3_unit2_bn1/FusedBatchNormV3 + StatefulPartitionedCall/model_1/stage3_unit2_relu1/Relu (Scale)\n",
      "[04/10/2022-15:18:35] [V] [TRT] Tactic: 0 Time: 0.0435416\n",
      "[04/10/2022-15:18:35] [V] [TRT] Fastest Tactic: 0 Time: 0.0435416\n",
      "[04/10/2022-15:18:35] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Scale Tactic: 0\n",
      "[04/10/2022-15:18:35] [V] [TRT] *************** Autotuning Reformat:Float(50176,196,14,1) -> Float(50176,1,3584,256) ***************\n",
      "[04/10/2022-15:18:35] [V] [TRT] *************** Autotuning Reformat:Float(50176,196,14,1) -> Half(50176,196,14,1) ***************\n",
      "[04/10/2022-15:18:35] [V] [TRT] *************** Autotuning Reformat:Float(50176,196,14,1) -> Half(25088,196:2,14,1) ***************\n",
      "[04/10/2022-15:18:35] [V] [TRT] *************** Autotuning Reformat:Float(50176,1,3584,256) -> Float(50176,196,14,1) ***************\n",
      "[04/10/2022-15:18:35] [V] [TRT] *************** Autotuning Reformat:Float(50176,1,3584,256) -> Half(50176,196,14,1) ***************\n",
      "[04/10/2022-15:18:35] [V] [TRT] *************** Autotuning Reformat:Float(50176,1,3584,256) -> Half(25088,196:2,14,1) ***************\n",
      "[04/10/2022-15:18:35] [V] [TRT] *************** Autotuning Reformat:Half(50176,196,14,1) -> Float(50176,196,14,1) ***************\n",
      "[04/10/2022-15:18:35] [V] [TRT] *************** Autotuning Reformat:Half(50176,196,14,1) -> Float(50176,1,3584,256) ***************\n",
      "[04/10/2022-15:18:35] [V] [TRT] *************** Autotuning Reformat:Half(50176,196,14,1) -> Half(25088,196:2,14,1) ***************\n",
      "[04/10/2022-15:18:35] [V] [TRT] *************** Autotuning Reformat:Half(25088,196:2,14,1) -> Float(50176,196,14,1) ***************\n",
      "[04/10/2022-15:18:35] [V] [TRT] *************** Autotuning Reformat:Half(25088,196:2,14,1) -> Float(50176,1,3584,256) ***************\n",
      "[04/10/2022-15:18:35] [V] [TRT] *************** Autotuning Reformat:Half(25088,196:2,14,1) -> Half(50176,196,14,1) ***************\n",
      "[04/10/2022-15:18:35] [V] [TRT] *************** Autotuning format combination: Float(50176,196,14,1) -> Float(50176,196,14,1) ***************\n",
      "[04/10/2022-15:18:35] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage3_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit2_relu2/Relu (CudaDepthwiseConvolution)\n",
      "[04/10/2022-15:18:35] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:18:35] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage3_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit2_relu2/Relu (FusedConvActConvolution)\n",
      "[04/10/2022-15:18:36] [V] [TRT] Tactic: 524287 Time: 1.58529\n",
      "[04/10/2022-15:18:36] [V] [TRT] Tactic: 720895 Time: 1.70475\n",
      "[04/10/2022-15:18:36] [V] [TRT] Tactic: 983039 Time: 1.46572\n",
      "[04/10/2022-15:18:36] [V] [TRT] Tactic: 1048575 Time: 1.60557\n",
      "[04/10/2022-15:18:36] [V] [TRT] Tactic: 1703935 Time: 1.6139\n",
      "[04/10/2022-15:18:36] [V] [TRT] Tactic: 1769471 Time: 1.46559\n",
      "[04/10/2022-15:18:36] [V] [TRT] Tactic: 1966079 Time: 1.56615\n",
      "[04/10/2022-15:18:36] [V] [TRT] Tactic: 2031615 Time: 1.6109\n",
      "[04/10/2022-15:18:36] [V] [TRT] Tactic: 2228223 Time: 2.04667\n",
      "[04/10/2022-15:18:36] [V] [TRT] Tactic: 2424831 Time: 2.20471\n",
      "[04/10/2022-15:18:37] [V] [TRT] Tactic: 2621439 Time: 1.88199\n",
      "[04/10/2022-15:18:37] [V] [TRT] Tactic: 2752511 Time: 1.38677\n",
      "[04/10/2022-15:18:37] [V] [TRT] Tactic: 2818047 Time: 1.86917\n",
      "[04/10/2022-15:18:37] [V] [TRT] Tactic: 2883583 Time: 1.53057\n",
      "[04/10/2022-15:18:37] [V] [TRT] Tactic: 3014655 Time: 1.47378\n",
      "[04/10/2022-15:18:37] [V] [TRT] Tactic: 3145727 Time: 1.38335\n",
      "[04/10/2022-15:18:37] [V] [TRT] Tactic: 3473407 Time: 1.59633\n",
      "[04/10/2022-15:18:37] [V] [TRT] Tactic: 3604479 Time: 1.46511\n",
      "[04/10/2022-15:18:37] [V] [TRT] Tactic: 3735551 Time: 1.93043\n",
      "[04/10/2022-15:18:37] [V] [TRT] Tactic: 4390911 Time: 1.42612\n",
      "[04/10/2022-15:18:38] [V] [TRT] Tactic: 5046271 Time: 1.57685\n",
      "[04/10/2022-15:18:38] [V] [TRT] Tactic: 5963775 Time: 1.39613\n",
      "[04/10/2022-15:18:38] [V] [TRT] Tactic: 6160383 Time: 1.54989\n",
      "[04/10/2022-15:18:38] [V] [TRT] Tactic: 6488063 Time: 1.34449\n",
      "[04/10/2022-15:18:38] [V] [TRT] Tactic: 6881279 Time: 1.38178\n",
      "[04/10/2022-15:18:38] [V] [TRT] Tactic: 7274495 Time: 1.85661\n",
      "[04/10/2022-15:18:38] [V] [TRT] Tactic: 7864319 Time: 1.96979\n",
      "[04/10/2022-15:18:38] [V] [TRT] Tactic: 7995391 Time: 1.67398\n",
      "[04/10/2022-15:18:38] [V] [TRT] Tactic: 8585215 Time: 1.41888\n",
      "[04/10/2022-15:18:38] [V] [TRT] Tactic: 8847359 Time: 1.44826\n",
      "[04/10/2022-15:18:39] [V] [TRT] Tactic: 8978431 Time: 1.4064\n",
      "[04/10/2022-15:18:39] [V] [TRT] Tactic: 9043967 Time: 1.35594\n",
      "[04/10/2022-15:18:39] [V] [TRT] Tactic: 9175039 Time: 1.46523\n",
      "[04/10/2022-15:18:39] [V] [TRT] Tactic: 9502719 Time: 1.44245\n",
      "[04/10/2022-15:18:39] [V] [TRT] Tactic: 9830399 Time: 1.45557\n",
      "[04/10/2022-15:18:39] [V] [TRT] Tactic: 9961471 Time: 1.592\n",
      "[04/10/2022-15:18:39] [V] [TRT] Tactic: 10027007 Time: 1.42233\n",
      "[04/10/2022-15:18:39] [V] [TRT] Tactic: 10092543 Time: 1.42232\n",
      "[04/10/2022-15:18:39] [V] [TRT] Tactic: 10289151 Time: 1.56801\n",
      "[04/10/2022-15:18:39] [V] [TRT] Tactic: 10485759 Time: 1.41926\n",
      "[04/10/2022-15:18:40] [V] [TRT] Tactic: 10682367 Time: 1.91545\n",
      "[04/10/2022-15:18:40] [V] [TRT] Tactic: 10813439 Time: 1.6796\n",
      "[04/10/2022-15:18:40] [V] [TRT] Fastest Tactic: 6488063 Time: 1.34449\n",
      "[04/10/2022-15:18:40] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage3_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit2_relu2/Relu (CudnnConvolution)\n",
      "[04/10/2022-15:18:40] [V] [TRT] Tactic: 0 Time: 3.00717\n",
      "[04/10/2022-15:18:40] [V] [TRT] Tactic: 1 Time: 1.78854\n",
      "[04/10/2022-15:18:40] [V] [TRT] Tactic: 2 Time: 2.54719\n",
      "[04/10/2022-15:18:40] [V] [TRT] Tactic: 4 Time: 15.6114\n",
      "[04/10/2022-15:18:40] [V] [TRT] Tactic: 5 skipped. Scratch requested: 287440896, available: 268435456\n",
      "[04/10/2022-15:18:40] [V] [TRT] Tactic: 6 Time: 1.39528\n",
      "[04/10/2022-15:18:40] [V] [TRT] Fastest Tactic: 6 Time: 1.39528\n",
      "[04/10/2022-15:18:40] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage3_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit2_relu2/Relu (CaskConvolution)\n",
      "[04/10/2022-15:18:40] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit2_relu2/Relu Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758\n",
      "[04/10/2022-15:18:40] [V] [TRT] Tactic: 1062367460111450758 Time: 2.03186\n",
      "[04/10/2022-15:18:40] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit2_relu2/Relu Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v0 Tactic: 1754984623894446479\n",
      "[04/10/2022-15:18:40] [V] [TRT] Tactic: 1754984623894446479 Time: 2.60047\n",
      "[04/10/2022-15:18:40] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit2_relu2/Relu Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v0 Tactic: 3611739942397549984\n",
      "[04/10/2022-15:18:40] [V] [TRT] Tactic: 3611739942397549984 Time: 1.56357\n",
      "[04/10/2022-15:18:40] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit2_relu2/Relu Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v1 Tactic: 3827454225649558724\n",
      "[04/10/2022-15:18:40] [V] [TRT] Tactic: 3827454225649558724 Time: 1.17031\n",
      "[04/10/2022-15:18:40] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit2_relu2/Relu Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379\n",
      "[04/10/2022-15:18:40] [V] [TRT] Tactic: 4337000649858996379 Time: 1.59712\n",
      "[04/10/2022-15:18:40] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit2_relu2/Relu Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441\n",
      "[04/10/2022-15:18:41] [V] [TRT] Tactic: 4501471010995462441 Time: 1.56494\n",
      "[04/10/2022-15:18:41] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit2_relu2/Relu Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826\n",
      "[04/10/2022-15:18:41] [V] [TRT] Tactic: 5137655947464784826 Time: 1.51778\n",
      "[04/10/2022-15:18:41] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit2_relu2/Relu Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929\n",
      "[04/10/2022-15:18:41] [V] [TRT] Tactic: 5288347012147084929 Time: 1.52404\n",
      "[04/10/2022-15:18:41] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit2_relu2/Relu Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 5921334924264294896\n",
      "[04/10/2022-15:18:41] [V] [TRT] Tactic: 5921334924264294896 Time: 0.913405\n",
      "[04/10/2022-15:18:41] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit2_relu2/Relu Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056\n",
      "[04/10/2022-15:18:41] [V] [TRT] Tactic: 6645123197870846056 Time: 1.5735\n",
      "[04/10/2022-15:18:41] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit2_relu2/Relu Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478\n",
      "[04/10/2022-15:18:41] [V] [TRT] Tactic: 7144526460361122478 Time: 2.22883\n",
      "[04/10/2022-15:18:41] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit2_relu2/Relu Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: 7852627285308570038\n",
      "[04/10/2022-15:18:41] [V] [TRT] Tactic: 7852627285308570038 Time: 1.14835\n",
      "[04/10/2022-15:18:41] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit2_relu2/Relu Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713\n",
      "[04/10/2022-15:18:41] [V] [TRT] Tactic: -9137461792520977713 Time: 1.57426\n",
      "[04/10/2022-15:18:41] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit2_relu2/Relu Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v0 Tactic: -8776506421218919509\n",
      "[04/10/2022-15:18:41] [V] [TRT] Tactic: -8776506421218919509 Time: 1.10962\n",
      "[04/10/2022-15:18:41] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit2_relu2/Relu Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730\n",
      "[04/10/2022-15:18:41] [V] [TRT] Tactic: -8262349710178828730 Time: 1.57293\n",
      "[04/10/2022-15:18:41] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit2_relu2/Relu Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v0 Tactic: -8133971918129952780\n",
      "[04/10/2022-15:18:41] [V] [TRT] Tactic: -8133971918129952780 Time: 1.70995\n",
      "[04/10/2022-15:18:41] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit2_relu2/Relu Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144\n",
      "[04/10/2022-15:18:41] [V] [TRT] Tactic: -6092040395344634144 Time: 2.12523\n",
      "[04/10/2022-15:18:41] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit2_relu2/Relu Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159\n",
      "[04/10/2022-15:18:41] [V] [TRT] Tactic: -4787320710726427159 Time: 2.59094\n",
      "[04/10/2022-15:18:41] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit2_relu2/Relu Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839\n",
      "[04/10/2022-15:18:41] [V] [TRT] Tactic: -3456450830548107839 Time: 1.7896\n",
      "[04/10/2022-15:18:41] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit2_relu2/Relu Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v0 Tactic: -2318106587342035239\n",
      "[04/10/2022-15:18:41] [V] [TRT] Tactic: -2318106587342035239 Time: 1.11051\n",
      "[04/10/2022-15:18:41] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit2_relu2/Relu Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_mobile_relu_tile148t_nt_v0 Tactic: -1343271414618805657\n",
      "[04/10/2022-15:18:41] [V] [TRT] Tactic: -1343271414618805657 Time: 0.835853\n",
      "[04/10/2022-15:18:41] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit2_relu2/Relu Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241\n",
      "[04/10/2022-15:18:41] [V] [TRT] Tactic: -1218658103698133241 Time: 1.70357\n",
      "[04/10/2022-15:18:41] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit2_relu2/Relu Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091\n",
      "[04/10/2022-15:18:41] [V] [TRT] Tactic: -836875257600482091 Time: 1.6391\n",
      "[04/10/2022-15:18:41] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit2_relu2/Relu Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746\n",
      "[04/10/2022-15:18:41] [V] [TRT] Tactic: -410470605513481746 Time: 1.50072\n",
      "[04/10/2022-15:18:41] [V] [TRT] Fastest Tactic: -1343271414618805657 Time: 0.835853\n",
      "[04/10/2022-15:18:41] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -1343271414618805657\n",
      "[04/10/2022-15:18:41] [V] [TRT] *************** Autotuning format combination: Float(50176,1,3584,256) -> Float(50176,1,3584,256) ***************\n",
      "[04/10/2022-15:18:41] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage3_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit2_relu2/Relu (CudnnConvolution)\n",
      "[04/10/2022-15:18:41] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:18:41] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage3_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit2_relu2/Relu (CaskConvolution)\n",
      "[04/10/2022-15:18:41] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit2_relu2/Relu Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824\n",
      "[04/10/2022-15:18:41] [V] [TRT] Tactic: -9153228964338181824 Time: 1.83718\n",
      "[04/10/2022-15:18:41] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit2_relu2/Relu Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025\n",
      "[04/10/2022-15:18:41] [V] [TRT] Tactic: -7394439838318485025 Time: 1.49287\n",
      "[04/10/2022-15:18:41] [V] [TRT] Fastest Tactic: -7394439838318485025 Time: 1.49287\n",
      "[04/10/2022-15:18:41] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7394439838318485025\n",
      "[04/10/2022-15:18:41] [V] [TRT] *************** Autotuning format combination: Half(50176,196,14,1) -> Half(50176,196,14,1) ***************\n",
      "[04/10/2022-15:18:41] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage3_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit2_relu2/Relu (CudnnConvolution)\n",
      "[04/10/2022-15:18:41] [V] [TRT] Tactic: 0 Time: 2.96357\n",
      "[04/10/2022-15:18:42] [V] [TRT] Tactic: 1 Time: 1.93313\n",
      "[04/10/2022-15:18:42] [V] [TRT] Tactic: 2 Time: 2.48903\n",
      "[04/10/2022-15:18:42] [V] [TRT] Tactic: 4 Time: 16.885\n",
      "[04/10/2022-15:18:42] [V] [TRT] Tactic: 5 skipped. Scratch requested: 287440896, available: 268435456\n",
      "[04/10/2022-15:18:42] [V] [TRT] Tactic: 6 Time: 2.65539\n",
      "[04/10/2022-15:18:42] [V] [TRT] Fastest Tactic: 1 Time: 1.93313\n",
      "[04/10/2022-15:18:42] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage3_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit2_relu2/Relu (CaskConvolution)\n",
      "[04/10/2022-15:18:42] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:18:42] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 1\n",
      "[04/10/2022-15:18:42] [V] [TRT] *************** Autotuning format combination: Half(25088,196:2,14,1) -> Half(25088,196:2,14,1) ***************\n",
      "[04/10/2022-15:18:42] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage3_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit2_relu2/Relu (FusedConvActConvolution)\n",
      "[04/10/2022-15:18:42] [V] [TRT] Tactic: 524287 Time: 0.851673\n",
      "[04/10/2022-15:18:42] [V] [TRT] Tactic: 720895 Time: 0.960345\n",
      "[04/10/2022-15:18:42] [V] [TRT] Tactic: 983039 Time: 0.809629\n",
      "[04/10/2022-15:18:42] [V] [TRT] Tactic: 1048575 Time: 0.889648\n",
      "[04/10/2022-15:18:42] [V] [TRT] Tactic: 1703935 Time: 0.902239\n",
      "[04/10/2022-15:18:43] [V] [TRT] Tactic: 1769471 Time: 5.27116\n",
      "[04/10/2022-15:18:43] [V] [TRT] Tactic: 1966079 Time: 0.941641\n",
      "[04/10/2022-15:18:43] [V] [TRT] Tactic: 2031615 Time: 0.834167\n",
      "[04/10/2022-15:18:43] [V] [TRT] Tactic: 2228223 Time: 1.09998\n",
      "[04/10/2022-15:18:43] [V] [TRT] Tactic: 2424831 Time: 1.64462\n",
      "[04/10/2022-15:18:43] [V] [TRT] Tactic: 2621439 Time: 0.999759\n",
      "[04/10/2022-15:18:43] [V] [TRT] Tactic: 2752511 Time: 0.731517\n",
      "[04/10/2022-15:18:43] [V] [TRT] Tactic: 2818047 Time: 1.03024\n",
      "[04/10/2022-15:18:43] [V] [TRT] Tactic: 2883583 Time: 0.894082\n",
      "[04/10/2022-15:18:43] [V] [TRT] Tactic: 3014655 Time: 0.830287\n",
      "[04/10/2022-15:18:43] [V] [TRT] Tactic: 3145727 Time: 0.771172\n",
      "[04/10/2022-15:18:43] [V] [TRT] Tactic: 3473407 Time: 0.9275\n",
      "[04/10/2022-15:18:43] [V] [TRT] Tactic: 3604479 Time: 0.820443\n",
      "[04/10/2022-15:18:43] [V] [TRT] Tactic: 3735551 Time: 0.931081\n",
      "[04/10/2022-15:18:44] [V] [TRT] Tactic: 4390911 Time: 0.762122\n",
      "[04/10/2022-15:18:44] [V] [TRT] Tactic: 5046271 Time: 0.836589\n",
      "[04/10/2022-15:18:44] [V] [TRT] Tactic: 5963775 Time: 0.783874\n",
      "[04/10/2022-15:18:44] [V] [TRT] Tactic: 6160383 Time: 0.892318\n",
      "[04/10/2022-15:18:44] [V] [TRT] Tactic: 6488063 Time: 0.750625\n",
      "[04/10/2022-15:18:44] [V] [TRT] Tactic: 6881279 Time: 0.769844\n",
      "[04/10/2022-15:18:44] [V] [TRT] Tactic: 7274495 Time: 1.06353\n",
      "[04/10/2022-15:18:44] [V] [TRT] Tactic: 7864319 Time: 1.07391\n",
      "[04/10/2022-15:18:44] [V] [TRT] Tactic: 7995391 Time: 0.96513\n",
      "[04/10/2022-15:18:44] [V] [TRT] Tactic: 8585215 Time: 0.801934\n",
      "[04/10/2022-15:18:44] [V] [TRT] Tactic: 8847359 Time: 0.776061\n",
      "[04/10/2022-15:18:44] [V] [TRT] Tactic: 8978431 Time: 0.8286\n",
      "[04/10/2022-15:18:44] [V] [TRT] Tactic: 9043967 Time: 0.727344\n",
      "[04/10/2022-15:18:44] [V] [TRT] Tactic: 9175039 Time: 0.820612\n",
      "[04/10/2022-15:18:44] [V] [TRT] Tactic: 9502719 Time: 0.739642\n",
      "[04/10/2022-15:18:44] [V] [TRT] Tactic: 9830399 Time: 0.779004\n",
      "[04/10/2022-15:18:44] [V] [TRT] Tactic: 9961471 Time: 0.892312\n",
      "[04/10/2022-15:18:45] [V] [TRT] Tactic: 10027007 Time: 0.762057\n",
      "[04/10/2022-15:18:45] [V] [TRT] Tactic: 10092543 Time: 0.765736\n",
      "[04/10/2022-15:18:45] [V] [TRT] Tactic: 10289151 Time: 0.939381\n",
      "[04/10/2022-15:18:45] [V] [TRT] Tactic: 10485759 Time: 0.752975\n",
      "[04/10/2022-15:18:45] [V] [TRT] Tactic: 10682367 Time: 0.98457\n",
      "[04/10/2022-15:18:45] [V] [TRT] Tactic: 10813439 Time: 0.986849\n",
      "[04/10/2022-15:18:45] [V] [TRT] Fastest Tactic: 9043967 Time: 0.727344\n",
      "[04/10/2022-15:18:45] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage3_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit2_relu2/Relu (CudnnConvolution)\n",
      "[04/10/2022-15:18:45] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:18:45] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage3_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit2_relu2/Relu (CaskConvolution)\n",
      "[04/10/2022-15:18:45] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit2_relu2/Relu Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998\n",
      "[04/10/2022-15:18:45] [V] [TRT] Tactic: 3564772625446233998 Time: 1.03523\n",
      "[04/10/2022-15:18:45] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit2_relu2/Relu Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_large_nn_v1 Tactic: 3650389455493082349\n",
      "[04/10/2022-15:18:45] [V] [TRT] Tactic: 3650389455493082349 Time: 1.08136\n",
      "[04/10/2022-15:18:45] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit2_relu2/Relu Set Tactic Name: maxwell_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 4772821744921268633\n",
      "[04/10/2022-15:18:45] [V] [TRT] Tactic: 4772821744921268633 Time: 0.483613\n",
      "[04/10/2022-15:18:45] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit2_relu2/Relu Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452\n",
      "[04/10/2022-15:18:45] [V] [TRT] Tactic: 5319956359050645452 Time: 0.905885\n",
      "[04/10/2022-15:18:45] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit2_relu2/Relu Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848\n",
      "[04/10/2022-15:18:45] [V] [TRT] Tactic: 7205456024582378848 Time: 0.802422\n",
      "[04/10/2022-15:18:45] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit2_relu2/Relu Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_large_nn_v1 Tactic: -6490690591794140522\n",
      "[04/10/2022-15:18:45] [V] [TRT] Tactic: -6490690591794140522 Time: 0.809408\n",
      "[04/10/2022-15:18:45] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit2_relu2/Relu Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_large_nn_v1 Tactic: -4686027666808657977\n",
      "[04/10/2022-15:18:45] [V] [TRT] Tactic: -4686027666808657977 Time: 0.797005\n",
      "[04/10/2022-15:18:45] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit2_relu2/Relu Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890\n",
      "[04/10/2022-15:18:45] [V] [TRT] Tactic: -4212163711445252890 Time: 0.760801\n",
      "[04/10/2022-15:18:45] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit2_relu2/Relu Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110\n",
      "[04/10/2022-15:18:45] [V] [TRT] Tactic: -3898373634979201110 Time: 0.793425\n",
      "[04/10/2022-15:18:45] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit2_conv1/Conv2D + StatefulPartitionedCall/model_1/stage3_unit2_relu2/Relu Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473\n",
      "[04/10/2022-15:18:45] [V] [TRT] Tactic: -2409163523992614473 Time: 0.774707\n",
      "[04/10/2022-15:18:45] [V] [TRT] Fastest Tactic: 4772821744921268633 Time: 0.483613\n",
      "[04/10/2022-15:18:45] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 4772821744921268633\n",
      "[04/10/2022-15:18:45] [V] [TRT] *************** Autotuning Reformat:Float(50176,196,14,1) -> Float(50176,1,3584,256) ***************\n",
      "[04/10/2022-15:18:45] [V] [TRT] *************** Autotuning Reformat:Float(50176,196,14,1) -> Half(50176,196,14,1) ***************\n",
      "[04/10/2022-15:18:45] [V] [TRT] *************** Autotuning Reformat:Float(50176,196,14,1) -> Half(25088,196:2,14,1) ***************\n",
      "[04/10/2022-15:18:45] [V] [TRT] *************** Autotuning Reformat:Float(50176,1,3584,256) -> Float(50176,196,14,1) ***************\n",
      "[04/10/2022-15:18:45] [V] [TRT] *************** Autotuning Reformat:Float(50176,1,3584,256) -> Half(50176,196,14,1) ***************\n",
      "[04/10/2022-15:18:45] [V] [TRT] *************** Autotuning Reformat:Float(50176,1,3584,256) -> Half(25088,196:2,14,1) ***************\n",
      "[04/10/2022-15:18:45] [V] [TRT] *************** Autotuning Reformat:Half(50176,196,14,1) -> Float(50176,196,14,1) ***************\n",
      "[04/10/2022-15:18:45] [V] [TRT] *************** Autotuning Reformat:Half(50176,196,14,1) -> Float(50176,1,3584,256) ***************\n",
      "[04/10/2022-15:18:45] [V] [TRT] *************** Autotuning Reformat:Half(50176,196,14,1) -> Half(25088,196:2,14,1) ***************\n",
      "[04/10/2022-15:18:45] [V] [TRT] *************** Autotuning Reformat:Half(25088,196:2,14,1) -> Float(50176,196,14,1) ***************\n",
      "[04/10/2022-15:18:45] [V] [TRT] *************** Autotuning Reformat:Half(25088,196:2,14,1) -> Float(50176,1,3584,256) ***************\n",
      "[04/10/2022-15:18:45] [V] [TRT] *************** Autotuning Reformat:Half(25088,196:2,14,1) -> Half(50176,196,14,1) ***************\n",
      "[04/10/2022-15:18:45] [V] [TRT] *************** Autotuning Reformat:Float(50176,196,14,1) -> Float(50176,1,3584,256) ***************\n",
      "[04/10/2022-15:18:45] [V] [TRT] *************** Autotuning Reformat:Float(50176,196,14,1) -> Half(50176,196,14,1) ***************\n",
      "[04/10/2022-15:18:45] [V] [TRT] *************** Autotuning Reformat:Float(50176,196,14,1) -> Half(25088,196:2,14,1) ***************\n",
      "[04/10/2022-15:18:45] [V] [TRT] *************** Autotuning Reformat:Float(50176,1,3584,256) -> Float(50176,196,14,1) ***************\n",
      "[04/10/2022-15:18:45] [V] [TRT] *************** Autotuning Reformat:Float(50176,1,3584,256) -> Half(50176,196,14,1) ***************\n",
      "[04/10/2022-15:18:45] [V] [TRT] *************** Autotuning Reformat:Float(50176,1,3584,256) -> Half(25088,196:2,14,1) ***************\n",
      "[04/10/2022-15:18:45] [V] [TRT] *************** Autotuning Reformat:Half(50176,196,14,1) -> Float(50176,196,14,1) ***************\n",
      "[04/10/2022-15:18:45] [V] [TRT] *************** Autotuning Reformat:Half(50176,196,14,1) -> Float(50176,1,3584,256) ***************\n",
      "[04/10/2022-15:18:45] [V] [TRT] *************** Autotuning Reformat:Half(50176,196,14,1) -> Half(25088,196:2,14,1) ***************\n",
      "[04/10/2022-15:18:45] [V] [TRT] *************** Autotuning Reformat:Half(25088,196:2,14,1) -> Float(50176,196,14,1) ***************\n",
      "[04/10/2022-15:18:45] [V] [TRT] *************** Autotuning Reformat:Half(25088,196:2,14,1) -> Float(50176,1,3584,256) ***************\n",
      "[04/10/2022-15:18:45] [V] [TRT] *************** Autotuning Reformat:Half(25088,196:2,14,1) -> Half(50176,196,14,1) ***************\n",
      "[04/10/2022-15:18:45] [V] [TRT] *************** Autotuning format combination: Float(50176,196,14,1), Float(50176,196,14,1) -> Float(50176,196,14,1) ***************\n",
      "[04/10/2022-15:18:45] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage3_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_5/add (CudaDepthwiseConvolution)\n",
      "[04/10/2022-15:18:45] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:18:45] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage3_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_5/add (FusedConvActConvolution)\n",
      "[04/10/2022-15:18:45] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:18:45] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage3_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_5/add (CudnnConvolution)\n",
      "[04/10/2022-15:18:45] [V] [TRT] Tactic: 0 Time: 3.00199\n",
      "[04/10/2022-15:18:45] [V] [TRT] Tactic: 1 Time: 1.80563\n",
      "[04/10/2022-15:18:45] [V] [TRT] Tactic: 2 Time: 2.52595\n",
      "[04/10/2022-15:18:46] [V] [TRT] Tactic: 4 Time: 15.3926\n",
      "[04/10/2022-15:18:46] [V] [TRT] Tactic: 5 skipped. Scratch requested: 287440896, available: 268435456\n",
      "[04/10/2022-15:18:46] [V] [TRT] Tactic: 6 Time: 1.41533\n",
      "[04/10/2022-15:18:46] [V] [TRT] Fastest Tactic: 6 Time: 1.41533\n",
      "[04/10/2022-15:18:46] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage3_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_5/add (CaskConvolution)\n",
      "[04/10/2022-15:18:46] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_5/add Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758\n",
      "[04/10/2022-15:18:46] [V] [TRT] Tactic: 1062367460111450758 Time: 2.04625\n",
      "[04/10/2022-15:18:46] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_5/add Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v0 Tactic: 1754984623894446479\n",
      "[04/10/2022-15:18:46] [V] [TRT] Tactic: 1754984623894446479 Time: 2.59977\n",
      "[04/10/2022-15:18:46] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_5/add Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v0 Tactic: 3611739942397549984\n",
      "[04/10/2022-15:18:46] [V] [TRT] Tactic: 3611739942397549984 Time: 1.56575\n",
      "[04/10/2022-15:18:46] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_5/add Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v1 Tactic: 3827454225649558724\n",
      "[04/10/2022-15:18:46] [V] [TRT] Tactic: 3827454225649558724 Time: 1.19707\n",
      "[04/10/2022-15:18:46] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_5/add Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379\n",
      "[04/10/2022-15:18:46] [V] [TRT] Tactic: 4337000649858996379 Time: 1.60281\n",
      "[04/10/2022-15:18:46] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_5/add Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441\n",
      "[04/10/2022-15:18:46] [V] [TRT] Tactic: 4501471010995462441 Time: 1.57113\n",
      "[04/10/2022-15:18:46] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_5/add Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826\n",
      "[04/10/2022-15:18:46] [V] [TRT] Tactic: 5137655947464784826 Time: 1.51885\n",
      "[04/10/2022-15:18:46] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_5/add Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929\n",
      "[04/10/2022-15:18:46] [V] [TRT] Tactic: 5288347012147084929 Time: 1.52726\n",
      "[04/10/2022-15:18:46] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_5/add Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 5921334924264294896\n",
      "[04/10/2022-15:18:46] [V] [TRT] Tactic: 5921334924264294896 Time: 0.921823\n",
      "[04/10/2022-15:18:46] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_5/add Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056\n",
      "[04/10/2022-15:18:46] [V] [TRT] Tactic: 6645123197870846056 Time: 1.57337\n",
      "[04/10/2022-15:18:46] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_5/add Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478\n",
      "[04/10/2022-15:18:46] [V] [TRT] Tactic: 7144526460361122478 Time: 2.22736\n",
      "[04/10/2022-15:18:46] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_5/add Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: 7852627285308570038\n",
      "[04/10/2022-15:18:46] [V] [TRT] Tactic: 7852627285308570038 Time: 1.15089\n",
      "[04/10/2022-15:18:46] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_5/add Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713\n",
      "[04/10/2022-15:18:46] [V] [TRT] Tactic: -9137461792520977713 Time: 1.57536\n",
      "[04/10/2022-15:18:46] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_5/add Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v0 Tactic: -8776506421218919509\n",
      "[04/10/2022-15:18:46] [V] [TRT] Tactic: -8776506421218919509 Time: 1.1243\n",
      "[04/10/2022-15:18:46] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_5/add Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730\n",
      "[04/10/2022-15:18:46] [V] [TRT] Tactic: -8262349710178828730 Time: 1.57437\n",
      "[04/10/2022-15:18:46] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_5/add Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v0 Tactic: -8133971918129952780\n",
      "[04/10/2022-15:18:46] [V] [TRT] Tactic: -8133971918129952780 Time: 1.71453\n",
      "[04/10/2022-15:18:46] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_5/add Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144\n",
      "[04/10/2022-15:18:46] [V] [TRT] Tactic: -6092040395344634144 Time: 2.13523\n",
      "[04/10/2022-15:18:46] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_5/add Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159\n",
      "[04/10/2022-15:18:47] [V] [TRT] Tactic: -4787320710726427159 Time: 2.5898\n",
      "[04/10/2022-15:18:47] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_5/add Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839\n",
      "[04/10/2022-15:18:47] [V] [TRT] Tactic: -3456450830548107839 Time: 1.78703\n",
      "[04/10/2022-15:18:47] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_5/add Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v0 Tactic: -2318106587342035239\n",
      "[04/10/2022-15:18:47] [V] [TRT] Tactic: -2318106587342035239 Time: 1.11904\n",
      "[04/10/2022-15:18:47] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_5/add Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_mobile_relu_tile148t_nt_v0 Tactic: -1343271414618805657\n",
      "[04/10/2022-15:18:47] [V] [TRT] Tactic: -1343271414618805657 Time: 0.84084\n",
      "[04/10/2022-15:18:47] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_5/add Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241\n",
      "[04/10/2022-15:18:47] [V] [TRT] Tactic: -1218658103698133241 Time: 1.70798\n",
      "[04/10/2022-15:18:47] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_5/add Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091\n",
      "[04/10/2022-15:18:47] [V] [TRT] Tactic: -836875257600482091 Time: 1.64455\n",
      "[04/10/2022-15:18:47] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_5/add Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746\n",
      "[04/10/2022-15:18:47] [V] [TRT] Tactic: -410470605513481746 Time: 1.50208\n",
      "[04/10/2022-15:18:47] [V] [TRT] Fastest Tactic: -1343271414618805657 Time: 0.84084\n",
      "[04/10/2022-15:18:47] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -1343271414618805657\n",
      "[04/10/2022-15:18:47] [V] [TRT] *************** Autotuning format combination: Float(50176,1,3584,256), Float(50176,1,3584,256) -> Float(50176,1,3584,256) ***************\n",
      "[04/10/2022-15:18:47] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage3_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_5/add (CudnnConvolution)\n",
      "[04/10/2022-15:18:47] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:18:47] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage3_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_5/add (CaskConvolution)\n",
      "[04/10/2022-15:18:47] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_5/add Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824\n",
      "[04/10/2022-15:18:47] [V] [TRT] Tactic: -9153228964338181824 Time: 1.87206\n",
      "[04/10/2022-15:18:47] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_5/add Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025\n",
      "[04/10/2022-15:18:47] [V] [TRT] Tactic: -7394439838318485025 Time: 1.5008\n",
      "[04/10/2022-15:18:47] [V] [TRT] Fastest Tactic: -7394439838318485025 Time: 1.5008\n",
      "[04/10/2022-15:18:47] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7394439838318485025\n",
      "[04/10/2022-15:18:47] [V] [TRT] *************** Autotuning format combination: Half(50176,196,14,1), Half(50176,196,14,1) -> Half(50176,196,14,1) ***************\n",
      "[04/10/2022-15:18:47] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage3_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_5/add (CudnnConvolution)\n",
      "[04/10/2022-15:18:47] [V] [TRT] Tactic: 0 Time: 2.94923\n",
      "[04/10/2022-15:18:47] [V] [TRT] Tactic: 1 Time: 1.90229\n",
      "[04/10/2022-15:18:47] [V] [TRT] Tactic: 2 Time: 2.47001\n",
      "[04/10/2022-15:18:47] [V] [TRT] Tactic: 4 Time: 15.5184\n",
      "[04/10/2022-15:18:47] [V] [TRT] Tactic: 5 skipped. Scratch requested: 287440896, available: 268435456\n",
      "[04/10/2022-15:18:48] [V] [TRT] Tactic: 6 Time: 2.59956\n",
      "[04/10/2022-15:18:48] [V] [TRT] Fastest Tactic: 1 Time: 1.90229\n",
      "[04/10/2022-15:18:48] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage3_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_5/add (CaskConvolution)\n",
      "[04/10/2022-15:18:48] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:18:48] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 1\n",
      "[04/10/2022-15:18:48] [V] [TRT] *************** Autotuning format combination: Half(25088,196:2,14,1), Half(25088,196:2,14,1) -> Half(25088,196:2,14,1) ***************\n",
      "[04/10/2022-15:18:48] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage3_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_5/add (FusedConvActConvolution)\n",
      "[04/10/2022-15:18:48] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:18:48] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage3_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_5/add (CudnnConvolution)\n",
      "[04/10/2022-15:18:48] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:18:48] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage3_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_5/add (CaskConvolution)\n",
      "[04/10/2022-15:18:48] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_5/add Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998\n",
      "[04/10/2022-15:18:48] [V] [TRT] Tactic: 3564772625446233998 Time: 1.03948\n",
      "[04/10/2022-15:18:48] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_5/add Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_large_nn_v1 Tactic: 3650389455493082349\n",
      "[04/10/2022-15:18:48] [V] [TRT] Tactic: 3650389455493082349 Time: 1.07674\n",
      "[04/10/2022-15:18:48] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_5/add Set Tactic Name: maxwell_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 4772821744921268633\n",
      "[04/10/2022-15:18:48] [V] [TRT] Tactic: 4772821744921268633 Time: 0.492142\n",
      "[04/10/2022-15:18:48] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_5/add Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452\n",
      "[04/10/2022-15:18:48] [V] [TRT] Tactic: 5319956359050645452 Time: 0.894043\n",
      "[04/10/2022-15:18:48] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_5/add Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848\n",
      "[04/10/2022-15:18:48] [V] [TRT] Tactic: 7205456024582378848 Time: 0.801257\n",
      "[04/10/2022-15:18:48] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_5/add Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_large_nn_v1 Tactic: -6490690591794140522\n",
      "[04/10/2022-15:18:48] [V] [TRT] Tactic: -6490690591794140522 Time: 0.811478\n",
      "[04/10/2022-15:18:48] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_5/add Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_large_nn_v1 Tactic: -4686027666808657977\n",
      "[04/10/2022-15:18:48] [V] [TRT] Tactic: -4686027666808657977 Time: 0.799349\n",
      "[04/10/2022-15:18:48] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_5/add Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890\n",
      "[04/10/2022-15:18:48] [V] [TRT] Tactic: -4212163711445252890 Time: 0.759713\n",
      "[04/10/2022-15:18:48] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_5/add Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110\n",
      "[04/10/2022-15:18:48] [V] [TRT] Tactic: -3898373634979201110 Time: 0.795775\n",
      "[04/10/2022-15:18:48] [V] [TRT] StatefulPartitionedCall/model_1/stage3_unit2_conv2/Conv2D + StatefulPartitionedCall/model_1/add_5/add Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473\n",
      "[04/10/2022-15:18:48] [V] [TRT] Tactic: -2409163523992614473 Time: 0.784375\n",
      "[04/10/2022-15:18:48] [V] [TRT] Fastest Tactic: 4772821744921268633 Time: 0.492142\n",
      "[04/10/2022-15:18:48] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 4772821744921268633\n",
      "[04/10/2022-15:18:48] [V] [TRT] *************** Autotuning Reformat:Float(50176,196,14,1) -> Float(50176,1,3584,256) ***************\n",
      "[04/10/2022-15:18:48] [V] [TRT] *************** Autotuning Reformat:Float(50176,196,14,1) -> Half(50176,196,14,1) ***************\n",
      "[04/10/2022-15:18:48] [V] [TRT] *************** Autotuning Reformat:Float(50176,196,14,1) -> Half(25088,196:2,14,1) ***************\n",
      "[04/10/2022-15:18:48] [V] [TRT] *************** Autotuning Reformat:Float(50176,1,3584,256) -> Float(50176,196,14,1) ***************\n",
      "[04/10/2022-15:18:48] [V] [TRT] *************** Autotuning Reformat:Float(50176,1,3584,256) -> Half(50176,196,14,1) ***************\n",
      "[04/10/2022-15:18:48] [V] [TRT] *************** Autotuning Reformat:Float(50176,1,3584,256) -> Half(25088,196:2,14,1) ***************\n",
      "[04/10/2022-15:18:48] [V] [TRT] *************** Autotuning Reformat:Half(50176,196,14,1) -> Float(50176,196,14,1) ***************\n",
      "[04/10/2022-15:18:48] [V] [TRT] *************** Autotuning Reformat:Half(50176,196,14,1) -> Float(50176,1,3584,256) ***************\n",
      "[04/10/2022-15:18:48] [V] [TRT] *************** Autotuning Reformat:Half(50176,196,14,1) -> Half(25088,196:2,14,1) ***************\n",
      "[04/10/2022-15:18:48] [V] [TRT] *************** Autotuning Reformat:Half(25088,196:2,14,1) -> Float(50176,196,14,1) ***************\n",
      "[04/10/2022-15:18:48] [V] [TRT] *************** Autotuning Reformat:Half(25088,196:2,14,1) -> Float(50176,1,3584,256) ***************\n",
      "[04/10/2022-15:18:48] [V] [TRT] *************** Autotuning Reformat:Half(25088,196:2,14,1) -> Half(50176,196,14,1) ***************\n",
      "[04/10/2022-15:18:48] [V] [TRT] *************** Autotuning format combination: Float(50176,196,14,1) -> Float(50176,196,14,1) ***************\n",
      "[04/10/2022-15:18:48] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage4_unit1_bn1/FusedBatchNormV3 + StatefulPartitionedCall/model_1/stage4_unit1_relu1/Relu (Scale)\n",
      "[04/10/2022-15:18:48] [V] [TRT] Tactic: 0 Time: 0.039362\n",
      "[04/10/2022-15:18:48] [V] [TRT] Fastest Tactic: 0 Time: 0.039362\n",
      "[04/10/2022-15:18:48] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Scale Tactic: 0\n",
      "[04/10/2022-15:18:48] [V] [TRT] *************** Autotuning format combination: Float(50176,1,3584,256) -> Float(50176,1,3584,256) ***************\n",
      "[04/10/2022-15:18:48] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage4_unit1_bn1/FusedBatchNormV3 + StatefulPartitionedCall/model_1/stage4_unit1_relu1/Relu (Scale)\n",
      "[04/10/2022-15:18:48] [V] [TRT] Scale has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:18:48] [V] [TRT] *************** Autotuning format combination: Half(50176,196,14,1) -> Half(50176,196,14,1) ***************\n",
      "[04/10/2022-15:18:48] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage4_unit1_bn1/FusedBatchNormV3 + StatefulPartitionedCall/model_1/stage4_unit1_relu1/Relu (Scale)\n",
      "[04/10/2022-15:18:48] [V] [TRT] Tactic: 0 Time: 0.0337891\n",
      "[04/10/2022-15:18:48] [V] [TRT] Fastest Tactic: 0 Time: 0.0337891\n",
      "[04/10/2022-15:18:48] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Scale Tactic: 0\n",
      "[04/10/2022-15:18:48] [V] [TRT] *************** Autotuning format combination: Half(25088,196:2,14,1) -> Half(25088,196:2,14,1) ***************\n",
      "[04/10/2022-15:18:48] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage4_unit1_bn1/FusedBatchNormV3 + StatefulPartitionedCall/model_1/stage4_unit1_relu1/Relu (Scale)\n",
      "[04/10/2022-15:18:48] [V] [TRT] Tactic: 0 Time: 0.0430014\n",
      "[04/10/2022-15:18:48] [V] [TRT] Fastest Tactic: 0 Time: 0.0430014\n",
      "[04/10/2022-15:18:48] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Scale Tactic: 0\n",
      "[04/10/2022-15:18:48] [V] [TRT] *************** Autotuning Reformat:Float(50176,196,14,1) -> Float(50176,1,3584,256) ***************\n",
      "[04/10/2022-15:18:48] [V] [TRT] *************** Autotuning Reformat:Float(50176,196,14,1) -> Half(50176,196,14,1) ***************\n",
      "[04/10/2022-15:18:48] [V] [TRT] *************** Autotuning Reformat:Float(50176,196,14,1) -> Half(25088,196:2,14,1) ***************\n",
      "[04/10/2022-15:18:48] [V] [TRT] *************** Autotuning Reformat:Float(50176,1,3584,256) -> Float(50176,196,14,1) ***************\n",
      "[04/10/2022-15:18:48] [V] [TRT] *************** Autotuning Reformat:Float(50176,1,3584,256) -> Half(50176,196,14,1) ***************\n",
      "[04/10/2022-15:18:48] [V] [TRT] *************** Autotuning Reformat:Float(50176,1,3584,256) -> Half(25088,196:2,14,1) ***************\n",
      "[04/10/2022-15:18:48] [V] [TRT] *************** Autotuning Reformat:Half(50176,196,14,1) -> Float(50176,196,14,1) ***************\n",
      "[04/10/2022-15:18:48] [V] [TRT] *************** Autotuning Reformat:Half(50176,196,14,1) -> Float(50176,1,3584,256) ***************\n",
      "[04/10/2022-15:18:48] [V] [TRT] *************** Autotuning Reformat:Half(50176,196,14,1) -> Half(25088,196:2,14,1) ***************\n",
      "[04/10/2022-15:18:48] [V] [TRT] *************** Autotuning Reformat:Half(25088,196:2,14,1) -> Float(50176,196,14,1) ***************\n",
      "[04/10/2022-15:18:48] [V] [TRT] *************** Autotuning Reformat:Half(25088,196:2,14,1) -> Float(50176,1,3584,256) ***************\n",
      "[04/10/2022-15:18:48] [V] [TRT] *************** Autotuning Reformat:Half(25088,196:2,14,1) -> Half(50176,196,14,1) ***************\n",
      "[04/10/2022-15:18:48] [V] [TRT] *************** Autotuning Reformat:Float(50176,196,14,1) -> Float(50176,1,3584,256) ***************\n",
      "[04/10/2022-15:18:48] [V] [TRT] *************** Autotuning Reformat:Float(50176,196,14,1) -> Half(50176,196,14,1) ***************\n",
      "[04/10/2022-15:18:48] [V] [TRT] *************** Autotuning Reformat:Float(50176,196,14,1) -> Half(25088,196:2,14,1) ***************\n",
      "[04/10/2022-15:18:48] [V] [TRT] *************** Autotuning Reformat:Float(50176,1,3584,256) -> Float(50176,196,14,1) ***************\n",
      "[04/10/2022-15:18:48] [V] [TRT] *************** Autotuning Reformat:Float(50176,1,3584,256) -> Half(50176,196,14,1) ***************\n",
      "[04/10/2022-15:18:48] [V] [TRT] *************** Autotuning Reformat:Float(50176,1,3584,256) -> Half(25088,196:2,14,1) ***************\n",
      "[04/10/2022-15:18:48] [V] [TRT] *************** Autotuning Reformat:Half(50176,196,14,1) -> Float(50176,196,14,1) ***************\n",
      "[04/10/2022-15:18:48] [V] [TRT] *************** Autotuning Reformat:Half(50176,196,14,1) -> Float(50176,1,3584,256) ***************\n",
      "[04/10/2022-15:18:48] [V] [TRT] *************** Autotuning Reformat:Half(50176,196,14,1) -> Half(25088,196:2,14,1) ***************\n",
      "[04/10/2022-15:18:48] [V] [TRT] *************** Autotuning Reformat:Half(25088,196:2,14,1) -> Float(50176,196,14,1) ***************\n",
      "[04/10/2022-15:18:48] [V] [TRT] *************** Autotuning Reformat:Half(25088,196:2,14,1) -> Float(50176,1,3584,256) ***************\n",
      "[04/10/2022-15:18:48] [V] [TRT] *************** Autotuning Reformat:Half(25088,196:2,14,1) -> Half(50176,196,14,1) ***************\n",
      "[04/10/2022-15:18:48] [V] [TRT] *************** Autotuning format combination: Float(50176,196,14,1) -> Float(25088,49,7,1) ***************\n",
      "[04/10/2022-15:18:48] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage4_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage4_unit1_relu2/Relu (CudaDepthwiseConvolution)\n",
      "[04/10/2022-15:18:48] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:18:48] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage4_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage4_unit1_relu2/Relu (FusedConvActConvolution)\n",
      "[04/10/2022-15:18:48] [V] [TRT] Tactic: 458751 Time: 1.31535\n",
      "[04/10/2022-15:18:48] [V] [TRT] Fastest Tactic: 458751 Time: 1.31535\n",
      "[04/10/2022-15:18:48] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage4_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage4_unit1_relu2/Relu (CudnnConvolution)\n",
      "[04/10/2022-15:18:48] [V] [TRT] Tactic: 0 Time: 1.93729\n",
      "[04/10/2022-15:18:48] [V] [TRT] Tactic: 1 Time: 1.94408\n",
      "[04/10/2022-15:18:48] [V] [TRT] Tactic: 2 Time: 1.57896\n",
      "[04/10/2022-15:18:48] [V] [TRT] Tactic: 5 skipped. Scratch requested: 573767680, available: 268435456\n",
      "[04/10/2022-15:18:48] [V] [TRT] Fastest Tactic: 2 Time: 1.57896\n",
      "[04/10/2022-15:18:48] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage4_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage4_unit1_relu2/Relu (CaskConvolution)\n",
      "[04/10/2022-15:18:48] [V] [TRT] StatefulPartitionedCall/model_1/stage4_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage4_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758\n",
      "[04/10/2022-15:18:48] [V] [TRT] Tactic: 1062367460111450758 Time: 2.00166\n",
      "[04/10/2022-15:18:48] [V] [TRT] StatefulPartitionedCall/model_1/stage4_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage4_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v0 Tactic: 1754984623894446479\n",
      "[04/10/2022-15:18:48] [V] [TRT] Tactic: 1754984623894446479 Time: 2.54176\n",
      "[04/10/2022-15:18:48] [V] [TRT] StatefulPartitionedCall/model_1/stage4_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage4_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v0 Tactic: 3611739942397549984\n",
      "[04/10/2022-15:18:48] [V] [TRT] Tactic: 3611739942397549984 Time: 1.56934\n",
      "[04/10/2022-15:18:48] [V] [TRT] StatefulPartitionedCall/model_1/stage4_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage4_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379\n",
      "[04/10/2022-15:18:48] [V] [TRT] Tactic: 4337000649858996379 Time: 1.58291\n",
      "[04/10/2022-15:18:48] [V] [TRT] StatefulPartitionedCall/model_1/stage4_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage4_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441\n",
      "[04/10/2022-15:18:48] [V] [TRT] Tactic: 4501471010995462441 Time: 1.56347\n",
      "[04/10/2022-15:18:48] [V] [TRT] StatefulPartitionedCall/model_1/stage4_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage4_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826\n",
      "[04/10/2022-15:18:48] [V] [TRT] Tactic: 5137655947464784826 Time: 1.51919\n",
      "[04/10/2022-15:18:48] [V] [TRT] StatefulPartitionedCall/model_1/stage4_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage4_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929\n",
      "[04/10/2022-15:18:48] [V] [TRT] Tactic: 5288347012147084929 Time: 1.54195\n",
      "[04/10/2022-15:18:49] [V] [TRT] StatefulPartitionedCall/model_1/stage4_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage4_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056\n",
      "[04/10/2022-15:18:49] [V] [TRT] Tactic: 6645123197870846056 Time: 1.56897\n",
      "[04/10/2022-15:18:49] [V] [TRT] StatefulPartitionedCall/model_1/stage4_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage4_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478\n",
      "[04/10/2022-15:18:49] [V] [TRT] Tactic: 7144526460361122478 Time: 2.33002\n",
      "[04/10/2022-15:18:49] [V] [TRT] StatefulPartitionedCall/model_1/stage4_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage4_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713\n",
      "[04/10/2022-15:18:49] [V] [TRT] Tactic: -9137461792520977713 Time: 1.57555\n",
      "[04/10/2022-15:18:49] [V] [TRT] StatefulPartitionedCall/model_1/stage4_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage4_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730\n",
      "[04/10/2022-15:18:49] [V] [TRT] Tactic: -8262349710178828730 Time: 1.58445\n",
      "[04/10/2022-15:18:49] [V] [TRT] StatefulPartitionedCall/model_1/stage4_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage4_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v0 Tactic: -8133971918129952780\n",
      "[04/10/2022-15:18:49] [V] [TRT] Tactic: -8133971918129952780 Time: 1.77998\n",
      "[04/10/2022-15:18:49] [V] [TRT] StatefulPartitionedCall/model_1/stage4_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage4_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144\n",
      "[04/10/2022-15:18:49] [V] [TRT] Tactic: -6092040395344634144 Time: 2.11941\n",
      "[04/10/2022-15:18:49] [V] [TRT] StatefulPartitionedCall/model_1/stage4_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage4_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159\n",
      "[04/10/2022-15:18:49] [V] [TRT] Tactic: -4787320710726427159 Time: 2.53592\n",
      "[04/10/2022-15:18:49] [V] [TRT] StatefulPartitionedCall/model_1/stage4_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage4_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839\n",
      "[04/10/2022-15:18:49] [V] [TRT] Tactic: -3456450830548107839 Time: 1.80951\n",
      "[04/10/2022-15:18:49] [V] [TRT] StatefulPartitionedCall/model_1/stage4_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage4_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241\n",
      "[04/10/2022-15:18:49] [V] [TRT] Tactic: -1218658103698133241 Time: 1.76519\n",
      "[04/10/2022-15:18:49] [V] [TRT] StatefulPartitionedCall/model_1/stage4_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage4_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091\n",
      "[04/10/2022-15:18:49] [V] [TRT] Tactic: -836875257600482091 Time: 1.70861\n",
      "[04/10/2022-15:18:49] [V] [TRT] StatefulPartitionedCall/model_1/stage4_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage4_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746\n",
      "[04/10/2022-15:18:49] [V] [TRT] Tactic: -410470605513481746 Time: 1.51301\n",
      "[04/10/2022-15:18:49] [V] [TRT] Fastest Tactic: -410470605513481746 Time: 1.51301\n",
      "[04/10/2022-15:18:49] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: FusedConvActConvolution Tactic: 458751\n",
      "[04/10/2022-15:18:49] [V] [TRT] *************** Autotuning format combination: Float(50176,1,3584,256) -> Float(25088,1,3584,512) ***************\n",
      "[04/10/2022-15:18:49] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage4_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage4_unit1_relu2/Relu (CudnnConvolution)\n",
      "[04/10/2022-15:18:49] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:18:49] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage4_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage4_unit1_relu2/Relu (CaskConvolution)\n",
      "[04/10/2022-15:18:49] [V] [TRT] StatefulPartitionedCall/model_1/stage4_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage4_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824\n",
      "[04/10/2022-15:18:49] [V] [TRT] Tactic: -9153228964338181824 Time: 1.83566\n",
      "[04/10/2022-15:18:49] [V] [TRT] StatefulPartitionedCall/model_1/stage4_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage4_unit1_relu2/Relu Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025\n",
      "[04/10/2022-15:18:49] [V] [TRT] Tactic: -7394439838318485025 Time: 1.49985\n",
      "[04/10/2022-15:18:49] [V] [TRT] Fastest Tactic: -7394439838318485025 Time: 1.49985\n",
      "[04/10/2022-15:18:49] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7394439838318485025\n",
      "[04/10/2022-15:18:49] [V] [TRT] *************** Autotuning format combination: Half(50176,196,14,1) -> Half(25088,49,7,1) ***************\n",
      "[04/10/2022-15:18:49] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage4_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage4_unit1_relu2/Relu (CudnnConvolution)\n",
      "[04/10/2022-15:18:49] [V] [TRT] Tactic: 0 Time: 1.9499\n",
      "[04/10/2022-15:18:49] [V] [TRT] Tactic: 1 Time: 1.95526\n",
      "[04/10/2022-15:18:49] [V] [TRT] Tactic: 2 Time: 1.58783\n",
      "[04/10/2022-15:18:49] [V] [TRT] Tactic: 5 skipped. Scratch requested: 573767680, available: 268435456\n",
      "[04/10/2022-15:18:49] [V] [TRT] Fastest Tactic: 2 Time: 1.58783\n",
      "[04/10/2022-15:18:49] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage4_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage4_unit1_relu2/Relu (CaskConvolution)\n",
      "[04/10/2022-15:18:49] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:18:49] [V] [TRT] Setting workspace to 573767680enables more tactics for profiling\n",
      "[04/10/2022-15:18:49] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 2\n",
      "[04/10/2022-15:18:49] [V] [TRT] *************** Autotuning format combination: Half(25088,196:2,14,1) -> Half(12544,49:2,7,1) ***************\n",
      "[04/10/2022-15:18:49] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage4_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage4_unit1_relu2/Relu (FusedConvActConvolution)\n",
      "[04/10/2022-15:18:49] [V] [TRT] Tactic: 458751 Time: 0.988516\n",
      "[04/10/2022-15:18:49] [V] [TRT] Fastest Tactic: 458751 Time: 0.988516\n",
      "[04/10/2022-15:18:49] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage4_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage4_unit1_relu2/Relu (CudnnConvolution)\n",
      "[04/10/2022-15:18:49] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:18:49] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage4_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage4_unit1_relu2/Relu (CaskConvolution)\n",
      "[04/10/2022-15:18:49] [V] [TRT] StatefulPartitionedCall/model_1/stage4_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage4_unit1_relu2/Relu Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998\n",
      "[04/10/2022-15:18:50] [V] [TRT] Tactic: 3564772625446233998 Time: 1.01741\n",
      "[04/10/2022-15:18:50] [V] [TRT] StatefulPartitionedCall/model_1/stage4_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage4_unit1_relu2/Relu Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_large_nn_v1 Tactic: 3650389455493082349\n",
      "[04/10/2022-15:18:50] [V] [TRT] Tactic: 3650389455493082349 Time: 1.06467\n",
      "[04/10/2022-15:18:50] [V] [TRT] StatefulPartitionedCall/model_1/stage4_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage4_unit1_relu2/Relu Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452\n",
      "[04/10/2022-15:18:50] [V] [TRT] Tactic: 5319956359050645452 Time: 0.906178\n",
      "[04/10/2022-15:18:50] [V] [TRT] StatefulPartitionedCall/model_1/stage4_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage4_unit1_relu2/Relu Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848\n",
      "[04/10/2022-15:18:50] [V] [TRT] Tactic: 7205456024582378848 Time: 0.793984\n",
      "[04/10/2022-15:18:50] [V] [TRT] StatefulPartitionedCall/model_1/stage4_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage4_unit1_relu2/Relu Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_large_nn_v1 Tactic: -6490690591794140522\n",
      "[04/10/2022-15:18:50] [V] [TRT] Tactic: -6490690591794140522 Time: 0.802767\n",
      "[04/10/2022-15:18:50] [V] [TRT] StatefulPartitionedCall/model_1/stage4_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage4_unit1_relu2/Relu Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_large_nn_v1 Tactic: -4686027666808657977\n",
      "[04/10/2022-15:18:50] [V] [TRT] Tactic: -4686027666808657977 Time: 0.803489\n",
      "[04/10/2022-15:18:50] [V] [TRT] StatefulPartitionedCall/model_1/stage4_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage4_unit1_relu2/Relu Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890\n",
      "[04/10/2022-15:18:50] [V] [TRT] Tactic: -4212163711445252890 Time: 0.76888\n",
      "[04/10/2022-15:18:50] [V] [TRT] StatefulPartitionedCall/model_1/stage4_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage4_unit1_relu2/Relu Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110\n",
      "[04/10/2022-15:18:50] [V] [TRT] Tactic: -3898373634979201110 Time: 0.790306\n",
      "[04/10/2022-15:18:50] [V] [TRT] StatefulPartitionedCall/model_1/stage4_unit1_conv1/Conv2D + StatefulPartitionedCall/model_1/stage4_unit1_relu2/Relu Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473\n",
      "[04/10/2022-15:18:50] [V] [TRT] Tactic: -2409163523992614473 Time: 0.771485\n",
      "[04/10/2022-15:18:50] [V] [TRT] Fastest Tactic: -4212163711445252890 Time: 0.76888\n",
      "[04/10/2022-15:18:50] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -4212163711445252890\n",
      "[04/10/2022-15:18:50] [V] [TRT] *************** Autotuning Reformat:Float(25088,49,7,1) -> Float(25088,1,3584,512) ***************\n",
      "[04/10/2022-15:18:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:18:50] [V] [TRT] Tactic: 1002 Time: 0.0368099\n",
      "[04/10/2022-15:18:50] [V] [TRT] Tactic: 0 Time: 0.0426236\n",
      "[04/10/2022-15:18:50] [V] [TRT] Fastest Tactic: 1002 Time: 0.0368099\n",
      "[04/10/2022-15:18:50] [V] [TRT] *************** Autotuning Reformat:Float(25088,49,7,1) -> Half(25088,49,7,1) ***************\n",
      "[04/10/2022-15:18:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:18:50] [V] [TRT] Tactic: 1002 Time: 0.781589\n",
      "[04/10/2022-15:18:50] [V] [TRT] Tactic: 0 Time: 0.029967\n",
      "[04/10/2022-15:18:50] [V] [TRT] Fastest Tactic: 0 Time: 0.029967\n",
      "[04/10/2022-15:18:50] [V] [TRT] *************** Autotuning Reformat:Float(25088,49,7,1) -> Half(12544,49:2,7,1) ***************\n",
      "[04/10/2022-15:18:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:18:50] [V] [TRT] Tactic: 1002 Time: 0.0491407\n",
      "[04/10/2022-15:18:50] [V] [TRT] Tactic: 0 Time: 0.0245378\n",
      "[04/10/2022-15:18:50] [V] [TRT] Fastest Tactic: 0 Time: 0.0245378\n",
      "[04/10/2022-15:18:50] [V] [TRT] *************** Autotuning Reformat:Float(25088,1,3584,512) -> Float(25088,49,7,1) ***************\n",
      "[04/10/2022-15:18:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:18:50] [V] [TRT] Tactic: 1002 Time: 0.047181\n",
      "[04/10/2022-15:18:50] [V] [TRT] Tactic: 0 Time: 0.0392251\n",
      "[04/10/2022-15:18:50] [V] [TRT] Fastest Tactic: 0 Time: 0.0392251\n",
      "[04/10/2022-15:18:50] [V] [TRT] *************** Autotuning Reformat:Float(25088,1,3584,512) -> Half(25088,49,7,1) ***************\n",
      "[04/10/2022-15:18:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:18:50] [V] [TRT] Tactic: 1002 Time: 0.0378449\n",
      "[04/10/2022-15:18:50] [V] [TRT] Tactic: 0 Time: 0.0396616\n",
      "[04/10/2022-15:18:50] [V] [TRT] Fastest Tactic: 1002 Time: 0.0378449\n",
      "[04/10/2022-15:18:50] [V] [TRT] *************** Autotuning Reformat:Float(25088,1,3584,512) -> Half(12544,49:2,7,1) ***************\n",
      "[04/10/2022-15:18:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:18:50] [V] [TRT] Tactic: 1002 Time: 0.0437369\n",
      "[04/10/2022-15:18:50] [V] [TRT] Tactic: 0 Time: 0.0464063\n",
      "[04/10/2022-15:18:50] [V] [TRT] Fastest Tactic: 1002 Time: 0.0437369\n",
      "[04/10/2022-15:18:50] [V] [TRT] *************** Autotuning Reformat:Half(25088,49,7,1) -> Float(25088,49,7,1) ***************\n",
      "[04/10/2022-15:18:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:18:50] [V] [TRT] Tactic: 1002 Time: 0.804583\n",
      "[04/10/2022-15:18:50] [V] [TRT] Tactic: 0 Time: 0.0263931\n",
      "[04/10/2022-15:18:50] [V] [TRT] Fastest Tactic: 0 Time: 0.0263931\n",
      "[04/10/2022-15:18:50] [V] [TRT] *************** Autotuning Reformat:Half(25088,49,7,1) -> Float(25088,1,3584,512) ***************\n",
      "[04/10/2022-15:18:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:18:50] [V] [TRT] Tactic: 1002 Time: 0.0350131\n",
      "[04/10/2022-15:18:50] [V] [TRT] Tactic: 0 Time: 0.0428385\n",
      "[04/10/2022-15:18:50] [V] [TRT] Fastest Tactic: 1002 Time: 0.0350131\n",
      "[04/10/2022-15:18:50] [V] [TRT] *************** Autotuning Reformat:Half(25088,49,7,1) -> Half(12544,49:2,7,1) ***************\n",
      "[04/10/2022-15:18:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:18:50] [V] [TRT] Tactic: 1002 Time: 0.0537175\n",
      "[04/10/2022-15:18:50] [V] [TRT] Tactic: 0 Time: 0.0245181\n",
      "[04/10/2022-15:18:50] [V] [TRT] Fastest Tactic: 0 Time: 0.0245181\n",
      "[04/10/2022-15:18:50] [V] [TRT] *************** Autotuning Reformat:Half(12544,49:2,7,1) -> Float(25088,49,7,1) ***************\n",
      "[04/10/2022-15:18:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:18:50] [V] [TRT] Tactic: 1002 Time: 0.0467837\n",
      "[04/10/2022-15:18:50] [V] [TRT] Tactic: 0 Time: 0.0219793\n",
      "[04/10/2022-15:18:50] [V] [TRT] Fastest Tactic: 0 Time: 0.0219793\n",
      "[04/10/2022-15:18:50] [V] [TRT] *************** Autotuning Reformat:Half(12544,49:2,7,1) -> Float(25088,1,3584,512) ***************\n",
      "[04/10/2022-15:18:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:18:50] [V] [TRT] Tactic: 1002 Time: 0.036276\n",
      "[04/10/2022-15:18:50] [V] [TRT] Tactic: 0 Time: 0.049388\n",
      "[04/10/2022-15:18:50] [V] [TRT] Fastest Tactic: 1002 Time: 0.036276\n",
      "[04/10/2022-15:18:50] [V] [TRT] *************** Autotuning Reformat:Half(12544,49:2,7,1) -> Half(25088,49,7,1) ***************\n",
      "[04/10/2022-15:18:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)\n",
      "[04/10/2022-15:18:50] [V] [TRT] Tactic: 1002 Time: 0.05847\n",
      "[04/10/2022-15:18:50] [V] [TRT] Tactic: 0 Time: 0.022233\n",
      "[04/10/2022-15:18:50] [V] [TRT] Fastest Tactic: 0 Time: 0.022233\n",
      "[04/10/2022-15:18:50] [V] [TRT] *************** Autotuning format combination: Float(25088,49,7,1) -> Float(25088,49,7,1) ***************\n",
      "[04/10/2022-15:18:50] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage4_unit1_conv2/Conv2D (CudaDepthwiseConvolution)\n",
      "[04/10/2022-15:18:50] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:18:50] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage4_unit1_conv2/Conv2D (FusedConvActConvolution)\n",
      "[04/10/2022-15:18:50] [V] [TRT] Tactic: 524287 Time: 1.52357\n",
      "[04/10/2022-15:18:50] [V] [TRT] Tactic: 720895 Time: 2.91508\n",
      "[04/10/2022-15:18:51] [V] [TRT] Tactic: 983039 Time: 1.40202\n",
      "[04/10/2022-15:18:51] [V] [TRT] Tactic: 1048575 Time: 2.1818\n",
      "[04/10/2022-15:18:51] [V] [TRT] Tactic: 1703935 Time: 2.07555\n",
      "[04/10/2022-15:18:51] [V] [TRT] Tactic: 1769471 Time: 1.86066\n",
      "[04/10/2022-15:18:51] [V] [TRT] Tactic: 1966079 Time: 1.55178\n",
      "[04/10/2022-15:18:52] [V] [TRT] Tactic: 2031615 Time: 2.53525\n",
      "[04/10/2022-15:18:52] [V] [TRT] Tactic: 2228223 Time: 2.49803\n",
      "[04/10/2022-15:18:52] [V] [TRT] Tactic: 2424831 Time: 2.72345\n",
      "[04/10/2022-15:18:52] [V] [TRT] Tactic: 2621439 Time: 2.38398\n",
      "[04/10/2022-15:18:52] [V] [TRT] Tactic: 2752511 Time: 1.7856\n",
      "[04/10/2022-15:18:53] [V] [TRT] Tactic: 2818047 Time: 2.4483\n",
      "[04/10/2022-15:18:53] [V] [TRT] Tactic: 2883583 Time: 2.54117\n",
      "[04/10/2022-15:18:53] [V] [TRT] Tactic: 3014655 Time: 1.39662\n",
      "[04/10/2022-15:18:53] [V] [TRT] Tactic: 3145727 Time: 1.78869\n",
      "[04/10/2022-15:18:53] [V] [TRT] Tactic: 3473407 Time: 2.18445\n",
      "[04/10/2022-15:18:53] [V] [TRT] Tactic: 3604479 Time: 1.38736\n",
      "[04/10/2022-15:18:54] [V] [TRT] Tactic: 3735551 Time: 2.99675\n",
      "[04/10/2022-15:18:54] [V] [TRT] Tactic: 4390911 Time: 1.73966\n",
      "[04/10/2022-15:18:54] [V] [TRT] Tactic: 5046271 Time: 1.50724\n",
      "[04/10/2022-15:18:54] [V] [TRT] Tactic: 5963775 Time: 1.39376\n",
      "[04/10/2022-15:18:54] [V] [TRT] Tactic: 6160383 Time: 1.61792\n",
      "[04/10/2022-15:18:55] [V] [TRT] Tactic: 6488063 Time: 1.28653\n",
      "[04/10/2022-15:18:55] [V] [TRT] Tactic: 6881279 Time: 1.90404\n",
      "[04/10/2022-15:18:55] [V] [TRT] Tactic: 7274495 Time: 2.10168\n",
      "[04/10/2022-15:18:55] [V] [TRT] Tactic: 7864319 Time: 2.48904\n",
      "[04/10/2022-15:18:55] [V] [TRT] Tactic: 7995391 Time: 1.65209\n",
      "[04/10/2022-15:18:55] [V] [TRT] Tactic: 8585215 Time: 1.98296\n",
      "[04/10/2022-15:18:56] [V] [TRT] Tactic: 8847359 Time: 1.35826\n",
      "[04/10/2022-15:18:56] [V] [TRT] Tactic: 8978431 Time: 1.4055\n",
      "[04/10/2022-15:18:56] [V] [TRT] Tactic: 9043967 Time: 1.28202\n",
      "[04/10/2022-15:18:56] [V] [TRT] Tactic: 9175039 Time: 1.38712\n",
      "[04/10/2022-15:18:56] [V] [TRT] Tactic: 9502719 Time: 1.78479\n",
      "[04/10/2022-15:18:56] [V] [TRT] Tactic: 9830399 Time: 1.63068\n",
      "[04/10/2022-15:18:57] [V] [TRT] Tactic: 9961471 Time: 1.48876\n",
      "[04/10/2022-15:18:57] [V] [TRT] Tactic: 10027007 Time: 1.79887\n",
      "[04/10/2022-15:18:57] [V] [TRT] Tactic: 10092543 Time: 1.7402\n",
      "[04/10/2022-15:18:57] [V] [TRT] Tactic: 10289151 Time: 1.54949\n",
      "[04/10/2022-15:18:57] [V] [TRT] Tactic: 10485759 Time: 1.85143\n",
      "[04/10/2022-15:18:57] [V] [TRT] Tactic: 10682367 Time: 2.43959\n",
      "[04/10/2022-15:18:58] [V] [TRT] Tactic: 10813439 Time: 1.64962\n",
      "[04/10/2022-15:18:58] [V] [TRT] Fastest Tactic: 9043967 Time: 1.28202\n",
      "[04/10/2022-15:18:58] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage4_unit1_conv2/Conv2D (CudnnConvolution)\n",
      "[04/10/2022-15:18:58] [V] [TRT] Tactic: 0 Time: 3.5444\n",
      "[04/10/2022-15:18:58] [V] [TRT] Tactic: 1 Time: 3.15389\n",
      "[04/10/2022-15:18:58] [V] [TRT] Tactic: 2 Time: 2.79976\n",
      "[04/10/2022-15:18:58] [V] [TRT] Tactic: 4 skipped. Scratch requested: 614596608, available: 268435456\n",
      "[04/10/2022-15:18:58] [V] [TRT] Tactic: 5 skipped. Scratch requested: 1145307136, available: 268435456\n",
      "[04/10/2022-15:18:58] [V] [TRT] Tactic: 6 Time: 3.16872\n",
      "[04/10/2022-15:18:58] [V] [TRT] Fastest Tactic: 2 Time: 2.79976\n",
      "[04/10/2022-15:18:58] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage4_unit1_conv2/Conv2D (CaskConvolution)\n",
      "[04/10/2022-15:18:58] [V] [TRT] StatefulPartitionedCall/model_1/stage4_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758\n",
      "[04/10/2022-15:18:58] [V] [TRT] Tactic: 1062367460111450758 Time: 4.26458\n",
      "[04/10/2022-15:18:58] [V] [TRT] StatefulPartitionedCall/model_1/stage4_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v0 Tactic: 1754984623894446479\n",
      "[04/10/2022-15:18:58] [V] [TRT] Tactic: 1754984623894446479 Time: 5.42011\n",
      "[04/10/2022-15:18:58] [V] [TRT] StatefulPartitionedCall/model_1/stage4_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v0 Tactic: 3611739942397549984\n",
      "[04/10/2022-15:18:58] [V] [TRT] Tactic: 3611739942397549984 Time: 3.12999\n",
      "[04/10/2022-15:18:58] [V] [TRT] StatefulPartitionedCall/model_1/stage4_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v1 Tactic: 3827454225649558724\n",
      "[04/10/2022-15:18:58] [V] [TRT] Tactic: 3827454225649558724 Time: 2.24151\n",
      "[04/10/2022-15:18:58] [V] [TRT] StatefulPartitionedCall/model_1/stage4_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379\n",
      "[04/10/2022-15:18:59] [V] [TRT] Tactic: 4337000649858996379 Time: 3.22473\n",
      "[04/10/2022-15:18:59] [V] [TRT] StatefulPartitionedCall/model_1/stage4_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441\n",
      "[04/10/2022-15:18:59] [V] [TRT] Tactic: 4501471010995462441 Time: 3.1494\n",
      "[04/10/2022-15:18:59] [V] [TRT] StatefulPartitionedCall/model_1/stage4_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826\n",
      "[04/10/2022-15:18:59] [V] [TRT] Tactic: 5137655947464784826 Time: 2.98676\n",
      "[04/10/2022-15:18:59] [V] [TRT] StatefulPartitionedCall/model_1/stage4_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929\n",
      "[04/10/2022-15:18:59] [V] [TRT] Tactic: 5288347012147084929 Time: 3.05756\n",
      "[04/10/2022-15:18:59] [V] [TRT] StatefulPartitionedCall/model_1/stage4_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 5921334924264294896\n",
      "[04/10/2022-15:18:59] [V] [TRT] Tactic: 5921334924264294896 Time: 1.73896\n",
      "[04/10/2022-15:18:59] [V] [TRT] StatefulPartitionedCall/model_1/stage4_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056\n",
      "[04/10/2022-15:18:59] [V] [TRT] Tactic: 6645123197870846056 Time: 3.15561\n",
      "[04/10/2022-15:18:59] [V] [TRT] StatefulPartitionedCall/model_1/stage4_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478\n",
      "[04/10/2022-15:18:59] [V] [TRT] Tactic: 7144526460361122478 Time: 4.65033\n",
      "[04/10/2022-15:18:59] [V] [TRT] StatefulPartitionedCall/model_1/stage4_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: 7852627285308570038\n",
      "[04/10/2022-15:18:59] [V] [TRT] Tactic: 7852627285308570038 Time: 2.16118\n",
      "[04/10/2022-15:18:59] [V] [TRT] StatefulPartitionedCall/model_1/stage4_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713\n",
      "[04/10/2022-15:18:59] [V] [TRT] Tactic: -9137461792520977713 Time: 3.14956\n",
      "[04/10/2022-15:18:59] [V] [TRT] StatefulPartitionedCall/model_1/stage4_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v0 Tactic: -8776506421218919509\n",
      "[04/10/2022-15:18:59] [V] [TRT] Tactic: -8776506421218919509 Time: 2.08369\n",
      "[04/10/2022-15:18:59] [V] [TRT] StatefulPartitionedCall/model_1/stage4_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730\n",
      "[04/10/2022-15:19:00] [V] [TRT] Tactic: -8262349710178828730 Time: 3.15705\n",
      "[04/10/2022-15:19:00] [V] [TRT] StatefulPartitionedCall/model_1/stage4_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v0 Tactic: -8133971918129952780\n",
      "[04/10/2022-15:19:00] [V] [TRT] Tactic: -8133971918129952780 Time: 3.62199\n",
      "[04/10/2022-15:19:00] [V] [TRT] StatefulPartitionedCall/model_1/stage4_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144\n",
      "[04/10/2022-15:19:00] [V] [TRT] Tactic: -6092040395344634144 Time: 4.45807\n",
      "[04/10/2022-15:19:00] [V] [TRT] StatefulPartitionedCall/model_1/stage4_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159\n",
      "[04/10/2022-15:19:00] [V] [TRT] Tactic: -4787320710726427159 Time: 5.38022\n",
      "[04/10/2022-15:19:00] [V] [TRT] StatefulPartitionedCall/model_1/stage4_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839\n",
      "[04/10/2022-15:19:00] [V] [TRT] Tactic: -3456450830548107839 Time: 3.57799\n",
      "[04/10/2022-15:19:00] [V] [TRT] StatefulPartitionedCall/model_1/stage4_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v0 Tactic: -2318106587342035239\n",
      "[04/10/2022-15:19:00] [V] [TRT] Tactic: -2318106587342035239 Time: 2.07626\n",
      "[04/10/2022-15:19:00] [V] [TRT] StatefulPartitionedCall/model_1/stage4_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_mobile_relu_tile148t_nt_v0 Tactic: -1343271414618805657\n",
      "[04/10/2022-15:19:00] [V] [TRT] Tactic: -1343271414618805657 Time: 1.58583\n",
      "[04/10/2022-15:19:00] [V] [TRT] StatefulPartitionedCall/model_1/stage4_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241\n",
      "[04/10/2022-15:19:00] [V] [TRT] Tactic: -1218658103698133241 Time: 3.60588\n",
      "[04/10/2022-15:19:00] [V] [TRT] StatefulPartitionedCall/model_1/stage4_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091\n",
      "[04/10/2022-15:19:00] [V] [TRT] Tactic: -836875257600482091 Time: 3.41277\n",
      "[04/10/2022-15:19:00] [V] [TRT] StatefulPartitionedCall/model_1/stage4_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746\n",
      "[04/10/2022-15:19:00] [V] [TRT] Tactic: -410470605513481746 Time: 2.99535\n",
      "[04/10/2022-15:19:00] [V] [TRT] Fastest Tactic: -1343271414618805657 Time: 1.58583\n",
      "[04/10/2022-15:19:00] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: FusedConvActConvolution Tactic: 9043967\n",
      "[04/10/2022-15:19:00] [V] [TRT] *************** Autotuning format combination: Float(25088,1,3584,512) -> Float(25088,1,3584,512) ***************\n",
      "[04/10/2022-15:19:00] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage4_unit1_conv2/Conv2D (CudnnConvolution)\n",
      "[04/10/2022-15:19:00] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:19:00] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage4_unit1_conv2/Conv2D (CaskConvolution)\n",
      "[04/10/2022-15:19:01] [V] [TRT] StatefulPartitionedCall/model_1/stage4_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824\n",
      "[04/10/2022-15:19:01] [V] [TRT] Tactic: -9153228964338181824 Time: 3.41253\n",
      "[04/10/2022-15:19:01] [V] [TRT] StatefulPartitionedCall/model_1/stage4_unit1_conv2/Conv2D Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025\n",
      "[04/10/2022-15:19:01] [V] [TRT] Tactic: -7394439838318485025 Time: 2.90556\n",
      "[04/10/2022-15:19:01] [V] [TRT] Fastest Tactic: -7394439838318485025 Time: 2.90556\n",
      "[04/10/2022-15:19:01] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7394439838318485025\n",
      "[04/10/2022-15:19:01] [V] [TRT] *************** Autotuning format combination: Half(25088,49,7,1) -> Half(25088,49,7,1) ***************\n",
      "[04/10/2022-15:19:01] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage4_unit1_conv2/Conv2D (CudnnConvolution)\n",
      "[04/10/2022-15:19:01] [V] [TRT] Tactic: 0 Time: 3.44862\n",
      "[04/10/2022-15:19:01] [V] [TRT] Tactic: 1 Time: 3.52011\n",
      "[04/10/2022-15:19:01] [V] [TRT] Tactic: 2 Time: 2.80757\n",
      "[04/10/2022-15:19:01] [V] [TRT] Tactic: 4 skipped. Scratch requested: 614596608, available: 268435456\n",
      "[04/10/2022-15:19:01] [V] [TRT] Tactic: 5 skipped. Scratch requested: 1145307136, available: 268435456\n",
      "[04/10/2022-15:19:01] [V] [TRT] Tactic: 6 Time: 5.02424\n",
      "[04/10/2022-15:19:01] [V] [TRT] Fastest Tactic: 2 Time: 2.80757\n",
      "[04/10/2022-15:19:01] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage4_unit1_conv2/Conv2D (CaskConvolution)\n",
      "[04/10/2022-15:19:01] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping\n",
      "[04/10/2022-15:19:01] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 2\n",
      "[04/10/2022-15:19:01] [V] [TRT] *************** Autotuning format combination: Half(12544,49:2,7,1) -> Half(12544,49:2,7,1) ***************\n",
      "[04/10/2022-15:19:01] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model_1/stage4_unit1_conv2/Conv2D (FusedConvActConvolution)\n",
      "[04/10/2022-15:19:01] [V] [TRT] Tactic: 524287 Time: 0.908848\n",
      "[04/10/2022-15:19:01] [V] [TRT] Tactic: 720895 Time: 1.68975\n"
     ]
    }
   ],
   "source": [
    "!/usr/src/tensorrt/bin/trtexec --verbose --fp16 --workspace=256 --maxBatch=1 --onnx=\"meilleur_model_colab/meilleur_model_colab.onnx\" --saveEngine=\"meilleur_model_colab/meilleur_modele_colab_FP16.engine\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60f2774-a197-4977-8a78-a83e9ec55de5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
