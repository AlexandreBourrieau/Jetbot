{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Suivi de trajectoire - Entrainement du modèle\n",
    "\n",
    "Dans ce notebook, nous allons entrainer le modèle qui prend en entrée une image et nous donne en sortie les coordonnées X,Y de la cible.\n",
    "\n",
    "Nous allons utiliser le modèle Resnet18 avec Keras / Tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from tensorflow import keras\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Téléchargement et extraction des données collectées \n",
    "\n",
    "Tout d'abord il faut récupérer les données collectées contenues dans le fichier ``dataset.zip`` que nous avons créé précedemment. Pour cela, il suffit d'exécuter la commande ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!unzip -q dataset.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un dossier nommé ``dataset_xy`` devrait apparaître dans l'explorateur de fichiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création du dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Récupération du chemin des images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "repertoires_images = []\n",
    "repertoire_courant = os.getcwd()\n",
    "for fichier in glob.glob(repertoire_courant+\"/dataset_xy/*.jpg\"):\n",
    "    repertoires_images.append(fichier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repertoires_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Création du dataset d'entrainement en type regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va créer le dataset en ajoutant à chaque entrée un label correspondant. Ce label sera les coordonnées X,Y extraites à partir du nom du fichier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction de création du dataset d'entrainement\n",
    "# à partir de la liste des fichiers\n",
    "\n",
    "# /home/alexandre/Notebook/Jetbot/Suivi_trajectoire/dataset_xy/xy_060_174_5dd5ae38-b8bc-11ec-a2fb-401c8381bcee.jpg\n",
    "\n",
    "def CreationDatasetRegression(liste_fichiers,width=224, height=224):\n",
    "    # Listes dans lesquelles ont va sauvegarder les images et les labels\n",
    "    images_= []\n",
    "    coordonnees_ = []\n",
    "\n",
    "    for fichier in liste_fichiers:\n",
    "        # Extraction des coordonnées (x0,Y0)\n",
    "        # correspondantes aux dimensions de l'image chargée (height,width)\n",
    "        element = tf.strings.split(fichier,sep=\"xy_\")\n",
    "        element = tf.strings.split(element[1],sep=\"_\")\n",
    "        x0 = (tf.strings.to_number(element[0],out_type=tf.dtypes.float32) - width/2) / (width/2)\n",
    "        y0 = (tf.strings.to_number(element[1],out_type=tf.dtypes.float32) - height/2) / (height/2)\n",
    "\n",
    "        # Chargement de l'image\n",
    "        image = tf.keras.preprocessing.image.load_img(fichier)\n",
    "        \n",
    "        # Transformations éventuelles de l'image\n",
    "        image = tf.image.random_saturation(tf.keras.preprocessing.image.img_to_array(image), 0.7, 1.3)\n",
    "        image = tf.image.random_hue(image, 0.3)\n",
    "        image = tf.image.random_brightness(image, 0.7, 1.3)\n",
    "        image = tf.image.random_contrast(image, 0.7, 1.3)\n",
    "\n",
    "        # Sauvegarde de l'image et des coordonnées dans les listes\n",
    "        images_.append(tf.cast(tf.keras.preprocessing.image.img_to_array(image),tf.uint8))\n",
    "        coordonnees_.append(np.asarray([x0,y0]))\n",
    "        \n",
    "        # Ajout d'une image inversée horizontalement\n",
    "        image = tf.image.flip_left_right(tf.keras.preprocessing.image.img_to_array(image))\n",
    "        x0 = -x0\n",
    "        images_.append(tf.cast(image,tf.uint8))\n",
    "        coordonnees_.append(np.asarray([x0,y0]))\n",
    "        \n",
    "    # Création du dataset\n",
    "    images_ = tf.convert_to_tensor(images_)                                # (nbr_images,224,224,3)\n",
    "    coordonnees_ = tf.convert_to_tensor(coordonnees_)                      # (nbr_images,2)\n",
    "\n",
    "    datasetImages = tf.data.Dataset.from_tensors(images_)                  # (nbr_images,224,224,3)\n",
    "    datasetCoordonnees = tf.data.Dataset.from_tensors(coordonnees_)        # (nbr_images,2) \n",
    "    dataset = tf.data.Dataset.zip((datasetImages,datasetCoordonnees))\n",
    "\n",
    "    return (dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_regression = CreationDatasetRegression(repertoires_images,224,224)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regardons à quoi ressemble le dataset :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image,coordonnees in dataset_regression.take(1):\n",
    "    print(image.shape)\n",
    "    print(coordonnees.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image,coordonnees in dataset_regression.take(1):\n",
    "    i = np.random.randint(0,len(repertoires_images)*2)\n",
    "    xs = np.int(224 * ((coordonnees[i,0]+1) / 2.0))\n",
    "    ys = np.int(224 * ((coordonnees[i,1]+1) / 2.0))\n",
    "\n",
    "    image = cv2.circle(np.array(image[i,:,:,:]), (xs,ys), 8, (255, 0, 0), 3)\n",
    "    image = cv2.line(np.array(image),(112,224),(xs,ys),(0,0,255),3)\n",
    "    plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On redimensionne le dataset au bon batch_size :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "dataset_regression = dataset_regression.unbatch()\n",
    "dataset_regression = dataset_regression.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image,coordonnees in dataset_regression.take(1):\n",
    "    print(image.shape)\n",
    "    print(coordonnees.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Séparation du dataset en dataset d'entrainement et de validation\n",
    "On réserve 90% des images pour l'entrainement et 10% pour les validations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pourcentage_entrainement = 0.8\n",
    "\n",
    "# Récupère la taille du dataset\n",
    "taille_dataset = len(list(dataset_regression))\n",
    "\n",
    "# Calcul des tailles d'entrainement et de validation\n",
    "taille_entrainement = int(pourcentage_entrainement * taille_dataset)\n",
    "taille_validation = int((1-pourcentage_entrainement) * taille_dataset)\n",
    "\n",
    "# Mélange du dataset\n",
    "dataset_regression = dataset_regression.shuffle(taille_dataset)\n",
    "\n",
    "# Création des dataset d'entrainement et de validation\n",
    "dataset_entrainement = dataset_regression.take(taille_entrainement)\n",
    "dataset_validation = dataset_regression.take(taille_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création du modèle Restnet-18 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install git+https://github.com/qubvel/classification_models.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import classification_models\n",
    "from classification_models.tfkeras import Classifiers\n",
    "\n",
    "# Chargement du modèle ResNEt18\n",
    "ResNet18, preprocess_input = Classifiers.get('resnet18')\n",
    "\n",
    "# Instanciation du modèle pré-entrainé ResNet18\n",
    "base_model = ResNet18(input_shape=(224,224,3), weights='imagenet', include_top=False, pooling=False)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=base_model.input, outputs=base_model.output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Désactivation des couches pour l'entrainement\n",
    "#for layer in base_model.layers:\n",
    "#    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On ajoute ensuite la couche d'applatissemnt des sorties et la couche dense avec 2 neurones (1 neurone par coordonée) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajout de l'applatissement des sorties et de la couche dense avec 2 neurones\"\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "output = tf.keras.layers.Dense(units=2, activation=\"linear\")(x)\n",
    "\n",
    "# Création du modèle global\n",
    "model = tf.keras.Model(inputs=[base_model.input], outputs=[output])\n",
    "\n",
    "# Affichage des informations sur le modèle\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrainement en régression:\n",
    "\n",
    "On entraine le modèle sur 100 périodes. Cette fois on utilise l'erreur MSE (Mean Square Error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Nombre de périodes d'entrainement\n",
    "periodes = 100\n",
    "\n",
    "# Définition de la fonction d'enregistrement automatique du meilleur modèle\n",
    "model_save = ModelCheckpoint('meilleur_modele.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "\n",
    "# Définition de l'ooptimiseur\n",
    "adam = keras.optimizers.Adam(learning_rate=1e-3)\n",
    "\n",
    "# Entrainement du modèle : from_logits=True car on utilise un Softmax en sortie de notre modèle\n",
    "model.compile(optimizer=adam, loss='mse')\n",
    "historique = model.fit(dataset_entrainement,validation_data=dataset_validation,verbose=1,epochs=periodes, callbacks=[model_save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = historique.history['loss']\n",
    "val_loss = historique.history['val_loss']\n",
    "\n",
    "intervalle_periodes = range(periodes)\n",
    "\n",
    "plt.plot(intervalle_periodes, loss, label=\"Erreur d'entrainement\")\n",
    "plt.plot(intervalle_periodes, val_loss, label=\"Erreur de validation\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.title(\"Erreur d'entrainement et de validation\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
