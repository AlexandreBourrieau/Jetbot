{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a28a4aff-6905-42a8-ae17-c007acbc8077",
   "metadata": {},
   "source": [
    "# Démonstration du modèle TensorRT en temps réel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c34835d-78d5-4be6-9290-dd7d93675b77",
   "metadata": {},
   "source": [
    "Dans ce carnet, nous allons étudier comment faire suivre au Jetbot un objet spécifique. Nous allons utiliser un modèle pré-entrainé SSD-MobileNet V2 sur le dataset COCO qui est composé de 90 classes d'objets. Parmi ces objets on trouve :\n",
    "- Personnes (index 0)\n",
    "- Coupe (index 47)\n",
    "\n",
    "et plein d'autres (vous pouvez trouver les index dans ce fichier : https://github.com/tensorflow/models/blob/master/research/object_detection/data/mscoco_label_map.pbtxt).\n",
    "\n",
    "Ce modèle a précédemment été optimisé avec TensorRT ce qui le rend très rapide. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8da7f2-ebf7-4ccf-9a39-83c0fd5aeff2",
   "metadata": {},
   "source": [
    "### Classe de capture et de traitement du flux vidéo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ea398c-dd29-45e7-b02a-b8eac796c436",
   "metadata": {},
   "source": [
    "La classe suivante est hérité des Threading et prend en charge :\n",
    "\n",
    "- L'initialisation de la caméra et du moteur TensorRT\n",
    "- La capture du flux vidéo et son traitement avec le modèle, exécuté dans le programme principal du thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "414c601c-13b0-461c-9f6e-14425b489cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorrt as trt\n",
    "import numpy as np\n",
    "import pycuda.driver as cuda\n",
    "import threading\n",
    "import ctypes\n",
    "import time\n",
    "import traitlets\n",
    "import atexit\n",
    "import cv2\n",
    "\n",
    "class TRTInference(threading.Thread):\n",
    "    def __init__(self,repertoire_engine, repertoire_labels, widget_image,\n",
    "                 type_camera=\"CSI\",capture_device=\"0\",capture_width=\"320\",capture_height=\"320\",\n",
    "                 display_width=\"320\",display_height=\"320\",fps=\"30\",flip=0):\n",
    "        threading.Thread.__init__(self)\n",
    "        self.widget_image = widget_image\n",
    "        self.type_camera = type_camera\n",
    "        self.capture_device = capture_device\n",
    "        self.capture_width = capture_width\n",
    "        self.capture_height = capture_height\n",
    "        self.display_width = display_width\n",
    "        self.display_height = display_height\n",
    "        self.fps = fps\n",
    "        self.flip = flip\n",
    "        self.camera_on = False\n",
    "\n",
    "        # Initialisation des variables de la caméra\n",
    "        self._running = False\n",
    "        self.image = np.zeros((self.display_height, self.display_width, 3), dtype=np.uint8)\n",
    "        if self.type_camera.find(\"CSI\")>=0:\n",
    "            self.cap = cv2.VideoCapture(self._gstreamer_pipeline_CSI(),cv2.CAP_GSTREAMER)\n",
    "        else:\n",
    "            self.cap = cv2.VideoCapture(self._gstreamer_pipeline_USB(),cv2.CAP_GSTREAMER)\n",
    "        if self.cap.isOpened():\n",
    "            print(\"Caméra initialisée\")\n",
    "        else:\n",
    "            print(\"Erreur d'ouverture du flux vidéo\")\n",
    "        atexit.register(self.cap.release)\n",
    "\n",
    "        # Initialisation du runtime TensorRT\n",
    "        #self.logger = MyLogger()\n",
    "        self.logger = trt.Logger(trt.Logger.INFO)\n",
    "        trt.init_libnvinfer_plugins(self.logger, namespace=\"\")\n",
    "        self.runtime = trt.Runtime(self.logger)\n",
    "        \n",
    "        # Chargement du moteur\n",
    "        print(\"Chargement du moteur...\")\n",
    "        with open(repertoire_engine, \"rb\") as f:\n",
    "            self.engine = self.runtime.deserialize_cuda_engine(f.read())\n",
    "        \n",
    "        self.context = self.engine.create_execution_context()\n",
    " \n",
    "        #Initialisation du context Cuda et du contexte TensorRT \n",
    "        cuda.init()\n",
    "        self.cudactx = cuda.Device(0).retain_primary_context()\n",
    "        self.cudactx.push()\n",
    "        self.context.debug_sync = True\n",
    "        \n",
    "        # Réservation de la mémoire pour l'entrée\n",
    "        print(\"Allocation mémoire...\")\n",
    "        size_input = trt.volume(self.engine.get_binding_shape(0))*self.engine.max_batch_size\n",
    "        self.input_host_mem = cuda.pagelocked_empty(size_input, np.float32)\n",
    "        self.input_device_mem = cuda.mem_alloc(self.input_host_mem.nbytes)\n",
    "\n",
    "        # Réservation de la mémoire pour les sorties\n",
    "        self.output_device_mem = [];\n",
    "        format_sorties = [];\n",
    "        types_sorties = [];\n",
    "\n",
    "        for i in range(self.engine.num_bindings):\n",
    "            if not self.engine.binding_is_input(i):\n",
    "                size_output = trt.volume(self.engine.get_binding_shape(i))*self.engine.max_batch_size\n",
    "                output_hm = cuda.pagelocked_empty(size_output,trt.nptype(self.engine.get_binding_dtype(i)))\n",
    "                self.output_device_mem.append(cuda.mem_alloc(output_hm.nbytes))\n",
    "                format_sorties.append(self.engine.get_binding_shape(i))\n",
    "                types_sorties.append(trt.nptype(self.engine.get_binding_dtype(i)))\n",
    "\n",
    "        # Récupère les adresses en GPU des buffers entrées / sorties\n",
    "        binding_entree = int(self.input_device_mem)\n",
    "        binding_sorties = []\n",
    "\n",
    "        for output_ in self.output_device_mem:\n",
    "            binding_sorties.append(int(output_))\n",
    "        self.bindings = [binding_entree, binding_sorties[0],binding_sorties[1],binding_sorties[2],binding_sorties[3]]\n",
    "\n",
    "        # Allocation de la mémoire hote pour les sorties\n",
    "        self.output_host_mem = []\n",
    "        for i in range(len(self.output_device_mem)):\n",
    "            self.output_host_mem.append(np.zeros(format_sorties[i],types_sorties[i]))\n",
    "        \n",
    "        # Input tensor\n",
    "        self.image = np.zeros((320,320,3), dtype=trt.nptype(self.engine.get_binding_dtype(0)))\n",
    "\n",
    "        # Initialisation des labels\n",
    "        self.classes = self.read_label_map(repertoire_labels)\n",
    "\n",
    "        self.cudactx.pop()\n",
    "\n",
    "    # Lectures de labels\n",
    "    def read_label_map(self,label_map_path):\n",
    "        item_id = None\n",
    "        item_name = None\n",
    "        items = {}\n",
    "\n",
    "        with open(label_map_path, \"r\") as file:\n",
    "            for line in file:\n",
    "                line.replace(\" \", \"\")\n",
    "                if line == \"item{\":\n",
    "                    pass\n",
    "                elif line == \"}\":\n",
    "                    pass\n",
    "                elif \"id\" in line:\n",
    "                    item_id = int(line.split(\":\", 1)[1].strip())\n",
    "                elif \"display_name\" in line:\n",
    "                    item_name = line.split(\" \")[-1].replace(\"\\\"\", \" \").strip()\n",
    "                if item_id is not None and item_name is not None:\n",
    "                    items[item_id] = item_name\n",
    "                    item_id = None\n",
    "                    item_name = None\n",
    "        return items\n",
    "\n",
    "    # Inférence\n",
    "    def Calcul(self):\n",
    "        # Copie de l'image dans le tenseur d'entrée\n",
    "        x = self.image.astype(np.float32)\n",
    "        x = np.expand_dims(x,axis=0)                    # (1,320,320,3)\n",
    "        np.copyto(self.input_host_mem,x.ravel())\n",
    "        \n",
    "        # Transfert de l'entrée vers le GPU\n",
    "        self.cudactx = cuda.Device(0).retain_primary_context()\n",
    "        self.cudactx.push()\n",
    "        cuda.memcpy_htod(self.input_device_mem, self.input_host_mem)\n",
    "        \n",
    "        # Appel du modèle\n",
    "        self.context.execute(batch_size=1, bindings=self.bindings)\n",
    "        \n",
    "        # Récupération des sorties\n",
    "        for i in range(len(self.output_host_mem)):\n",
    "            cuda.memcpy_dtoh(self.output_host_mem[i], self.output_device_mem[i])\n",
    "        self.cudactx.pop()\n",
    "\n",
    "        # Affiche le rectangle sur les objets détectés\n",
    "        for i in range(2):\n",
    "            ymin = int(320 * self.output_host_mem[1][0,i,0])\n",
    "            xmin = int(320 * self.output_host_mem[1][0,i,1])\n",
    "            ymax = int(320 * self.output_host_mem[1][0,i,2])\n",
    "            xmax = int(320 * self.output_host_mem[1][0,i,3])\n",
    "\n",
    "            cv2.rectangle(self.image, (xmin,ymin),\n",
    "                          (xmax, ymax),\n",
    "                          (255, 0, 0), 1)\n",
    "            cv2.putText(self.image,\n",
    "                        str(self.classes.get(1+self.output_host_mem[3][0,i])),\n",
    "                        (xmin,ymin+20),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        0.6,\n",
    "                        (0, 255, 0),\n",
    "                        1,\n",
    "                        cv2.LINE_AA)\n",
    "\n",
    "    # Lecture d'une frame\n",
    "    def capture_image(self):\n",
    "        re, image = self.cap.read()\n",
    "        if re:\n",
    "            image_resized = cv2.resize(image,(int(self.display_width),int(self.display_height)))\n",
    "            return image_resized\n",
    "        else:\n",
    "            return self.image\n",
    "        \n",
    "    def run(self):\n",
    "        while True:\n",
    "            if self.camera_on is True:\n",
    "                self.image = self.capture_image()\n",
    "                self.Calcul()\n",
    "                self.widget_image.value = bgr8_to_jpeg(self.image)\n",
    "                time.sleep(0.001)\n",
    "\n",
    "    # Définition du pipeline pour la caméra CSI\n",
    "    def _gstreamer_pipeline_CSI(self):\n",
    "        return(\"nvarguscamerasrc sensor-id=%d ! \"\n",
    "                \"video/x-raw(memory:NVMM),\"\n",
    "                \"width=(int)%d,height=(int)%d,\"\n",
    "                \"format=(string)NV12, framerate=(fraction)%d/1 ! \"\n",
    "                \"nvvidconv flip-method=%d ! \"\n",
    "                \"video/x-raw,\"\n",
    "                \"width=(int)%d,height=(int)%d,\"\n",
    "                \"format=(string)BGRx ! videoconvert ! \"\n",
    "                \"video/x-raw, format=(string)BGR ! \"\n",
    "                \"appsink drop=true\"\n",
    "        %(self.capture_device,self.capture_width,self.capture_height,self.fps,self.flip, self.display_width,self.display_height))\n",
    "\n",
    "    # Définition du pipeline pour la USB\n",
    "    def _gstreamer_pipeline_USB(self):\n",
    "        return(\"v4l2src device=/dev/video%d ! \"\n",
    "               \"video/x-raw, width=(int)%d, height=(int)%d, framerate=(fraction)%d/1 ! \"\n",
    "               \"videoflip method=%d ! \"\n",
    "               \"videoconvert ! \"\n",
    "               \"video/x-raw, format=(string)BGR ! appsink drop=true\"\n",
    "        %(self.capture_device,self.capture_width,self.capture_height,self.fps,self.flip))            \n",
    "\n",
    "    # Routine pour arrêter le Thread\n",
    "    def raise_exception(self):\n",
    "        for id, thread in threading._active.items():\n",
    "            if thread is self:\n",
    "                thread_id = id\n",
    "        res = ctypes.pythonapi.PyThreadState_SetAsyncExc(thread_id,ctypes.py_object(SystemExit))\n",
    "        if res > 1:\n",
    "            ctypes.pythonapi.PyThreadState_SetAsyncExc(thread_id, 0)\n",
    "            print('Exception raise failure')\n",
    "\n",
    "    def destroy(self):\n",
    "        self.cudactx.detach()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def20f89-5cf1-4ab4-aa0a-747eda87b77f",
   "metadata": {},
   "source": [
    "### Interface de visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "770e6db1-a140-4507-832e-c666b5198af2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c6a52ca0e3243ab913a4e5041960478",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Image(value=b'', format='jpeg', height='320', width='320'),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets.widgets as widgets\n",
    "import traitlets\n",
    "from IPython.display import display\n",
    "from jetbot import bgr8_to_jpeg\n",
    "\n",
    "# Création de l'interface\n",
    "image_widget = widgets.Image(format='jpeg', width=320, height=320)\n",
    "\n",
    "# Affichage de l'interface\n",
    "display(widgets.VBox([image_widget]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10a0eee4-db1e-4537-987a-e1a0fdaaffeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caméra initialisée\n",
      "Chargement du moteur...\n",
      "Allocation mémoire...\n"
     ]
    }
   ],
   "source": [
    "trt_inference_wrapper = TRTInference(repertoire_engine=\"tfmodel_ssd_mobilenet_v2_320x320_coco17_tpu-8/model.engine\",\n",
    "                        repertoire_labels=\"models/research/object_detection/data/mscoco_complete_label_map.pbtxt\",\n",
    "                        widget_image=image_widget,\n",
    "                        type_camera=\"CSI\",capture_device=0,\n",
    "                        capture_width=320,capture_height=320,\n",
    "                        display_width=320,display_height=320,\n",
    "                        fps=30,flip=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ff8b348-25db-4fac-b7ec-ad4b0869b4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trt_inference_wrapper.start()\n",
    "trt_inference_wrapper.camera_on = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9548e1a-45ec-4990-8891-b49644b1ba64",
   "metadata": {},
   "source": [
    "### Arrêt de la caméra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11e96724-f54c-475b-bd7a-e2653708aedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "trt_inference_wrapper.camera_on = False"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
