{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "176edbf8-89fc-4cf7-84e7-14544b45c006",
   "metadata": {},
   "source": [
    "# Utilisation du modèle TensorRT optimisé"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736f84be-b780-4645-829d-29f6c99c1dd0",
   "metadata": {},
   "source": [
    "Dans ce Notebook, nous allons étudier comment utiliser un modèle optimisé avec TensorRT à l'aide de Cuda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8ba5e2-e088-4efc-a3e9-4966ca7ed970",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from tensorflow import keras\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed13e997-6eb0-40fd-b06d-a93f4b1e2dd6",
   "metadata": {},
   "source": [
    "### Chargement du moteur (engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636308cf-cd5a-4b21-a3af-dd0617695690",
   "metadata": {},
   "source": [
    "On commence par créer une instance de logger qui va nous permettre d'afficher les informations pendant l'utilisation du moteur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed48f90-4c29-46d9-a847-0faea9bb3d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorrt as trt\n",
    "\n",
    "# Construction de la class du logger\n",
    "class MyLogger(trt.ILogger):\n",
    "    def __init__(self):\n",
    "        trt.ILogger.__init__(self)\n",
    "\n",
    "    def log(self, severity, msg):\n",
    "        print(\"%s : %s\" %(severity,msg))\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f5bd6a-39bd-4459-a1a8-40edaaec3855",
   "metadata": {},
   "source": [
    " Ensuite, on créé un ``runtime`` (environnement de travail) pour notre modèle puis on charge le moteur à l'aide de la fonction ``deserialize_cuda_engine`` que nous porpose ce runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8e38f6-4242-482c-a6bb-1d2ec74c2e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "\n",
    "PRECISION = trt.float32\n",
    "\n",
    "logger = MyLogger()\n",
    "runtime = trt.Runtime(logger)\n",
    "trt.init_libnvinfer_plugins(logger, namespace=\"\")\n",
    "    \n",
    "with open(\"tfmodel_ssd_mobilenet_v2_320x320_coco17_tpu-8/model.engine\", \"rb\") as f:\n",
    "    engine = runtime.deserialize_cuda_engine(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997143cf-9e05-4e82-a3ba-956dc282517a",
   "metadata": {},
   "source": [
    " ### Création du contexte"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b277e47e-469a-43be-8d07-45276bd3d9ff",
   "metadata": {},
   "source": [
    "Ensuite, il faut créer un contexte nécessaire pour lancer le modèle. Ce contexte va allouer une certaine quantité de mémoire afin de pouvoir travailler avec notre mmoteur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc9a9e5-8a8e-4047-810b-8fe50aeb5d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = engine.create_execution_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec81f66f-0b53-4791-a40e-79b9b23307a3",
   "metadata": {},
   "source": [
    "### Allocation de l'espace mémoire hôte et GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c37afa-1284-4dc3-a0a6-5c1942ae1cb0",
   "metadata": {},
   "source": [
    "Nous allons devoir allouer de l'espace en mémoire sur **l'hote** et sur le **GPU** pour réaliser des transferts de données entre eux.\n",
    "Commençons par regarder combien de mémoire nous avons en GPU :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26fd880-c7ee-4805-98e2-bcb3d5c92e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda.mem_get_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f271b23f-6314-4fc5-b079-ad6c5362fe9c",
   "metadata": {},
   "source": [
    "Pour transférer des données entre l'hôte et le GPU, celles-ci doivent être transférées depuis un espace mémoire paginé vérrouillé de l'hôte. On va donc devoir réserver un espace mémoire sur l'hôte et le vérrouiller (cet espace ne pourra pas servir à autre chose et donc ne pourra pas être utlisé par un autre processus).\n",
    "\n",
    "Les étapes à suivre pour utliser notre moteur sont les suivantes :\n",
    "- Réserver un espace mémoire vérrouillé sur l'hote pour y placer l'entrée (**input_host_mem**) et la sortie du modèle (**output_host_mem**)\n",
    "- Réserver un espace mémoire dans le GPU pour y placer ces mêmes informations (**input_device_mem** et **output_device_mem**)\n",
    "- Placer les données d'entrées du modèle (notre image) dans l'espace mémoire hôte vérrouillé qu'on a pris soin de réserver au préalable (**input_host_mem**)\n",
    "- Transférer le contenu de cet espace mémoire vers la mémoire du GPU (**input_device_mem**)\n",
    "- Lancer les calculs avec le modèle TensorRT qu'on a défini ; les résultats seront écrits dans la mémoire du GPU (**output_device_mem**)\n",
    "- Transférer les résultats de la mémoire GPU (**output_device_mem**) vers la mémoire vérrouillées de l'hote (**output_host_mem**)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48f9a49-8f2a-486c-8c6f-d96deb70a8f5",
   "metadata": {},
   "source": [
    "On peut trouver des informations sur le format des tenseurs en entrée et en sortie de notre moteur :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2af96c-7cc5-4a59-9874-d52cb3eeab92",
   "metadata": {},
   "outputs": [],
   "source": [
    "for binding in engine:\n",
    "    print(engine.get_binding_shape(binding))\n",
    "    print(trt.nptype(engine.get_binding_dtype(binding)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9099a1a-c400-40d1-a276-37eaec754c2d",
   "metadata": {},
   "source": [
    "On va donc utiliser ces informations pour allouer les espaces en mémoire hôte et GPU :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c93c11-cd64-4382-b42b-7e3cf7a8bb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Réservation de la mémoire pour l'entrée\n",
    "size_input = trt.volume(engine.get_binding_shape(0))* engine.max_batch_size\n",
    "input_host_mem = cuda.pagelocked_empty(size_input, trt.nptype(PRECISION))\n",
    "input_device_mem = cuda.mem_alloc(input_host_mem.nbytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a3284e-14fa-4f7b-b2f8-f717f1b46b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Réservation de la mémoire pour les sorties\n",
    "output_device_mem = [];\n",
    "format_sorties = [];\n",
    "types_sorties = [];\n",
    "\n",
    "for i in range(engine.num_bindings):\n",
    "    if not engine.binding_is_input(i):\n",
    "        size_output = trt.volume(engine.get_binding_shape(i))* engine.max_batch_size\n",
    "        output_host_mem = cuda.pagelocked_empty(size_output, trt.nptype(PRECISION))\n",
    "        output_device_mem.append(cuda.mem_alloc(output_host_mem.nbytes))\n",
    "        format_sorties.append(engine.get_binding_shape(i))\n",
    "        types_sorties.append(trt.nptype(engine.get_binding_dtype(i)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b204693c-dc3c-48e5-96a3-01c70c60297e",
   "metadata": {},
   "source": [
    "Il faut maintenant récupérer les adresses mémoires GPU. Ces adresses seront utiles au contexte de TensorRT précédemment ouvert pour pouvoir exécuter le modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ee2115-5c7c-4ccb-b190-f9e98bcfa97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupère les adresses en GPU des buffers entrées / sorties\n",
    "binding_entree = int(input_device_mem)\n",
    "\n",
    "binding_sorties = []\n",
    "for output_ in output_device_mem:\n",
    "    binding_sorties.append(int(output_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4f871e-322f-4d0a-8457-fff29b876706",
   "metadata": {},
   "source": [
    "### Exécution d'une prédiction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800f796d-78fe-4e75-9005-cbf2f8656df9",
   "metadata": {},
   "source": [
    "On commence par récupérer une image du dataset :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5bd1f5-0544-449e-ac3e-f0fa49722f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = tf.keras.preprocessing.image.load_img(\"models/research/object_detection/test_images/image2.jpg\",\n",
    "                                             target_size=(320, 320))\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362e169d-7359-4a93-a0e2-363b35eaf139",
   "metadata": {},
   "source": [
    "Puis on convertit cette image en tenseur :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e4cd14-a070-4a69-836b-f0f2654d6566",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = tf.keras.preprocessing.image.img_to_array(image)\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d9b3c1-95fb-4bbb-bd8e-55428bf5cc76",
   "metadata": {},
   "source": [
    "On copie maintenant ce tenseur dans l'espace mémoire d'entrée de l'hôte. Le tenseur est applati à l'aide de la fonction ``ravel()``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95653c42-a71a-404c-bbb1-4908beda0695",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.expand_dims(image,axis=0)                          # (1,320,320,3)\n",
    "np.copyto(input_host_mem,image.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be91479d-9207-4259-9d84-b3d3b943f56a",
   "metadata": {},
   "source": [
    "Transfert les données de l'image vers la mémoire GPU (transfert Host => Device) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c2ef78-aa49-4937-a6d6-39028acae09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda.memcpy_htod(input_device_mem, input_host_mem)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06009440-41db-43fc-ae32-87085bd76a13",
   "metadata": {},
   "source": [
    "Exécution du modèle :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab678ad-083c-480b-85a6-dc0cea31d32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bindings = [binding_entree, binding_sorties[0],binding_sorties[1],binding_sorties[2],binding_sorties[3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428aa6f7-aa50-4302-8617-65dd0d9427a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bindings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427deaf4-8826-49c3-ab26-6d92a49d0781",
   "metadata": {},
   "outputs": [],
   "source": [
    "context.execute(batch_size=1,bindings=bindings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593784d6-8be0-46e9-bc23-743376a80dab",
   "metadata": {},
   "source": [
    "On transfert le résultat stocké en mémoire GPU vers la mémoire destination de l'hôte :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b547ced-8b1d-47b2-ab79-bb5d349dbad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_device_mem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809b042b-b359-4f25-ba6f-101f91a10b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_host_mem = []\n",
    "for i in range(len(output_device_mem)):\n",
    "    output_host_mem.append(np.zeros(format_sorties[i],types_sorties[i]))\n",
    "\n",
    "for i in range(len(output_host_mem)):\n",
    "    cuda.memcpy_dtoh(output_host_mem[i], output_device_mem[i])\n",
    "output_host_mem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4145daa-12a3-42b2-a335-1131146e1495",
   "metadata": {},
   "source": [
    "## Visualisation du résultat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3884c7-736e-4187-924d-9d1e97c90317",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageDraw\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "\n",
    "def draw_bbox_and_label_in_image(img, boxes, num_detections, box_width=3):\n",
    "    \"\"\"\n",
    "    Draw bounding boxes and class labels in images\n",
    "    :param img: PIL Image or np arrays\n",
    "    :param boxes: in size [num_detections, 4], contains xys or boxes\n",
    "    :param box_width: the width of boxes\n",
    "    :return: Image\n",
    "    \"\"\"\n",
    "\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    width, height = img.size\n",
    "\n",
    "    for i in range(num_detections):\n",
    "        ymin, xmin, ymax, xmax = boxes[i]\n",
    "\n",
    "        ymin = int(ymin * height)\n",
    "        ymax = int(ymax * height)\n",
    "        xmin = int(xmin * width)\n",
    "        xmax = int(xmax * width)\n",
    "\n",
    "        class_color = \"LimeGreen\"\n",
    "\n",
    "        draw.line([(xmin, ymin), (xmax, ymin), (xmax, ymax), (xmin, ymax), (xmin, ymin)], width=box_width, fill=class_color)\n",
    "\n",
    "    return img\n",
    "\n",
    "img_data = tf.io.gfile.GFile('models/research/object_detection/test_images/image2.jpg', 'rb').read()\n",
    "image = Image.open(BytesIO(img_data))\n",
    "\n",
    "draw_image = draw_bbox_and_label_in_image(image, output_host_mem[1][0,0:3,:],3)\n",
    "draw_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d6d909-e0f9-4cad-acfe-9024cbdaf2ad",
   "metadata": {},
   "source": [
    "Enfin pour terminer, on libère la mémoire allouée :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b635e6-29b6-49fd-9fe0-708f4ba950cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_device_mem.free()\n",
    "for i in range(len(output_device_mem)):\n",
    "    output_device_mem[i].free()\n",
    "del input_host_mem\n",
    "del output_host_mem\n",
    "del context\n",
    "del engine"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
