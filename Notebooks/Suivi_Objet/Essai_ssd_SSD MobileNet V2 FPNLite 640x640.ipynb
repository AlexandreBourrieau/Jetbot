{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6mL51GS_g07x"
   },
   "source": [
    "# Téléchargement et installation des libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u14QW7Kug070"
   },
   "source": [
    "### Clonage du dépot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "keo1XMPzg072"
   },
   "source": [
    "URL du dépot : https://github.com/tensorflow/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DiPwgcnqIvc5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Installation du dépot Tensorflow Models\n",
    "!git clone --recursive https://github.com/tensorflow/models.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OHysyFcTg076"
   },
   "source": [
    "Le tableau à cette adresse récapitule les informations des différents modèles disponnibles. Il permet également d'obtenir les liens pour les télécharger : https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C9WDvIKSg076"
   },
   "source": [
    "### Installation des librairies Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gT1-4kE6g077"
   },
   "source": [
    "L'adresse suivante exlique comment installer les librairies Python pour utiliser les modèles : https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wagszkLLg077"
   },
   "outputs": [],
   "source": [
    "%cd models/research\n",
    "\n",
    "# Compile protos.\n",
    "!protoc object_detection/protos/*.proto --python_out=.\n",
    "\n",
    "# Install TensorFlow Object Detection API.\n",
    "!cp object_detection/packages/tf2/setup.py .\n",
    "!python3 -m pip install ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vIIvuOVCg078"
   },
   "source": [
    "# Téléchargement du modèle et configuration de l'environnement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rdIomjzbg078"
   },
   "source": [
    "### Téléchargement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "347xxhUCg079"
   },
   "outputs": [],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ovbJ7m92tcv0"
   },
   "outputs": [],
   "source": [
    "# Téléchargement du modèle ssd_mobilenet_v2_fpnlite_640x640_coco17\n",
    "\n",
    "!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz\n",
    "!tar -zxf ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz\n",
    "!rm ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CIgPBApxEoVc"
   },
   "source": [
    "Après le téléchargement, on exporte le modèle en utilisant les propriétés du fichier de configuration `pipeline.config` et en utlisant les fichiers `checkpoint`. Pour cela on utilise le programme `TensorFlow Object Detection Exporter`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4slEHDTDg07-"
   },
   "source": [
    "### Configuration des variables d'environnement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UGSaJX1XF_VN"
   },
   "outputs": [],
   "source": [
    "%set_env PYTHONPATH=\"/env/python:models/research:models/research/slim:/models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h5KonNacLfr8"
   },
   "outputs": [],
   "source": [
    "!mkdir tfmodel_ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vpP8756jg08B"
   },
   "source": [
    "### Installation des packages supplémentaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9IUT4cngg08B"
   },
   "outputs": [],
   "source": [
    "!pip3 install tf_slim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lHTyU5Wrg08D"
   },
   "source": [
    "# Création du modèle pré-entrainé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_WOHr0AgLkf7"
   },
   "outputs": [],
   "source": [
    "!python3 models/research/object_detection/exporter_main_v2.py \\\n",
    "    --input_type float_image_tensor --trained_checkpoint_dir ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/checkpoint \\\n",
    "    --pipeline_config_path ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/pipeline.config \\\n",
    "    --output_directory tfmodel_ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eAE6WWydOjZ-"
   },
   "source": [
    "# Utilisation du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "krK7bXyJg08F"
   },
   "source": [
    "### Informations sur le modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rI4U5M6yUCaz"
   },
   "outputs": [],
   "source": [
    "!saved_model_cli show --dir tfmodel_ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/saved_model --all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UXiCdSyWg08G"
   },
   "source": [
    "### Chargement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MfJp_4oCR_Oc"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model_path = \"tfmodel_ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/saved_model\"\n",
    "model = tf.saved_model.load(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v6R2vDFKg08H"
   },
   "source": [
    "### Chargement d'une image dans le tenseur d'entrée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uNPKC5p2UdUm"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "from io import BytesIO\n",
    "\n",
    "img_data = tf.io.gfile.GFile('models/research/object_detection/test_images/image2.jpg', 'rb').read()\n",
    "image = Image.open(BytesIO(img_data))\n",
    "(im_width, im_height) = image.size\n",
    "image_np  = np.array(image.getdata()).reshape((im_height, im_width, 3)).astype(np.uint8)\n",
    "input_tensor = np.expand_dims(image_np, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X1pA_Z6cg08I"
   },
   "outputs": [],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "06DBQ2F7g08I"
   },
   "source": [
    "### Traitement de l'image avec le modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b9Y6dzUsXLBk"
   },
   "outputs": [],
   "source": [
    "detections = model(input_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8K-LfljZg08J"
   },
   "source": [
    "### Structure de la sortie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1O7HiaFWg08J"
   },
   "source": [
    "La sortie est un dictionnaire qui contient les informations suivantes :\n",
    "- `num_detections` : Tenseur au format [N] (type tf.int) qui contient le nombre de détections.\n",
    "- `detection_boxes` : Tenseur au format [N,4] (type tf.float32) qui contient les coordonnées des boites au format [ymin, xmin, ymax, xmax].\n",
    "- `detection_classes` : Tenseur au format [N] (type tf.int) qui contient l'index des classes contenues dans le fichier des labels.\n",
    "- `detection_scores` : Tenseur au format [N] (type tf.float32) qui contient les scores de détection.\n",
    "- `raw_detection_boxes` : Tenseur au format [1,M,4] (type tf.float32) qui contient les coordonnées des boites sans supressions Non-Max.\n",
    "- `raw_detection_scores` : Tenseur au format [1,M,91] (type tf.float32) qui contient les scores des classes au format logits des boites précédentes.\n",
    "- `detection_anchor_indices` : Tenseur au format [N] (type tf.float32) qui contient les indices des ancres des détections après suppression Non-Max.\n",
    "- `detection_multiclass_scores` : Tenseur au format [1,N,91] qui contient les scores des classes (avec le fond) des boites de détections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x6hySy-9g08J"
   },
   "outputs": [],
   "source": [
    "detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "teUmS8uYX8Z8"
   },
   "outputs": [],
   "source": [
    "detections['detection_boxes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RrZIR613YRz4"
   },
   "outputs": [],
   "source": [
    "detections['detection_boxes'][0,0,:].numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v5uYVRyag08L"
   },
   "source": [
    "### Affichage des résultats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UbtN_FgAg08L"
   },
   "source": [
    "Dessine les boites sur les trois premiers objets détectés :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bmLomP1wwL-5"
   },
   "outputs": [],
   "source": [
    "from PIL import ImageDraw\n",
    "from io import BytesIO\n",
    "\n",
    "\n",
    "def draw_bbox_and_label_in_image(img, boxes, num_detections, box_width=3):\n",
    "    \"\"\"\n",
    "    Draw bounding boxes and class labels in images\n",
    "    :param img: PIL Image or np arrays\n",
    "    :param boxes: in size [num_detections, 4], contains xys or boxes\n",
    "    :param box_width: the width of boxes\n",
    "    :return: Image\n",
    "    \"\"\"\n",
    "\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    width, height = img.size\n",
    "\n",
    "    for i in range(num_detections):\n",
    "        ymin, xmin, ymax, xmax = boxes[i]\n",
    "\n",
    "        ymin = int(ymin * height)\n",
    "        ymax = int(ymax * height)\n",
    "        xmin = int(xmin * width)\n",
    "        xmax = int(xmax * width)\n",
    "\n",
    "        class_color = \"LimeGreen\"\n",
    "\n",
    "        draw.line([(xmin, ymin), (xmax, ymin), (xmax, ymax), (xmin, ymax), (xmin, ymin)], width=box_width, fill=class_color)\n",
    "\n",
    "    return img\n",
    "\n",
    "draw_image = draw_bbox_and_label_in_image(image, detections['detection_boxes'][0,0:3,:],3)\n",
    "draw_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RceEfkuyg08M"
   },
   "outputs": [],
   "source": [
    "print (\"Classe du 1er objet : %d (score : %)\" %(detections['detection_classes'][0,0]))\n",
    "print (\"Classe du 2eme objet : %d\" %(detections['detection_classes'][0,1]))\n",
    "print (\"Classe du 3eme objet : %d\" %(detections['detection_classes'][0,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HR54mH6Zg08M"
   },
   "outputs": [],
   "source": [
    "detections['detection_classes'][0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EuZlr4wKCXI1"
   },
   "source": [
    "### Conversion du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lO1P-K_YFLBZ"
   },
   "outputs": [],
   "source": [
    "%set_env PYTHONPATH=\"/env/python:models/research:models/research/slim:models:TensorRT/samples/python/tensorflow_object_detection_api\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YJpagyaTBO4q"
   },
   "outputs": [],
   "source": [
    "!python3 TensorRT/samples/python/tensorflow_object_detection_api/create_onnx.py \\\n",
    "        --pipeline_config tfmodel_ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/pipeline.config \\\n",
    "        --saved_model tfmodel_ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/saved_model \\\n",
    "        --onnx tfmodel_ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/model_ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8_nms04.onnx \\\n",
    "        --input_format \"NHWC\" \\\n",
    "        --batch_size=1 \\\n",
    "        --first_nms_threshold 0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5cfJNMHNCScE"
   },
   "source": [
    "### Modification des formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j0WmTvY9By9s"
   },
   "outputs": [],
   "source": [
    "import onnx\n",
    "\n",
    "batch_size = 1\n",
    "onnx_model = onnx.load(\"tfmodel_ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/model_ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8_nms04.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o4b6to2aJ1Gq"
   },
   "outputs": [],
   "source": [
    "inputs = onnx_model.graph.input\n",
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversion du modèle au format TensorRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!TensorRT/build/trtexec --fp16 --workspace=3072 \\\n",
    "    --onnx=\"tfmodel_ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/model_ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8_nms04.onnx\" \\\n",
    "    --saveEngine=\"tfmodel_ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/model_ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8_nms04.engine\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test de la rapidité du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!TensorRT/build/trtexec --loadEngine=tfmodel_ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/model_ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8_nms04.engine \\\n",
    "                        --useCudaGraph \\\n",
    "                        --noDataTransfers \\\n",
    "                        --iterations=100 \\\n",
    "                        --avgRuns=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Essai_CenterNet Resnet101 V1.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
