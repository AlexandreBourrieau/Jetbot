{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Démonstration en temps réel de suivi d'objet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contrôle du robot pour le suivi d'un objet\n",
    "\n",
    "Nous voulons que le robot puisse suivre un objet spécifique. Pour cela, nous allons mettre en place les étapes suivantes :\n",
    "\n",
    "1.  Détecter les objets d'une classe spécifique\n",
    "2.  Sélectionner l'objet le plus proche du centre du champ de vision de la caméra. Cela sera notre objet \"cible\"\n",
    "3.  Piloter le robot vers la cible détectée, sinon errer\n",
    "4.  Si le robot est bloqué par un obstacle, tourner à gauche\n",
    "\n",
    "Fichier des labels : https://github.com/tensorflow/models/blob/master/research/object_detection/data/mscoco_label_map.pbtxt\n",
    "\n",
    "Nous allons également mettre en place des widgets permettant de contrôler la vitesse du robot, de choisir l'objet cible, ainsi que le gain en vitesse avec lequel le robot tournera pour aller vers la cible selon la distance avec celle-ci depuis le centre de la caméra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetbot import Robot\n",
    "\n",
    "robot = Robot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La classe ci-dessous reprend la classe vue dans le carnet précédent (CameraTempsReel) mais en y ajoutant le pilotage du robot et la détection des obstacles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorrt as trt\n",
    "import numpy as np\n",
    "import pycuda.driver as cuda\n",
    "import threading\n",
    "import ctypes\n",
    "import time\n",
    "import traitlets\n",
    "import atexit\n",
    "import cv2\n",
    "\n",
    "class TRTInference(threading.Thread):\n",
    "    def __init__(self,repertoire_engine_detection_objet, repertoire_labels, repertoire_engine_collision,\n",
    "                 widget_image,widget_bloque,widget_label,text_label_widget,vitesse_widget,gain_widget,widget_seuil_proba,widget_seuil_proba_bloque,\n",
    "                 type_camera=\"CSI\",capture_device=\"0\",capture_width=\"320\",capture_height=\"320\",\n",
    "                 display_width=\"320\",display_height=\"320\",fps=\"30\",flip=0,input_detect_width=320,input_detect_height=320):\n",
    "        threading.Thread.__init__(self)\n",
    "        self.widget_image = widget_image\n",
    "        self.widget_bloque = widget_bloque\n",
    "        self.type_camera = type_camera\n",
    "        self.capture_device = capture_device\n",
    "        self.capture_width = capture_width\n",
    "        self.capture_height = capture_height\n",
    "        self.display_width = display_width\n",
    "        self.display_height = display_height\n",
    "        self.widget_label = widget_label\n",
    "        self.text_label_widget = text_label_widget\n",
    "        self.vitesse_widget = vitesse_widget\n",
    "        self.widget_seuil_proba = widget_seuil_proba\n",
    "        self.widget_seuil_proba_bloque = widget_seuil_proba_bloque\n",
    "        self.gain_widget = gain_widget\n",
    "        self.fps = fps\n",
    "        self.flip = flip\n",
    "        self.camera_on = False\n",
    "        self.input_detect_width = input_detect_width\n",
    "        self.input_detect_height = input_detect_height\n",
    "        self.centre_1 = [input_detect_width/2,input_detect_height/2]\n",
    "\n",
    "        # Initialisation des variables de la caméra\n",
    "        self._running = False\n",
    "        self.image = np.zeros((self.display_height, self.display_width, 3), dtype=np.uint8)\n",
    "        if self.type_camera.find(\"CSI\")>=0:\n",
    "            self.cap = cv2.VideoCapture(self._gstreamer_pipeline_CSI(),cv2.CAP_GSTREAMER)\n",
    "        else:\n",
    "            self.cap = cv2.VideoCapture(self._gstreamer_pipeline_USB(),cv2.CAP_GSTREAMER)\n",
    "        if self.cap.isOpened():\n",
    "            print(\"Caméra initialisée\")\n",
    "        else:\n",
    "            print(\"Erreur d'ouverture du flux vidéo\")\n",
    "        atexit.register(self.cap.release)\n",
    "\n",
    "        # Initialisation du runtime TensorRT\n",
    "        self.logger = trt.Logger(trt.Logger.INFO)\n",
    "        trt.init_libnvinfer_plugins(self.logger, namespace=\"\")\n",
    "        self.runtime = trt.Runtime(self.logger)\n",
    "        \n",
    "        ################################################################\n",
    "        # Chargement du moteur de détection d'objets\n",
    "        print(\"Chargement du moteur de détection d'objets...\")\n",
    "        with open(repertoire_engine_detection_objet, \"rb\") as f:\n",
    "            self.engine_detection_objet = self.runtime.deserialize_cuda_engine(f.read())\n",
    "        \n",
    "        self.context_detection_objet = self.engine_detection_objet.create_execution_context()\n",
    "\n",
    "        #Initialisation du context Cuda et du contexte TensorRT \n",
    "        cuda.init()\n",
    "        self.cudactx = cuda.Device(0).retain_primary_context()\n",
    "        self.cudactx.push()\n",
    "        \n",
    "        # Réservation de la mémoire pour l'entrée\n",
    "        print(\"Allocation mémoire...\")\n",
    "        size_input = trt.volume(self.engine_detection_objet.get_binding_shape(0))*self.engine_detection_objet.max_batch_size\n",
    "        self.input_host_mem_detection_objet = cuda.pagelocked_empty(size_input, np.float32)\n",
    "        self.input_device_mem_detection_objet = cuda.mem_alloc(self.input_host_mem_detection_objet.nbytes)\n",
    "\n",
    "        # Réservation de la mémoire pour les sorties\n",
    "        self.output_device_mem_detection_objet = [];\n",
    "        format_sorties = [];\n",
    "        types_sorties = [];\n",
    "\n",
    "        for i in range(self.engine_detection_objet.num_bindings):\n",
    "            if not self.engine_detection_objet.binding_is_input(i):\n",
    "                size_output = trt.volume(self.engine_detection_objet.get_binding_shape(i))*self.engine_detection_objet.max_batch_size\n",
    "                output_hm = cuda.pagelocked_empty(size_output,trt.nptype(self.engine_detection_objet.get_binding_dtype(i)))\n",
    "                self.output_device_mem_detection_objet.append(cuda.mem_alloc(output_hm.nbytes))\n",
    "                format_sorties.append(self.engine_detection_objet.get_binding_shape(i))\n",
    "                types_sorties.append(trt.nptype(self.engine_detection_objet.get_binding_dtype(i)))\n",
    "\n",
    "        # Récupère les adresses en GPU des buffers entrées / sorties\n",
    "        binding_entree = int(self.input_device_mem_detection_objet)\n",
    "        binding_sorties = []\n",
    "\n",
    "        for output_ in self.output_device_mem_detection_objet:\n",
    "            binding_sorties.append(int(output_))\n",
    "        self.bindings_detection_objet = [binding_entree, binding_sorties[0],binding_sorties[1],binding_sorties[2],binding_sorties[3]]\n",
    "\n",
    "        # Allocation de la mémoire hote pour les sorties\n",
    "        self.output_host_mem_detection_objet = []\n",
    "        for i in range(len(self.output_device_mem_detection_objet)):\n",
    "            self.output_host_mem_detection_objet.append(np.zeros(format_sorties[i],types_sorties[i]))\n",
    "        \n",
    "        # Input tensor\n",
    "        self.image = np.zeros((self.input_detect_width,self.input_detect_height,3), dtype=trt.nptype(self.engine_detection_objet.get_binding_dtype(0)))\n",
    "\n",
    "        # Initialisation des labels\n",
    "        self.classes = self.read_label_map(repertoire_labels)\n",
    "\n",
    "        self.cudactx.pop()\n",
    "        \n",
    "        #####################################################################\n",
    "        # Chargement du moteur détection de collisions\n",
    "        print(\"Chargement du moteur de détection de collisions...\")\n",
    "        with open(repertoire_engine_collision, \"rb\") as f:\n",
    "            self.engine_collision = self.runtime.deserialize_cuda_engine(f.read())\n",
    "        \n",
    "        self.context_collision = self.engine_collision.create_execution_context()\n",
    "        self.context_collision.debug_sync = True\n",
    "\n",
    "        #Initialisation du context Cuda \n",
    "        self.cudactx = cuda.Device(0).retain_primary_context()\n",
    "        self.cudactx.push()\n",
    "        \n",
    "        # Réservation de la mémoire pour l'entrée et la sortie\n",
    "        print(\"Allocation mémoire...\")\n",
    "        size_input = trt.volume(self.engine_collision.get_binding_shape(0))*self.engine_collision.max_batch_size\n",
    "        size_output = trt.volume(self.engine_collision.get_binding_shape(1))* self.engine_collision.max_batch_size\n",
    "        self.input_host_mem_collision = cuda.pagelocked_empty(size_input, np.float32)\n",
    "        self.input_device_mem_collision = cuda.mem_alloc(self.input_host_mem_collision.nbytes)\n",
    "        self.output_host_mem_collision = cuda.pagelocked_empty(size_output, np.float32)\n",
    "        self.output_device_mem_collision = cuda.mem_alloc(self.output_host_mem_collision.nbytes)\n",
    "        self.bindings_collision = [int(self.input_device_mem_collision), int(self.output_device_mem_collision)]\n",
    "        self.cudactx.pop()\n",
    "        \n",
    "    # Lectures de labels\n",
    "    def read_label_map(self,label_map_path):\n",
    "        item_id = None\n",
    "        item_name = None\n",
    "        items = {}\n",
    "\n",
    "        with open(label_map_path, \"r\") as file:\n",
    "            for line in file:\n",
    "                line.replace(\" \", \"\")\n",
    "                if line == \"item{\":\n",
    "                    pass\n",
    "                elif line == \"}\":\n",
    "                    pass\n",
    "                elif \"id\" in line:\n",
    "                    item_id = int(line.split(\":\", 1)[1].strip())\n",
    "                elif \"display_name\" in line:\n",
    "                    item_name = line.split(\" \")[-1].replace(\"\\\"\", \" \").strip()\n",
    "                if item_id is not None and item_name is not None:\n",
    "                    items[item_id] = item_name\n",
    "                    item_id = None\n",
    "                    item_name = None\n",
    "        return items\n",
    "    \n",
    "    # Calcul des coordonnées x,y du centre de la boite\n",
    "    def calcul_centre_boite(self,detection):\n",
    "        ymin = int(self.input_detect_height * detection[0])\n",
    "        xmin = int(self.input_detect_width * detection[1])\n",
    "        ymax = int(self.input_detect_height * detection[2])\n",
    "        xmax = int(self.input_detect_width * detection[3])\n",
    "        centre_x = (xmin + xmax) / 2.0\n",
    "        centre_y = (ymin + ymax) / 2.0\n",
    "        return [centre_x, centre_y]\n",
    "\n",
    "    # Calcul de la norme du vecteur position entre le centre de la boite et le centre de la caméra\n",
    "    def norme(self,vec):\n",
    "        return np.sqrt((vec[0]-self.input_detect_width/2)**2 + (vec[1]-self.input_detect_height/2)**2)\n",
    "\n",
    "    # Détection de la boite avec la plus haute probabilité\n",
    "    def detect_le_plus_probable(self,detections,index_detections):\n",
    "        det_plus_probable = None\n",
    "        proba = 0\n",
    "        i = 0\n",
    "        index_boite = None\n",
    "        for det in detections:\n",
    "            if det_plus_probable is None:\n",
    "                det_plus_probable = det\n",
    "                index_boite = index_detections[i]\n",
    "                proba = self.output_host_mem_detection_objet[2][0,index_detections[i]]\n",
    "            elif self.output_host_mem_detection_objet[2][0,index_detections[i]] > proba:\n",
    "                proba = self.output_host_mem_detection_objet[2][0,index_detections[i]]\n",
    "                det_plus_probable = det\n",
    "                index_boite = index_detections[i]\n",
    "            i = i + 1\n",
    "        return det_plus_probable, index_boite\n",
    "\n",
    "    # Inférence\n",
    "    def Calcul(self):\n",
    "        ######################################################\n",
    "        # Détection de collisions\n",
    "        #######################################################\n",
    "        img_224 = cv2.resize(self.image,dsize=(224,224))\n",
    "        x = img_224.astype(np.float32)\n",
    "        x = np.expand_dims(x,axis=0)                    # (1,224,224,3)\n",
    "        np.copyto(self.input_host_mem_collision,x.ravel())\n",
    "\n",
    "        # Transfert de l'entrée vers le GPU\n",
    "        self.cudactx = cuda.Device(0).retain_primary_context()\n",
    "        self.cudactx.push()\n",
    "        cuda.memcpy_htod(self.input_device_mem_collision, self.input_host_mem_collision)\n",
    "\n",
    "        # Appel du modèle\n",
    "        self.context_collision.execute(batch_size=1, bindings=self.bindings_collision)\n",
    "        \n",
    "        # Récupération de la sortie\n",
    "        cuda.memcpy_dtoh(self.output_host_mem_collision, self.output_device_mem_collision)\n",
    "        self.cudactx.pop()\n",
    "\n",
    "        proba_bloquer = float(np.asarray(self.output_host_mem_collision[0]))\n",
    "        self.widget_bloque.value = proba_bloquer\n",
    "        \n",
    "        ################################################\n",
    "        # Détection d'objets\n",
    "        ################################################\n",
    "        # Copie de l'image dans le tenseur d'entrée\n",
    "        x = self.image.astype(np.float32)\n",
    "        x = np.expand_dims(x,axis=0)                    # (1,input_detect_width,input_detect_height,3)\n",
    "        np.copyto(self.input_host_mem_detection_objet,x.ravel())\n",
    "        \n",
    "        # Transfert de l'entrée vers le GPU\n",
    "        self.cudactx = cuda.Device(0).retain_primary_context()\n",
    "        self.cudactx.push()\n",
    "        cuda.memcpy_htod(self.input_device_mem_detection_objet, self.input_host_mem_detection_objet)\n",
    "        \n",
    "        # Appel du modèle\n",
    "        self.context_detection_objet.execute(batch_size=1, bindings=self.bindings_detection_objet)\n",
    "        \n",
    "        # Récupération des sorties\n",
    "        for i in range(len(self.output_host_mem_detection_objet)):\n",
    "            cuda.memcpy_dtoh(self.output_host_mem_detection_objet[i], self.output_device_mem_detection_objet[i])\n",
    "        self.cudactx.pop()\n",
    "        \n",
    "        ##############################################\n",
    "        # Traitement des résultats\n",
    "        ##############################################\n",
    "       \n",
    "        # Affiche le nom de l'objet en cours de traitement\n",
    "        self.text_label_widget.value = str(self.classes.get(int(self.widget_label.value)))\n",
    "\n",
    "        # Récupère le ou les boites des objets de la classe à détecter\n",
    "        index = 0\n",
    "        detect = []\n",
    "        detect_idx = []\n",
    "        for boite in self.output_host_mem_detection_objet[1][0,:,:]:\n",
    "            classe = self.output_host_mem_detection_objet[3][0,index]+1\n",
    "            if classe == int(self.widget_label.value) and self.output_host_mem_detection_objet[2][0,index] > self.widget_seuil_proba.value:\n",
    "                detect.append(boite)\n",
    "                detect_idx.append(index)\n",
    "            index = index + 1\n",
    "                \n",
    "        # Récupère la boite la plus probable\n",
    "        boite_la_plus_probable, index = self.detect_le_plus_probable(detect,detect_idx)\n",
    "\n",
    "        # Si un objet à suivre a été détecté\n",
    "        # Affiche un rectangle en rouge sur l'objet à suivre\n",
    "        # et avance vers la cible \n",
    "        if boite_la_plus_probable is not None and proba_bloquer < self.widget_seuil_proba_bloque.value:\n",
    "            # Tracé du rectangle\n",
    "            ymin = int(self.input_detect_height * boite_la_plus_probable[0])\n",
    "            xmin = int(self.input_detect_width * boite_la_plus_probable[1])\n",
    "            ymax = int(self.input_detect_height * boite_la_plus_probable[2])\n",
    "            xmax = int(self.input_detect_width * boite_la_plus_probable[3])\n",
    "            cv2.rectangle(self.image, (xmin,ymin),\n",
    "                              (xmax, ymax),\n",
    "                              (0, 0, 255), 1)\n",
    "            cv2.putText(self.image,\n",
    "                                str(self.classes.get(1+self.output_host_mem_detection_objet[3][0,index])),\n",
    "                                (xmin,ymin+20),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                                0.6,\n",
    "                                (0, 0, 255),\n",
    "                                1,\n",
    "                                cv2.LINE_AA)\n",
    "            cv2.putText(self.image,\n",
    "                                str(self.output_host_mem_detection_objet[2][0,index]),\n",
    "                                (xmin,ymin+40),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                                0.4,\n",
    "                                (0, 0, 255),\n",
    "                                1,\n",
    "                                cv2.LINE_AA)\n",
    "            \n",
    "            # Avance le robot vers la cible avec vitesse propotionnelle à la distance de celle-ci\n",
    "            centre = self.calcul_centre_boite(boite_la_plus_probable)\n",
    "            if self.vitesse_widget.value == 0.0:\n",
    "                robot.set_motors(0.0,0.0)\n",
    "            else:\n",
    "                ecart = centre[0]-self.input_detect_width/2\n",
    "                robot.set_motors(\n",
    "                    float(self.vitesse_widget.value + self.gain_widget.value * ecart/self.input_detect_width),\n",
    "                    float(self.vitesse_widget.value - self.gain_widget.value * ecart/self.input_detect_width)\n",
    "                    )\n",
    "        \n",
    "        # Si aucun objet à suivre n'a été détecté et qu'il n'y a aucun obstacle\n",
    "        elif proba_bloquer < self.widget_seuil_proba_bloque.value:\n",
    "            # Affiche les rectangles en bleu sur les 3 premiers objets détectés\n",
    "            for i in range(3):\n",
    "                ymin = int(self.input_detect_height * self.output_host_mem_detection_objet[1][0,i,0])\n",
    "                xmin = int(self.input_detect_width * self.output_host_mem_detection_objet[1][0,i,1])\n",
    "                ymax = int(self.input_detect_height * self.output_host_mem_detection_objet[1][0,i,2])\n",
    "                xmax = int(self.input_detect_width * self.output_host_mem_detection_objet[1][0,i,3])\n",
    "\n",
    "                cv2.rectangle(self.image, (xmin,ymin),\n",
    "                                  (xmax, ymax),\n",
    "                                  (255, 0, 0), 1)\n",
    "                cv2.putText(self.image,\n",
    "                                str(self.classes.get(1+self.output_host_mem_detection_objet[3][0,i])),\n",
    "                                (xmin,ymin+20),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                                0.6,\n",
    "                                (0, 255, 0),\n",
    "                                1,\n",
    "                                cv2.LINE_AA)\n",
    "            robot.forward(float(self.vitesse_widget.value))\n",
    "            \n",
    "        # Si il y a un obstacle et qu'un objet à suivre a été détecté\n",
    "        elif boite_la_plus_probable is not None and proba_bloquer > self.widget_seuil_proba_bloque.value:\n",
    "            centre = self.calcul_centre_boite(boite_la_plus_probable)\n",
    "            # Tracé du rectangle\n",
    "            ymin = int(self.input_detect_height * boite_la_plus_probable[0])\n",
    "            xmin = int(self.input_detect_width * boite_la_plus_probable[1])\n",
    "            ymax = int(self.input_detect_height * boite_la_plus_probable[2])\n",
    "            xmax = int(self.input_detect_width * boite_la_plus_probable[3])\n",
    "            cv2.rectangle(self.image, (xmin,ymin),\n",
    "                              (xmax, ymax),\n",
    "                              (0, 0, 255), 1)\n",
    "            cv2.putText(self.image,\n",
    "                                str(self.classes.get(1+self.output_host_mem_detection_objet[3][0,index])),\n",
    "                                (xmin,ymin+20),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                                0.6,\n",
    "                                (0, 0, 255),\n",
    "                                1,\n",
    "                                cv2.LINE_AA)\n",
    "            cv2.putText(self.image,\n",
    "                                str(self.output_host_mem_detection_objet[2][0,index]),\n",
    "                                (xmin,ymin+40),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                                0.4,\n",
    "                                (0, 0, 255),\n",
    "                                1,\n",
    "                                cv2.LINE_AA)\n",
    "            robot.set_motors(0.0,0.0)\n",
    "        \n",
    "        # Obstacle et aucun objet détecté\n",
    "        else:\n",
    "            robot.left(float(self.vitesse_widget.value))\n",
    "            \n",
    "    # Lecture d'une frame\n",
    "    def capture_image(self):\n",
    "        re, image = self.cap.read()\n",
    "        if re:\n",
    "            image_resized = cv2.resize(image,(int(self.display_width),int(self.display_height)))\n",
    "            return image_resized\n",
    "        else:\n",
    "            return self.image\n",
    "        \n",
    "    def run(self):\n",
    "        while True:\n",
    "            if self.camera_on is True:\n",
    "                self.image = self.capture_image()\n",
    "                self.Calcul()\n",
    "                self.widget_image.value = bgr8_to_jpeg(self.image)\n",
    "                time.sleep(0.001)\n",
    "\n",
    "    # Définition du pipeline pour la caméra CSI\n",
    "    def _gstreamer_pipeline_CSI(self):\n",
    "        return(\"nvarguscamerasrc sensor-id=%d ! \"\n",
    "                \"video/x-raw(memory:NVMM),\"\n",
    "                \"width=(int)%d,height=(int)%d,\"\n",
    "                \"format=(string)NV12, framerate=(fraction)%d/1 ! \"\n",
    "                \"nvvidconv flip-method=%d ! \"\n",
    "                \"video/x-raw,\"\n",
    "                \"width=(int)%d,height=(int)%d,\"\n",
    "                \"format=(string)BGRx ! videoconvert ! \"\n",
    "                \"video/x-raw, format=(string)BGR ! \"\n",
    "                \"appsink drop=true\"\n",
    "        %(self.capture_device,self.capture_width,self.capture_height,self.fps,self.flip, self.display_width,self.display_height))\n",
    "\n",
    "    # Définition du pipeline pour la USB\n",
    "    def _gstreamer_pipeline_USB(self):\n",
    "        return(\"v4l2src device=/dev/video%d ! \"\n",
    "               \"video/x-raw, width=(int)%d, height=(int)%d, framerate=(fraction)%d/1 ! \"\n",
    "               \"videoflip method=%d ! \"\n",
    "               \"videoconvert ! \"\n",
    "               \"video/x-raw, format=(string)BGR ! appsink drop=true\"\n",
    "        %(self.capture_device,self.capture_width,self.capture_height,self.fps,self.flip))            \n",
    "\n",
    "    # Routine pour arrêter le Thread\n",
    "    def raise_exception(self):\n",
    "        for id, thread in threading._active.items():\n",
    "            if thread is self:\n",
    "                thread_id = id\n",
    "        res = ctypes.pythonapi.PyThreadState_SetAsyncExc(thread_id,ctypes.py_object(SystemExit))\n",
    "        if res > 1:\n",
    "            ctypes.pythonapi.PyThreadState_SetAsyncExc(thread_id, 0)\n",
    "            print('Exception raise failure')\n",
    "\n",
    "    def destroy(self):\n",
    "        self.cudactx.detach()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construisons maintenant l'interface de pilotage :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets.widgets as widgets\n",
    "import traitlets\n",
    "from IPython.display import display\n",
    "from jetbot import bgr8_to_jpeg\n",
    "\n",
    "widget_bloque = widgets.FloatSlider(min=0.0, max=1.0, value=0.0, description='bloquer')\n",
    "widget_seuil_proba = widgets.FloatSlider(min=0.0, max=1.0, value=0.5, description='seuil detection')\n",
    "widget_seuil_proba_bloque = widgets.FloatSlider(min=0.0, max=1.0, value=0.5, description='seuil bloquer')\n",
    "image_widget = widgets.Image(format='jpeg', width=320, height=320)\n",
    "label_widget = widgets.IntText(value=1, description='label cible')\n",
    "text_label_widget = widgets.Text(value=\"\")\n",
    "vitesse_widget = widgets.FloatSlider(value=0.0, min=0.0, max=1.0, description='vitesse')\n",
    "gain_widget = widgets.FloatSlider(value=0.2, min=0.0, max=2.0, description='gain')\n",
    "\n",
    "\n",
    "display(widgets.VBox([\n",
    "    widgets.HBox([image_widget, widgets.VBox([widget_bloque,widget_seuil_proba,widget_seuil_proba_bloque])]),\n",
    "    widgets.HBox([label_widget,text_label_widget]),\n",
    "    vitesse_widget,\n",
    "    gain_widget\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trt_inference_wrapper = TRTInference(repertoire_engine_detection_objet=\"tfmodel_ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/model_ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8_nms04.engine\",\n",
    "                        repertoire_labels=\"models/research/object_detection/data/mscoco_complete_label_map.pbtxt\",\n",
    "                        repertoire_engine_collision=\"model_collision.engine\",             \n",
    "                        widget_image=image_widget,\n",
    "                        widget_label = label_widget,\n",
    "                        text_label_widget = text_label_widget,\n",
    "                        widget_bloque=widget_bloque,\n",
    "                        vitesse_widget=vitesse_widget,\n",
    "                        widget_seuil_proba=widget_seuil_proba,\n",
    "                        widget_seuil_proba_bloque = widget_seuil_proba_bloque,\n",
    "                        gain_widget=gain_widget,\n",
    "                        type_camera=\"CSI\",capture_device=0,\n",
    "                        capture_width=1024,capture_height=768,\n",
    "                        display_width=640,display_height=640,\n",
    "                        fps=20,flip=0,input_detect_width=640,input_detect_height=640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trt_inference_wrapper.start()\n",
    "trt_inference_wrapper.camera_on = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trt_inference_wrapper.camera_on = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "time.sleep(1.0)\n",
    "robot.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
